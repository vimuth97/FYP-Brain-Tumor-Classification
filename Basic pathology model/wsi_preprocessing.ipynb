{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "wsi_preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1hGq37MROFXAnzNo_JtUtufLKjf8rx6Xr",
      "authorship_tag": "ABX9TyOPQSHLC6WCvQfxN4RoRqyt",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vimuth97/FYP-Brain-Tumor-Classification/blob/main/Basic%20pathology%20model/wsi_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjnCDx3uFJhB",
        "outputId": "28b30713-abe4-4196-84a0-4a9d6fbcda45"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import time\n",
        "import argparse\n",
        "import pdb\n",
        "import pandas as pd\n",
        "import math\n",
        "import xml.etree.ElementTree as ET\n",
        "from xml.dom import minidom\n",
        "import multiprocessing as mp\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import h5py\n",
        "import itertools\n",
        "import pickle\n",
        "!apt update && apt install -y openslide-tools\n",
        "!pip install openslide-python \n",
        "import openslide "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com (91.189.88.152)] [1 InRelease 14.2 kB/88.7\u001b[0m\r                                                                               \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Ign:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:5 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Ign:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:12 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,431 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:14 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:15 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,367 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [607 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [640 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,803 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,210 kB]\n",
            "Fetched 10.3 MB in 4s (2,804 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "37 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libopenslide0\n",
            "Suggested packages:\n",
            "  libtiff-tools\n",
            "The following NEW packages will be installed:\n",
            "  libopenslide0 openslide-tools\n",
            "0 upgraded, 2 newly installed, 0 to remove and 37 not upgraded.\n",
            "Need to get 92.5 kB of archives.\n",
            "After this operation, 268 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libopenslide0 amd64 3.4.1+dfsg-2 [79.8 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 openslide-tools amd64 3.4.1+dfsg-2 [12.7 kB]\n",
            "Fetched 92.5 kB in 1s (148 kB/s)\n",
            "Selecting previously unselected package libopenslide0.\n",
            "(Reading database ... 155047 files and directories currently installed.)\n",
            "Preparing to unpack .../libopenslide0_3.4.1+dfsg-2_amd64.deb ...\n",
            "Unpacking libopenslide0 (3.4.1+dfsg-2) ...\n",
            "Selecting previously unselected package openslide-tools.\n",
            "Preparing to unpack .../openslide-tools_3.4.1+dfsg-2_amd64.deb ...\n",
            "Unpacking openslide-tools (3.4.1+dfsg-2) ...\n",
            "Setting up libopenslide0 (3.4.1+dfsg-2) ...\n",
            "Setting up openslide-tools (3.4.1+dfsg-2) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Collecting openslide-python\n",
            "  Downloading openslide-python-1.1.2.tar.gz (316 kB)\n",
            "\u001b[K     |████████████████████████████████| 316 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from openslide-python) (7.1.2)\n",
            "Building wheels for collected packages: openslide-python\n",
            "  Building wheel for openslide-python (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openslide-python: filename=openslide_python-1.1.2-cp37-cp37m-linux_x86_64.whl size=27710 sha256=4155e1c74653ada05d83bbc7fafb5e6c16bbcd4d9627c700e9985faf4cd60217\n",
            "  Stored in directory: /root/.cache/pip/wheels/6f/c3/97/980962653f9305314bfb6d93f80be5e21f13e206af66fc7ad3\n",
            "Successfully built openslide-python\n",
            "Installing collected packages: openslide-python\n",
            "Successfully installed openslide-python-1.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pplQfl5FMgi",
        "outputId": "89f9cec6-4ff1-49a0-fb14-f347cd1cde40"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiSLS7Crjib7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFmY2prSF2l3"
      },
      "source": [
        "**File Utils**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkHL3_BZFqxv"
      },
      "source": [
        "def save_pkl(filename, save_object):\n",
        "\twriter = open(filename,'wb')\n",
        "\tpickle.dump(save_object, writer)\n",
        "\twriter.close()\n",
        "\n",
        "def load_pkl(filename):\n",
        "\tloader = open(filename,'rb')\n",
        "\tfile = pickle.load(loader)\n",
        "\tloader.close()\n",
        "\treturn file"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wY2xd0MEGCsA"
      },
      "source": [
        "**Util Classes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Equ_uuNGAnZ"
      },
      "source": [
        "class Contour_Checking_fn(object):\n",
        "\t# Defining __call__ method \n",
        "\tdef __call__(self, pt): \n",
        "\t\traise NotImplementedError\n",
        "\n",
        "class isInContourV1(Contour_Checking_fn):\n",
        "\tdef __init__(self, contour):\n",
        "\t\tself.cont = contour\n",
        "\n",
        "\tdef __call__(self, pt): \n",
        "\t\treturn 1 if cv2.pointPolygonTest(self.cont, pt, False) >= 0 else 0\n",
        "\n",
        "class isInContourV2(Contour_Checking_fn):\n",
        "\tdef __init__(self, contour, patch_size):\n",
        "\t\tself.cont = contour\n",
        "\t\tself.patch_size = patch_size\n",
        "\n",
        "\tdef __call__(self, pt): \n",
        "\t\treturn 1 if cv2.pointPolygonTest(self.cont, (pt[0]+self.patch_size//2, pt[1]+self.patch_size//2), False) >= 0 else 0\n",
        "\n",
        "class isInContourV3_Easy(Contour_Checking_fn):\n",
        "\tdef __init__(self, contour, patch_size, center_shift=0.5):\n",
        "\t\tself.cont = contour\n",
        "\t\tself.patch_size = patch_size\n",
        "\t\tself.shift = int(patch_size//2*center_shift)\n",
        "\tdef __call__(self, pt): \n",
        "\t\tcenter = (pt[0]+self.patch_size//2, pt[1]+self.patch_size//2)\n",
        "\t\tif self.shift > 0:\n",
        "\t\t\tall_points = [(center[0]-self.shift, center[1]-self.shift),\n",
        "\t\t\t\t\t\t  (center[0]+self.shift, center[1]+self.shift),\n",
        "\t\t\t\t\t\t  (center[0]+self.shift, center[1]-self.shift),\n",
        "\t\t\t\t\t\t  (center[0]-self.shift, center[1]+self.shift)\n",
        "\t\t\t\t\t\t  ]\n",
        "\t\telse:\n",
        "\t\t\tall_points = [center]\n",
        "\t\t\n",
        "\t\tfor points in all_points:\n",
        "\t\t\tif cv2.pointPolygonTest(self.cont, points, False) >= 0:\n",
        "\t\t\t\treturn 1\n",
        "\t\treturn 0\n",
        "\n",
        "# Hard version of 4pt contour checking function - all 4 points need to be in the contour for test to pass\n",
        "class isInContourV3_Hard(Contour_Checking_fn):\n",
        "\tdef __init__(self, contour, patch_size, center_shift=0.5):\n",
        "\t\tself.cont = contour\n",
        "\t\tself.patch_size = patch_size\n",
        "\t\tself.shift = int(patch_size//2*center_shift)\n",
        "\tdef __call__(self, pt): \n",
        "\t\tcenter = (pt[0]+self.patch_size//2, pt[1]+self.patch_size//2)\n",
        "\t\tif self.shift > 0:\n",
        "\t\t\tall_points = [(center[0]-self.shift, center[1]-self.shift),\n",
        "\t\t\t\t\t\t  (center[0]+self.shift, center[1]+self.shift),\n",
        "\t\t\t\t\t\t  (center[0]+self.shift, center[1]-self.shift),\n",
        "\t\t\t\t\t\t  (center[0]-self.shift, center[1]+self.shift)\n",
        "\t\t\t\t\t\t  ]\n",
        "\t\telse:\n",
        "\t\t\tall_points = [center]\n",
        "\t\t\n",
        "\t\tfor points in all_points:\n",
        "\t\t\tif cv2.pointPolygonTest(self.cont, points, False) < 0:\n",
        "\t\t\t\treturn 0\n",
        "\t\treturn 1\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rTJX4CfHBmf"
      },
      "source": [
        "**WSI Utils**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uou8Yl6jGI3Y"
      },
      "source": [
        "def savePatchIter_bag_hdf5(patch):\n",
        "    x, y, cont_idx, patch_level, downsample, downsampled_level_dim, level_dim, img_patch, name, save_path= tuple(patch.values())\n",
        "    img_patch = np.array(img_patch)[np.newaxis,...]\n",
        "    img_shape = img_patch.shape\n",
        "\n",
        "    file_path = os.path.join(save_path, name)+'.h5'\n",
        "    file = h5py.File(file_path, \"a\")\n",
        "\n",
        "    dset = file['imgs']\n",
        "    dset.resize(len(dset) + img_shape[0], axis=0)\n",
        "    dset[-img_shape[0]:] = img_patch\n",
        "\n",
        "    if 'coords' in file:\n",
        "        coord_dset = file['coords']\n",
        "        coord_dset.resize(len(coord_dset) + img_shape[0], axis=0)\n",
        "        coord_dset[-img_shape[0]:] = (x,y)\n",
        "\n",
        "    file.close()\n",
        "\n",
        "def initialize_hdf5_bag(first_patch, save_coord=False):\n",
        "    x, y, cont_idx, patch_level, downsample, downsampled_level_dim, level_dim, img_patch, name, save_path = tuple(first_patch.values())\n",
        "    file_path = os.path.join(save_path, name)+'.h5'\n",
        "    file = h5py.File(file_path, \"w\")\n",
        "    img_patch = np.array(img_patch)[np.newaxis,...]\n",
        "    dtype = img_patch.dtype\n",
        "\n",
        "    # Initialize a resizable dataset to hold the output\n",
        "    img_shape = img_patch.shape\n",
        "    maxshape = (None,) + img_shape[1:] #maximum dimensions up to which dataset maybe resized (None means unlimited)\n",
        "    dset = file.create_dataset('imgs', \n",
        "                                shape=img_shape, maxshape=maxshape,  chunks=img_shape, dtype=dtype)\n",
        "\n",
        "    dset[:] = img_patch\n",
        "    dset.attrs['patch_level'] = patch_level\n",
        "    dset.attrs['wsi_name'] = name\n",
        "    dset.attrs['downsample'] = downsample\n",
        "    dset.attrs['level_dim'] = level_dim\n",
        "    dset.attrs['downsampled_level_dim'] = downsampled_level_dim\n",
        "\n",
        "    if save_coord:\n",
        "        coord_dset = file.create_dataset('coords', shape=(1, 2), maxshape=(None, 2), chunks=(1, 2), dtype=np.int32)\n",
        "        coord_dset[:] = (x,y)\n",
        "\n",
        "    file.close()\n",
        "    return file_path\n",
        "\n",
        "def coord_generator(x_start, x_end, x_step, y_start, y_end, y_step, args_dict=None):\n",
        "    for x in range(x_start, x_end, x_step):\n",
        "        for y in range(y_start, y_end, y_step):\n",
        "            if args_dict is not None:\n",
        "                process_dict = args_dict.copy()\n",
        "                process_dict.update({'pt':(x,y)})\n",
        "                yield process_dict\n",
        "            else:\n",
        "                yield (x,y)\n",
        "\n",
        "def save_hdf5(output_path, asset_dict, attr_dict= None, mode='a'):\n",
        "    file = h5py.File(output_path, mode)\n",
        "    for key, val in asset_dict.items():\n",
        "        data_shape = val.shape\n",
        "        if key not in file:\n",
        "            data_type = val.dtype\n",
        "            chunk_shape = (1, ) + data_shape[1:]\n",
        "            maxshape = (None, ) + data_shape[1:]\n",
        "            dset = file.create_dataset(key, shape=data_shape, maxshape=maxshape, chunks=chunk_shape, dtype=data_type)\n",
        "            dset[:] = val\n",
        "            if attr_dict is not None:\n",
        "                if key in attr_dict.keys():\n",
        "                    for attr_key, attr_val in attr_dict[key].items():\n",
        "                        dset.attrs[attr_key] = attr_val\n",
        "        else:\n",
        "            dset = file[key]\n",
        "            dset.resize(len(dset) + data_shape[0], axis=0)\n",
        "            dset[-data_shape[0]:] = val\n",
        "    file.close()\n",
        "    return output_path\n",
        "\n",
        "def sample_indices(scores, k, start=0.48, end=0.52, convert_to_percentile=False, seed=1):\n",
        "    np.random.seed(seed)\n",
        "    if convert_to_percentile:\n",
        "        end_value = np.quantile(scores, end)\n",
        "        start_value = np.quantile(scores, start)\n",
        "    else:\n",
        "        end_value = end\n",
        "        start_value = start\n",
        "    score_window = np.logical_and(scores >= start_value, scores <= end_value)\n",
        "    indices = np.where(score_window)[0]\n",
        "    if len(indices) < 1:\n",
        "        return -1 \n",
        "    else:\n",
        "        return np.random.choice(indices, min(k, len(indices)), replace=False)\n",
        "\n",
        "\n",
        "def screen_coords(scores, coords, top_left, bot_right):\n",
        "    bot_right = np.array(bot_right)\n",
        "    top_left = np.array(top_left)\n",
        "    mask = np.logical_and(np.all(coords >= top_left, axis=1), np.all(coords <= bot_right, axis=1))\n",
        "    scores = scores[mask]\n",
        "    coords = coords[mask]\n",
        "    return scores, coords\n",
        "\n",
        "def isBlackPatch(patch, rgbThresh=40):\n",
        "    return True if np.all(np.mean(patch, axis = (0,1)) < rgbThresh) else False\n",
        "\n",
        "def isWhitePatch(patch, satThresh=5):\n",
        "    patch_hsv = cv2.cvtColor(patch, cv2.COLOR_RGB2HSV)\n",
        "    return True if np.mean(patch_hsv[:,:,1]) < satThresh else False\n",
        "\n",
        "def to_percentiles(scores):\n",
        "    from scipy.stats import rankdata\n",
        "    scores = rankdata(scores, 'average')/len(scores) * 100   \n",
        "    return scores"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoP0MuadpJ3k"
      },
      "source": [
        "def DrawMapFromCoords(canvas, wsi_object, coords, patch_size, vis_level, indices=None, verbose=1, draw_grid=True):\n",
        "    downsamples = wsi_object.wsi.level_downsamples[vis_level]\n",
        "    if indices is None:\n",
        "        indices = np.arange(len(coords))\n",
        "    total = len(indices)\n",
        "    if verbose > 0:\n",
        "        ten_percent_chunk = math.ceil(total * 0.1)\n",
        "        \n",
        "    patch_size = tuple(np.ceil((np.array(patch_size)/np.array(downsamples))).astype(np.int32))\n",
        "    print('downscaled patch size: {}x{}'.format(patch_size[0], patch_size[1]))\n",
        "    \n",
        "    for idx in range(total):\n",
        "        if verbose > 0:\n",
        "            if idx % ten_percent_chunk == 0:\n",
        "                print('progress: {}/{} stitched'.format(idx, total))\n",
        "        \n",
        "        patch_id = indices[idx]\n",
        "        coord = coords[patch_id]\n",
        "        patch = np.array(wsi_object.wsi.read_region(tuple(coord), vis_level, patch_size).convert(\"RGB\"))\n",
        "        coord = np.ceil(coord / downsamples).astype(np.int32)\n",
        "        canvas_crop_shape = canvas[coord[1]:coord[1]+patch_size[1], coord[0]:coord[0]+patch_size[0], :3].shape[:2]\n",
        "        canvas[coord[1]:coord[1]+patch_size[1], coord[0]:coord[0]+patch_size[0], :3] = patch[:canvas_crop_shape[0], :canvas_crop_shape[1], :]\n",
        "        if draw_grid:\n",
        "            DrawGrid(canvas, coord, patch_size)\n",
        "\n",
        "    return Image.fromarray(canvas)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XZ8DbgtHE9r"
      },
      "source": [
        "\n",
        "def StitchCoords(hdf5_file_path, wsi_object, downscale=16, draw_grid=False, bg_color=(0,0,0), alpha=-1):\n",
        "    wsi = wsi_object.getOpenSlide()\n",
        "    vis_level = wsi.get_best_level_for_downsample(downscale)\n",
        "    file = h5py.File(hdf5_file_path, 'r')\n",
        "    dset = file['coords']\n",
        "    coords = dset[:]\n",
        "    w, h = wsi.level_dimensions[0]\n",
        "\n",
        "    print('start stitching {}'.format(dset.attrs['name']))\n",
        "    print('original size: {} x {}'.format(w, h))\n",
        "\n",
        "    w, h = wsi.level_dimensions[vis_level]\n",
        "\n",
        "    print('downscaled size for stiching: {} x {}'.format(w, h))\n",
        "    print('number of patches: {}'.format(len(coords)))\n",
        "    \n",
        "    patch_size = dset.attrs['patch_size']\n",
        "    patch_level = dset.attrs['patch_level']\n",
        "    print('patch size: {}x{} patch level: {}'.format(patch_size, patch_size, patch_level))\n",
        "    patch_size = tuple((np.array((patch_size, patch_size)) * wsi.level_downsamples[patch_level]).astype(np.int32))\n",
        "    print('ref patch size: {}x{}'.format(patch_size, patch_size))\n",
        "\n",
        "    if w*h > Image.MAX_IMAGE_PIXELS: \n",
        "        raise Image.DecompressionBombError(\"Visualization Downscale %d is too large\" % downscale)\n",
        "    \n",
        "    if alpha < 0 or alpha == -1:\n",
        "        heatmap = Image.new(size=(w,h), mode=\"RGB\", color=bg_color)\n",
        "    else:\n",
        "        heatmap = Image.new(size=(w,h), mode=\"RGBA\", color=bg_color + (int(255 * alpha),))\n",
        "    \n",
        "    heatmap = np.array(heatmap)\n",
        "    heatmap = DrawMapFromCoords(heatmap, wsi_object, coords, patch_size, vis_level, indices=None, draw_grid=draw_grid)\n",
        "    \n",
        "    file.close()\n",
        "    return heatmap\n",
        "\n",
        "def initialize_df(slides, seg_params, filter_params, vis_params, patch_params, \n",
        "\tuse_heatmap_args=False, save_patches=False):\n",
        "\n",
        "\ttotal = len(slides)\n",
        "\tif isinstance(slides, pd.DataFrame):\n",
        "\t\tslide_ids = slides.slide_id.values\n",
        "\telse:\n",
        "\t\tslide_ids = slides\n",
        "\tdefault_df_dict = {'slide_id': slide_ids, 'process': np.full((total), 1, dtype=np.uint8)}\n",
        "\n",
        "\t# initiate empty labels in case not provided\n",
        "\tif use_heatmap_args:\n",
        "\t\tdefault_df_dict.update({'label': np.full((total), -1)})\n",
        "\t\n",
        "\tdefault_df_dict.update({\n",
        "\t\t'status': np.full((total), 'tbp'),\n",
        "\t\t# seg params\n",
        "\t\t'seg_level': np.full((total), int(seg_params['seg_level']), dtype=np.int8),\n",
        "\t\t'sthresh': np.full((total), int(seg_params['sthresh']), dtype=np.uint8),\n",
        "\t\t'mthresh': np.full((total), int(seg_params['mthresh']), dtype=np.uint8),\n",
        "\t\t'close': np.full((total), int(seg_params['close']), dtype=np.uint32),\n",
        "\t\t'use_otsu': np.full((total), bool(seg_params['use_otsu']), dtype=bool),\n",
        "\t\t'keep_ids': np.full((total), seg_params['keep_ids']),\n",
        "\t\t'exclude_ids': np.full((total), seg_params['exclude_ids']),\n",
        "\t\t\n",
        "\t\t# filter params\n",
        "\t\t'a_t': np.full((total), int(filter_params['a_t']), dtype=np.float32),\n",
        "\t\t'a_h': np.full((total), int(filter_params['a_h']), dtype=np.float32),\n",
        "\t\t'max_n_holes': np.full((total), int(filter_params['max_n_holes']), dtype=np.uint32),\n",
        "\n",
        "\t\t# vis params\n",
        "\t\t'vis_level': np.full((total), int(vis_params['vis_level']), dtype=np.int8),\n",
        "\t\t'line_thickness': np.full((total), int(vis_params['line_thickness']), dtype=np.uint32),\n",
        "\n",
        "\t\t# patching params\n",
        "\t\t'use_padding': np.full((total), bool(patch_params['use_padding']), dtype=bool),\n",
        "\t\t'contour_fn': np.full((total), patch_params['contour_fn'])\n",
        "\t\t})\n",
        "\n",
        "\tif save_patches:\n",
        "\t\tdefault_df_dict.update({\n",
        "\t\t\t'white_thresh': np.full((total), int(patch_params['white_thresh']), dtype=np.uint8),\n",
        "\t\t\t'black_thresh': np.full((total), int(patch_params['black_thresh']), dtype=np.uint8)})\n",
        "\n",
        "\tif use_heatmap_args:\n",
        "\t\t# initiate empty x,y coordinates in case not provided\n",
        "\t\tdefault_df_dict.update({'x1': np.empty((total)).fill(np.NaN), \n",
        "\t\t\t'x2': np.empty((total)).fill(np.NaN), \n",
        "\t\t\t'y1': np.empty((total)).fill(np.NaN), \n",
        "\t\t\t'y2': np.empty((total)).fill(np.NaN)})\n",
        "\n",
        "\n",
        "\tif isinstance(slides, pd.DataFrame):\n",
        "\t\ttemp_copy = pd.DataFrame(default_df_dict) # temporary dataframe w/ default params\n",
        "\t\t# find key in provided df\n",
        "\t\t# if exist, fill empty fields w/ default values, else, insert the default values as a new column\n",
        "\t\tfor key in default_df_dict.keys(): \n",
        "\t\t\tif key in slides.columns:\n",
        "\t\t\t\tmask = slides[key].isna()\n",
        "\t\t\t\tslides.loc[mask, key] = temp_copy.loc[mask, key]\n",
        "\t\t\telse:\n",
        "\t\t\t\tslides.insert(len(slides.columns), key, default_df_dict[key])\n",
        "\telse:\n",
        "\t\tslides = pd.DataFrame(default_df_dict)\n",
        "\t\n",
        "\treturn slides"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQ1oPkX-HMho"
      },
      "source": [
        "**WSI Image class**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NI7EyjejHJRx"
      },
      "source": [
        "Image.MAX_IMAGE_PIXELS = 9331200000\n",
        "\n",
        "class WholeSlideImage(object):\n",
        "    def __init__(self, path):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            path (str): fullpath to WSI file\n",
        "        \"\"\"\n",
        "\n",
        "        self.name = \".\".join(path.split(\"/\")[-1].split('.')[:-1])\n",
        "\n",
        "        print(\"Name:\"+self.name)\n",
        "\n",
        "        self.file_path = path \n",
        "        \n",
        "        self.wsi = openslide.open_slide(self.file_path)\n",
        "        \n",
        "\n",
        "        \n",
        "        #self.level_downsamples = level_downsamples\n",
        "        self.level_downsamples = self._assertLevelDownsamples()#\n",
        "        self.level_dim = self.wsi.level_dimensions #(4000,4000)\n",
        "    \n",
        "        self.contours_tissue = None\n",
        "        self.contours_tumor = None\n",
        "        self.hdf5_file = None\n",
        "\n",
        "    def getOpenSlide(self):\n",
        "        return self.wsi\n",
        "\n",
        "    def initXML(self, xml_path):\n",
        "        def _createContour(coord_list):\n",
        "            return np.array([[[int(float(coord.attributes['X'].value)), \n",
        "                               int(float(coord.attributes['Y'].value))]] for coord in coord_list], dtype = 'int32')\n",
        "\n",
        "        xmldoc = minidom.parse(xml_path)\n",
        "        annotations = [anno.getElementsByTagName('Coordinate') for anno in xmldoc.getElementsByTagName('Annotation')]\n",
        "        self.contours_tumor  = [_createContour(coord_list) for coord_list in annotations]\n",
        "        self.contours_tumor = sorted(self.contours_tumor, key=cv2.contourArea, reverse=True)\n",
        "\n",
        "    def initTxt(self,annot_path):\n",
        "        def _create_contours_from_dict(annot):\n",
        "            all_cnts = []\n",
        "            for idx, annot_group in enumerate(annot):\n",
        "                contour_group = annot_group['coordinates']\n",
        "                if annot_group['type'] == 'Polygon':\n",
        "                    for idx, contour in enumerate(contour_group):\n",
        "                        contour = np.array(contour).astype(np.int32).reshape(-1,1,2)\n",
        "                        all_cnts.append(contour) \n",
        "\n",
        "                else:\n",
        "                    for idx, sgmt_group in enumerate(contour_group):\n",
        "                        contour = []\n",
        "                        for sgmt in sgmt_group:\n",
        "                            contour.extend(sgmt)\n",
        "                        contour = np.array(contour).astype(np.int32).reshape(-1,1,2)    \n",
        "                        all_cnts.append(contour) \n",
        "\n",
        "            return all_cnts\n",
        "        \n",
        "        with open(annot_path, \"r\") as f:\n",
        "            annot = f.read()\n",
        "            annot = eval(annot)\n",
        "        self.contours_tumor  = _create_contours_from_dict(annot)\n",
        "        self.contours_tumor = sorted(self.contours_tumor, key=cv2.contourArea, reverse=True)\n",
        "\n",
        "    def initSegmentation(self, mask_file):\n",
        "        # load segmentation results from pickle file\n",
        "        import pickle\n",
        "        asset_dict = load_pkl(mask_file)\n",
        "        self.holes_tissue = asset_dict['holes']\n",
        "        self.contours_tissue = asset_dict['tissue']\n",
        "\n",
        "    def saveSegmentation(self, mask_file):\n",
        "        # save segmentation results using pickle\n",
        "        asset_dict = {'holes': self.holes_tissue, 'tissue': self.contours_tissue}\n",
        "        save_pkl(mask_file, asset_dict)\n",
        "\n",
        "    def segmentTissue(self, seg_level=0, sthresh=20, sthresh_up = 255, mthresh=7, close = 0, use_otsu=False, \n",
        "                            filter_params={'a_t':100}, ref_patch_size=512, exclude_ids=[], keep_ids=[]):\n",
        "        \"\"\"\n",
        "            Segment the tissue via HSV -> Median thresholding -> Binary threshold\n",
        "        \"\"\"\n",
        "        \n",
        "        def _filter_contours(contours, hierarchy, filter_params):\n",
        "            \"\"\"\n",
        "                Filter contours by: area.\n",
        "            \"\"\"\n",
        "            filtered = []\n",
        "\n",
        "            # find indices of foreground contours (parent == -1)\n",
        "            hierarchy_1 = np.flatnonzero(hierarchy[:,1] == -1)\n",
        "            all_holes = []\n",
        "            \n",
        "            # loop through foreground contour indices\n",
        "            for cont_idx in hierarchy_1:\n",
        "                # actual contour\n",
        "                cont = contours[cont_idx]\n",
        "                # indices of holes contained in this contour (children of parent contour)\n",
        "                holes = np.flatnonzero(hierarchy[:, 1] == cont_idx)\n",
        "                # take contour area (includes holes)\n",
        "                a = cv2.contourArea(cont)\n",
        "                # calculate the contour area of each hole\n",
        "                hole_areas = [cv2.contourArea(contours[hole_idx]) for hole_idx in holes]\n",
        "                # actual area of foreground contour region\n",
        "                a = a - np.array(hole_areas).sum()\n",
        "                if a == 0: continue\n",
        "                if tuple((filter_params['a_t'],)) < tuple((a,)): \n",
        "                    filtered.append(cont_idx)\n",
        "                    all_holes.append(holes)\n",
        "\n",
        "\n",
        "            foreground_contours = [contours[cont_idx] for cont_idx in filtered]\n",
        "            \n",
        "            hole_contours = []\n",
        "\n",
        "            for hole_ids in all_holes:\n",
        "                unfiltered_holes = [contours[idx] for idx in hole_ids ]\n",
        "                unfilered_holes = sorted(unfiltered_holes, key=cv2.contourArea, reverse=True)\n",
        "                # take max_n_holes largest holes by area\n",
        "                unfilered_holes = unfilered_holes[:filter_params['max_n_holes']]\n",
        "                filtered_holes = []\n",
        "                \n",
        "                # filter these holes\n",
        "                for hole in unfilered_holes:\n",
        "                    if cv2.contourArea(hole) > filter_params['a_h']:\n",
        "                        filtered_holes.append(hole)\n",
        "\n",
        "                hole_contours.append(filtered_holes)\n",
        "\n",
        "            return foreground_contours, hole_contours\n",
        "        \n",
        "        img = np.array(self.wsi.read_region((0,0), seg_level, self.level_dim[seg_level]))\n",
        "        img_hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)  # Convert to HSV space\n",
        "        img_med = cv2.medianBlur(img_hsv[:,:,1], mthresh)  # Apply median blurring\n",
        "        \n",
        "       \n",
        "        # Thresholding\n",
        "        if use_otsu:\n",
        "            _, img_otsu = cv2.threshold(img_med, 0, sthresh_up, cv2.THRESH_OTSU+cv2.THRESH_BINARY)\n",
        "        else:\n",
        "            _, img_otsu = cv2.threshold(img_med, sthresh, sthresh_up, cv2.THRESH_BINARY)\n",
        "\n",
        "        # Morphological closing\n",
        "        if close > 0:\n",
        "            kernel = np.ones((close, close), np.uint8)\n",
        "            img_otsu = cv2.morphologyEx(img_otsu, cv2.MORPH_CLOSE, kernel)                 \n",
        "\n",
        "        scale = self.level_downsamples[seg_level]\n",
        "        scaled_ref_patch_area = int(ref_patch_size**2 / (scale[0] * scale[1]))\n",
        "        filter_params = filter_params.copy()\n",
        "        filter_params['a_t'] = filter_params['a_t'] * scaled_ref_patch_area\n",
        "        filter_params['a_h'] = filter_params['a_h'] * scaled_ref_patch_area\n",
        "        \n",
        "        # Find and filter contours\n",
        "        contours, hierarchy = cv2.findContours(img_otsu, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE) # Find contours \n",
        "        hierarchy = np.squeeze(hierarchy, axis=(0,))[:, 2:]\n",
        "        if filter_params: foreground_contours, hole_contours = _filter_contours(contours, hierarchy, filter_params)  # Necessary for filtering out artifacts\n",
        "\n",
        "        self.contours_tissue = self.scaleContourDim(foreground_contours, scale)\n",
        "        self.holes_tissue = self.scaleHolesDim(hole_contours, scale)\n",
        "\n",
        "        #exclude_ids = [0,7,9]\n",
        "        if len(keep_ids) > 0:\n",
        "            contour_ids = set(keep_ids) - set(exclude_ids)\n",
        "        else:\n",
        "            contour_ids = set(np.arange(len(self.contours_tissue))) - set(exclude_ids)\n",
        "\n",
        "        self.contours_tissue = [self.contours_tissue[i] for i in contour_ids]\n",
        "        self.holes_tissue = [self.holes_tissue[i] for i in contour_ids]\n",
        "\n",
        "    def visWSI(self, vis_level=0, color = (0,255,0), hole_color = (0,0,255), annot_color=(255,0,0), \n",
        "                    line_thickness=250, max_size=None, top_left=None, bot_right=None, custom_downsample=1, view_slide_only=False,\n",
        "                    number_contours=False, seg_display=True, annot_display=True):\n",
        "        \n",
        "        downsample = self.level_downsamples[vis_level]\n",
        "        scale = [1/downsample[0], 1/downsample[1]]\n",
        "        \n",
        "        if top_left is not None and bot_right is not None:\n",
        "            top_left = tuple(top_left)\n",
        "            bot_right = tuple(bot_right)\n",
        "            w, h = tuple((np.array(bot_right) * scale).astype(int) - (np.array(top_left) * scale).astype(int))\n",
        "            region_size = (w, h)\n",
        "        else:\n",
        "            top_left = (0,0)\n",
        "            region_size = self.level_dim[vis_level]\n",
        "\n",
        "        img = np.array(self.wsi.read_region(top_left, vis_level, region_size).convert(\"RGB\"))\n",
        "        \n",
        "        if not view_slide_only:\n",
        "            offset = tuple(-(np.array(top_left) * scale).astype(int))\n",
        "            line_thickness = int(line_thickness * math.sqrt(scale[0] * scale[1]))\n",
        "            if self.contours_tissue is not None and seg_display:\n",
        "                if not number_contours:\n",
        "                    cv2.drawContours(img, self.scaleContourDim(self.contours_tissue, scale), \n",
        "                                     -1, color, line_thickness, lineType=cv2.LINE_8, offset=offset)\n",
        "\n",
        "                else: # add numbering to each contour\n",
        "                    for idx, cont in enumerate(self.contours_tissue):\n",
        "                        contour = np.array(self.scaleContourDim(cont, scale))\n",
        "                        M = cv2.moments(contour)\n",
        "                        cX = int(M[\"m10\"] / (M[\"m00\"] + 1e-9))\n",
        "                        cY = int(M[\"m01\"] / (M[\"m00\"] + 1e-9))\n",
        "                        # draw the contour and put text next to center\n",
        "                        cv2.drawContours(img,  [contour], -1, color, line_thickness, lineType=cv2.LINE_8, offset=offset)\n",
        "                        cv2.putText(img, \"{}\".format(idx), (cX, cY),\n",
        "                                cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 0, 0), 10)\n",
        "\n",
        "                for holes in self.holes_tissue:\n",
        "                    cv2.drawContours(img, self.scaleContourDim(holes, scale), \n",
        "                                     -1, hole_color, line_thickness, lineType=cv2.LINE_8)\n",
        "            \n",
        "            if self.contours_tumor is not None and annot_display:\n",
        "                cv2.drawContours(img, self.scaleContourDim(self.contours_tumor, scale), \n",
        "                                 -1, annot_color, line_thickness, lineType=cv2.LINE_8, offset=offset)\n",
        "        \n",
        "        img = Image.fromarray(img)\n",
        "    \n",
        "        w, h = img.size\n",
        "        if custom_downsample > 1:\n",
        "            img = img.resize((int(w/custom_downsample), int(h/custom_downsample)))\n",
        "\n",
        "        if max_size is not None and (w > max_size or h > max_size):\n",
        "            resizeFactor = max_size/w if w > h else max_size/h\n",
        "            img = img.resize((int(w*resizeFactor), int(h*resizeFactor)))\n",
        "       \n",
        "        return img\n",
        "\n",
        "\n",
        "    def createPatches_bag_hdf5(self, save_path, patch_level=0, patch_size=256, step_size=256, save_coord=True, **kwargs):\n",
        "        contours = self.contours_tissue\n",
        "        contour_holes = self.holes_tissue\n",
        "\n",
        "        print(\"Creating patches for: \", self.name, \"...\",)\n",
        "        elapsed = time.time()\n",
        "        for idx, cont in enumerate(contours):\n",
        "            patch_gen = self._getPatchGenerator(cont, idx, patch_level, save_path, patch_size, step_size, **kwargs)\n",
        "            \n",
        "            if self.hdf5_file is None:\n",
        "                try:\n",
        "                    first_patch = next(patch_gen)\n",
        "\n",
        "                # empty contour, continue\n",
        "                except StopIteration:\n",
        "                    continue\n",
        "\n",
        "                file_path = initialize_hdf5_bag(first_patch, save_coord=save_coord)\n",
        "                self.hdf5_file = file_path\n",
        "\n",
        "            for patch in patch_gen:\n",
        "                savePatchIter_bag_hdf5(patch)\n",
        "\n",
        "        return self.hdf5_file\n",
        "\n",
        "\n",
        "    def _getPatchGenerator(self, cont, cont_idx, patch_level, save_path, patch_size=256, step_size=256, custom_downsample=1,\n",
        "        white_black=True, white_thresh=15, black_thresh=50, contour_fn='four_pt', use_padding=True):\n",
        "        start_x, start_y, w, h = cv2.boundingRect(cont) if cont is not None else (0, 0, self.level_dim[patch_level][0], self.level_dim[patch_level][1])\n",
        "        print(\"Bounding Box:\", start_x, start_y, w, h)\n",
        "        print(\"Contour Area:\", cv2.contourArea(cont))\n",
        "        \n",
        "        if custom_downsample > 1:\n",
        "            assert custom_downsample == 2 \n",
        "            target_patch_size = patch_size\n",
        "            patch_size = target_patch_size * 2\n",
        "            step_size = step_size * 2\n",
        "            print(\"Custom Downsample: {}, Patching at {} x {}, But Final Patch Size is {} x {}\".format(custom_downsample, patch_size, patch_size, \n",
        "                target_patch_size, target_patch_size))\n",
        "\n",
        "        patch_downsample = (int(self.level_downsamples[patch_level][0]), int(self.level_downsamples[patch_level][1]))\n",
        "        ref_patch_size = (patch_size*patch_downsample[0], patch_size*patch_downsample[1])\n",
        "        \n",
        "        step_size_x = step_size * patch_downsample[0]\n",
        "        step_size_y = step_size * patch_downsample[1]\n",
        "        \n",
        "        if isinstance(contour_fn, str):\n",
        "            if contour_fn == 'four_pt':\n",
        "                cont_check_fn = isInContourV3_Easy(contour=cont, patch_size=ref_patch_size[0], center_shift=0.5)\n",
        "            elif contour_fn == 'four_pt_hard':\n",
        "                cont_check_fn = isInContourV3_Hard(contour=cont, patch_size=ref_patch_size[0], center_shift=0.5)\n",
        "            elif contour_fn == 'center':\n",
        "                cont_check_fn = isInContourV2(contour=cont, patch_size=ref_patch_size[0])\n",
        "            elif contour_fn == 'basic':\n",
        "                cont_check_fn = isInContourV1(contour=cont)\n",
        "            else:\n",
        "                raise NotImplementedError\n",
        "        else:\n",
        "            assert isinstance(contour_fn, Contour_Checking_fn)\n",
        "            cont_check_fn = contour_fn\n",
        "\n",
        "        img_w, img_h = self.level_dim[0]\n",
        "        if use_padding:\n",
        "            stop_y = start_y+h\n",
        "            stop_x = start_x+w\n",
        "        else:\n",
        "            stop_y = min(start_y+h, img_h-ref_patch_size[1])\n",
        "            stop_x = min(start_x+w, img_w-ref_patch_size[0])\n",
        "\n",
        "        count = 0\n",
        "        for y in range(start_y, stop_y, step_size_y):\n",
        "            for x in range(start_x, stop_x, step_size_x):\n",
        "\n",
        "                if not self.isInContours(cont_check_fn, (x,y), self.holes_tissue[cont_idx], ref_patch_size[0]): #point not inside contour and its associated holes\n",
        "                    continue    \n",
        "                \n",
        "                count+=1\n",
        "                patch_PIL = self.wsi.read_region((x,y), patch_level, (patch_size, patch_size)).convert('RGB')\n",
        "                if custom_downsample > 1:\n",
        "                    patch_PIL = patch_PIL.resize((target_patch_size, target_patch_size))\n",
        "                \n",
        "                if white_black:\n",
        "                    if isBlackPatch(np.array(patch_PIL), rgbThresh=black_thresh) or isWhitePatch(np.array(patch_PIL), satThresh=white_thresh): \n",
        "                        continue\n",
        "\n",
        "                patch_info = {'x':x // (patch_downsample[0] * custom_downsample), 'y':y // (patch_downsample[1] * custom_downsample), 'cont_idx':cont_idx, 'patch_level':patch_level, \n",
        "                'downsample': self.level_downsamples[patch_level], 'downsampled_level_dim': tuple(np.array(self.level_dim[patch_level])//custom_downsample), 'level_dim': self.level_dim[patch_level],\n",
        "                'patch_PIL':patch_PIL, 'name':self.name, 'save_path':save_path}\n",
        "\n",
        "                yield patch_info\n",
        "\n",
        "        \n",
        "        print(\"patches extracted: {}\".format(count))\n",
        "\n",
        "    @staticmethod\n",
        "    def isInHoles(holes, pt, patch_size):\n",
        "        for hole in holes:\n",
        "            if cv2.pointPolygonTest(hole, (pt[0]+patch_size/2, pt[1]+patch_size/2), False) > 0:\n",
        "                return 1\n",
        "        \n",
        "        return 0\n",
        "\n",
        "    @staticmethod\n",
        "    def isInContours(cont_check_fn, pt, holes=None, patch_size=256):\n",
        "        if cont_check_fn(pt):\n",
        "            if holes is not None:\n",
        "                return not WholeSlideImage.isInHoles(holes, pt, patch_size)\n",
        "            else:\n",
        "                return 1\n",
        "        return 0\n",
        "    \n",
        "    @staticmethod\n",
        "    def scaleContourDim(contours, scale):\n",
        "        return [np.array(cont * scale, dtype='int32') for cont in contours]\n",
        "\n",
        "    @staticmethod\n",
        "    def scaleHolesDim(contours, scale):\n",
        "        return [[np.array(hole * scale, dtype = 'int32') for hole in holes] for holes in contours]\n",
        "\n",
        "    def _assertLevelDownsamples(self):\n",
        "        level_downsamples = []\n",
        "        dim_0 = self.wsi.level_dimensions[0]   #(4000,4000)\n",
        "        \n",
        "        for downsample, dim in zip(self.wsi.level_downsamples, self.wsi.level_dimensions):\n",
        "            estimated_downsample = (dim_0[0]/float(dim[0]), dim_0[1]/float(dim[1]))\n",
        "            level_downsamples.append(estimated_downsample) if estimated_downsample != (downsample, downsample) else level_downsamples.append((downsample, downsample))\n",
        "        \n",
        "        return level_downsamples\n",
        "\n",
        "    def process_contours(self, save_path, patch_level=0, patch_size=256, step_size=256, **kwargs):\n",
        "        save_path_hdf5 = os.path.join(save_path, str(self.name) + '.h5')\n",
        "        print(\"Creating patches for: \", self.name, \"...\",)\n",
        "        elapsed = time.time()\n",
        "        n_contours = len(self.contours_tissue)\n",
        "        print(\"Total number of contours to process: \", n_contours)\n",
        "        fp_chunk_size = math.ceil(n_contours * 0.05)\n",
        "        init = True\n",
        "        for idx, cont in enumerate(self.contours_tissue):\n",
        "            if (idx + 1) % fp_chunk_size == fp_chunk_size:\n",
        "                print('Processing contour {}/{}'.format(idx, n_contours))\n",
        "            \n",
        "            asset_dict, attr_dict = self.process_contour(cont, self.holes_tissue[idx], patch_level, save_path, patch_size, step_size, **kwargs)\n",
        "            if len(asset_dict) > 0:\n",
        "                if init:\n",
        "                    save_hdf5(save_path_hdf5, asset_dict, attr_dict, mode='w')\n",
        "                    init = False\n",
        "                else:\n",
        "                    save_hdf5(save_path_hdf5, asset_dict, mode='a')\n",
        "\n",
        "        return self.hdf5_file\n",
        "\n",
        "\n",
        "    def process_contour(self, cont, contour_holes, patch_level, save_path, patch_size = 256, step_size = 256,\n",
        "        contour_fn='four_pt', use_padding=True, top_left=None, bot_right=None):\n",
        "        start_x, start_y, w, h = cv2.boundingRect(cont) if cont is not None else (0, 0, self.level_dim[patch_level][0], self.level_dim[patch_level][1])\n",
        "\n",
        "        patch_downsample = (int(self.level_downsamples[patch_level][0]), int(self.level_downsamples[patch_level][1]))\n",
        "        ref_patch_size = (patch_size*patch_downsample[0], patch_size*patch_downsample[1])\n",
        "        \n",
        "        img_w, img_h = self.level_dim[0]\n",
        "        if use_padding:\n",
        "            stop_y = start_y+h\n",
        "            stop_x = start_x+w\n",
        "        else:\n",
        "            stop_y = min(start_y+h, img_h-ref_patch_size[1]+1)\n",
        "            stop_x = min(start_x+w, img_w-ref_patch_size[0]+1)\n",
        "        \n",
        "        print(\"Bounding Box:\", start_x, start_y, w, h)\n",
        "        print(\"Contour Area:\", cv2.contourArea(cont))\n",
        "\n",
        "        if bot_right is not None:\n",
        "            stop_y = min(bot_right[1], stop_y)\n",
        "            stop_x = min(bot_right[0], stop_x)\n",
        "        if top_left is not None:\n",
        "            start_y = max(top_left[1], start_y)\n",
        "            start_x = max(top_left[0], start_x)\n",
        "\n",
        "        if bot_right is not None or top_left is not None:\n",
        "            w, h = stop_x - start_x, stop_y - start_y\n",
        "            if w <= 0 or h <= 0:\n",
        "                print(\"Contour is not in specified ROI, skip\")\n",
        "                return {}, {}\n",
        "            else:\n",
        "                print(\"Adjusted Bounding Box:\", start_x, start_y, w, h)\n",
        "    \n",
        "        if isinstance(contour_fn, str):\n",
        "            if contour_fn == 'four_pt':\n",
        "                cont_check_fn = isInContourV3_Easy(contour=cont, patch_size=ref_patch_size[0], center_shift=0.5)\n",
        "            elif contour_fn == 'four_pt_hard':\n",
        "                cont_check_fn = isInContourV3_Hard(contour=cont, patch_size=ref_patch_size[0], center_shift=0.5)\n",
        "            elif contour_fn == 'center':\n",
        "                cont_check_fn = isInContourV2(contour=cont, patch_size=ref_patch_size[0])\n",
        "            elif contour_fn == 'basic':\n",
        "                cont_check_fn = isInContourV1(contour=cont)\n",
        "            else:\n",
        "                raise NotImplementedError\n",
        "        else:\n",
        "            assert isinstance(contour_fn, Contour_Checking_fn)\n",
        "            cont_check_fn = contour_fn\n",
        "\n",
        "        \n",
        "        step_size_x = step_size * patch_downsample[0]\n",
        "        step_size_y = step_size * patch_downsample[1]\n",
        "\n",
        "        x_range = np.arange(start_x, stop_x, step=step_size_x)\n",
        "        y_range = np.arange(start_y, stop_y, step=step_size_y)\n",
        "        x_coords, y_coords = np.meshgrid(x_range, y_range, indexing='ij')\n",
        "        coord_candidates = np.array([x_coords.flatten(), y_coords.flatten()]).transpose()\n",
        "\n",
        "        num_workers = mp.cpu_count()\n",
        "        if num_workers > 4:\n",
        "            num_workers = 4\n",
        "        pool = mp.Pool(num_workers)\n",
        "\n",
        "        iterable = [(coord, contour_holes, ref_patch_size[0], cont_check_fn) for coord in coord_candidates]\n",
        "        results = pool.starmap(WholeSlideImage.process_coord_candidate, iterable)\n",
        "        pool.close()\n",
        "        results = np.array([result for result in results if result is not None])\n",
        "        \n",
        "        print('Extracted {} coordinates'.format(len(results)))\n",
        "\n",
        "        if len(results)>1:\n",
        "            asset_dict = {'coords' :          results}\n",
        "            \n",
        "            attr = {'patch_size' :            patch_size, # To be considered...\n",
        "                    'patch_level' :           patch_level,\n",
        "                    'downsample':             self.level_downsamples[patch_level],\n",
        "                    'downsampled_level_dim' : tuple(np.array(self.level_dim[patch_level])),\n",
        "                    'level_dim':              self.level_dim[patch_level],\n",
        "                    'name':                   self.name,\n",
        "                    'save_path':              save_path}\n",
        "\n",
        "            attr_dict = { 'coords' : attr}\n",
        "            return asset_dict, attr_dict\n",
        "\n",
        "        else:\n",
        "            return {}, {}\n",
        "\n",
        "    @staticmethod\n",
        "    def process_coord_candidate(coord, contour_holes, ref_patch_size, cont_check_fn):\n",
        "        if WholeSlideImage.isInContours(cont_check_fn, coord, contour_holes, ref_patch_size):\n",
        "            return coord\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    def visHeatmap(self, scores, coords, vis_level=-1, \n",
        "                   top_left=None, bot_right=None,\n",
        "                   patch_size=(256, 256), \n",
        "                   blank_canvas=False, canvas_color=(220, 20, 50), alpha=0.4, \n",
        "                   blur=False, overlap=0.0, \n",
        "                   segment=True, use_holes=True,\n",
        "                   convert_to_percentiles=False, \n",
        "                   binarize=False, thresh=0.5,\n",
        "                   max_size=None,\n",
        "                   custom_downsample = 1,\n",
        "                   cmap='coolwarm'):\n",
        "\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            scores (numpy array of float): Attention scores \n",
        "            coords (numpy array of int, n_patches x 2): Corresponding coordinates (relative to lvl 0)\n",
        "            vis_level (int): WSI pyramid level to visualize\n",
        "            patch_size (tuple of int): Patch dimensions (relative to lvl 0)\n",
        "            blank_canvas (bool): Whether to use a blank canvas to draw the heatmap (vs. using the original slide)\n",
        "            canvas_color (tuple of uint8): Canvas color\n",
        "            alpha (float [0, 1]): blending coefficient for overlaying heatmap onto original slide\n",
        "            blur (bool): apply gaussian blurring\n",
        "            overlap (float [0 1]): percentage of overlap between neighboring patches (only affect radius of blurring)\n",
        "            segment (bool): whether to use tissue segmentation contour (must have already called self.segmentTissue such that \n",
        "                            self.contours_tissue and self.holes_tissue are not None\n",
        "            use_holes (bool): whether to also clip out detected tissue cavities (only in effect when segment == True)\n",
        "            convert_to_percentiles (bool): whether to convert attention scores to percentiles\n",
        "            binarize (bool): only display patches > threshold\n",
        "            threshold (float): binarization threshold\n",
        "            max_size (int): Maximum canvas size (clip if goes over)\n",
        "            custom_downsample (int): additionally downscale the heatmap by specified factor\n",
        "            cmap (str): name of matplotlib colormap to use\n",
        "        \"\"\"\n",
        "\n",
        "        if vis_level < 0:\n",
        "            vis_level = self.wsi.get_best_level_for_downsample(32)\n",
        "\n",
        "        downsample = self.level_downsamples[vis_level]\n",
        "        scale = [1/downsample[0], 1/downsample[1]] # Scaling from 0 to desired level\n",
        "                \n",
        "        if len(scores.shape) == 2:\n",
        "            scores = scores.flatten()\n",
        "\n",
        "        if binarize:\n",
        "            if thresh < 0:\n",
        "                threshold = 1.0/len(scores)\n",
        "                \n",
        "            else:\n",
        "                threshold =  thresh\n",
        "        \n",
        "        else:\n",
        "            threshold = 0.0\n",
        "\n",
        "        ##### calculate size of heatmap and filter coordinates/scores outside specified bbox region #####\n",
        "        if top_left is not None and bot_right is not None:\n",
        "            scores, coords = screen_coords(scores, coords, top_left, bot_right)\n",
        "            coords = coords - top_left\n",
        "            top_left = tuple(top_left)\n",
        "            bot_right = tuple(bot_right)\n",
        "            w, h = tuple((np.array(bot_right) * scale).astype(int) - (np.array(top_left) * scale).astype(int))\n",
        "            region_size = (w, h)\n",
        "\n",
        "        else:\n",
        "            region_size = self.level_dim[vis_level]\n",
        "            top_left = (0,0)\n",
        "            bot_right = self.level_dim[0]\n",
        "            w, h = region_size\n",
        "\n",
        "        patch_size  = np.ceil(np.array(patch_size) * np.array(scale)).astype(int)\n",
        "        coords = np.ceil(coords * np.array(scale)).astype(int)\n",
        "        \n",
        "        print('\\ncreating heatmap for: ')\n",
        "        print('top_left: ', top_left, 'bot_right: ', bot_right)\n",
        "        print('w: {}, h: {}'.format(w, h))\n",
        "        print('scaled patch size: ', patch_size)\n",
        "\n",
        "        ###### normalize filtered scores ######\n",
        "        if convert_to_percentiles:\n",
        "            scores = to_percentiles(scores) \n",
        "\n",
        "        scores /= 100\n",
        "        \n",
        "        ######## calculate the heatmap of raw attention scores (before colormap) \n",
        "        # by accumulating scores over overlapped regions ######\n",
        "        \n",
        "        # heatmap overlay: tracks attention score over each pixel of heatmap\n",
        "        # overlay counter: tracks how many times attention score is accumulated over each pixel of heatmap\n",
        "        overlay = np.full(np.flip(region_size), 0).astype(float)\n",
        "        counter = np.full(np.flip(region_size), 0).astype(np.uint16)      \n",
        "        count = 0\n",
        "        for idx in range(len(coords)):\n",
        "            score = scores[idx]\n",
        "            coord = coords[idx]\n",
        "            if score >= threshold:\n",
        "                if binarize:\n",
        "                    score=1.0\n",
        "                    count+=1\n",
        "            else:\n",
        "                score=0.0\n",
        "            # accumulate attention\n",
        "            overlay[coord[1]:coord[1]+patch_size[1], coord[0]:coord[0]+patch_size[0]] += score\n",
        "            # accumulate counter\n",
        "            counter[coord[1]:coord[1]+patch_size[1], coord[0]:coord[0]+patch_size[0]] += 1\n",
        "\n",
        "        if binarize:\n",
        "            print('\\nbinarized tiles based on cutoff of {}'.format(threshold))\n",
        "            print('identified {}/{} patches as positive'.format(count, len(coords)))\n",
        "        \n",
        "        # fetch attended region and average accumulated attention\n",
        "        zero_mask = counter == 0\n",
        "\n",
        "        if binarize:\n",
        "            overlay[~zero_mask] = np.around(overlay[~zero_mask] / counter[~zero_mask])\n",
        "        else:\n",
        "            overlay[~zero_mask] = overlay[~zero_mask] / counter[~zero_mask]\n",
        "        del counter \n",
        "        if blur:\n",
        "            overlay = cv2.GaussianBlur(overlay,tuple((patch_size * (1-overlap)).astype(int) * 2 +1),0)  \n",
        "\n",
        "        if segment:\n",
        "            tissue_mask = self.get_seg_mask(region_size, scale, use_holes=use_holes, offset=tuple(top_left))\n",
        "            # return Image.fromarray(tissue_mask) # tissue mask\n",
        "        \n",
        "        if not blank_canvas:\n",
        "            # downsample original image and use as canvas\n",
        "            img = np.array(self.wsi.read_region(top_left, vis_level, region_size).convert(\"RGB\"))\n",
        "        else:\n",
        "            # use blank canvas\n",
        "            img = np.array(Image.new(size=region_size, mode=\"RGB\", color=(255,255,255))) \n",
        "\n",
        "        #return Image.fromarray(img) #raw image\n",
        "\n",
        "        print('\\ncomputing heatmap image')\n",
        "        print('total of {} patches'.format(len(coords)))\n",
        "        twenty_percent_chunk = max(1, int(len(coords) * 0.2))\n",
        "\n",
        "        if isinstance(cmap, str):\n",
        "            cmap = plt.get_cmap(cmap)\n",
        "        \n",
        "        for idx in range(len(coords)):\n",
        "            if (idx + 1) % twenty_percent_chunk == 0:\n",
        "                print('progress: {}/{}'.format(idx, len(coords)))\n",
        "            \n",
        "            score = scores[idx]\n",
        "            coord = coords[idx]\n",
        "            if score >= threshold:\n",
        "\n",
        "                # attention block\n",
        "                raw_block = overlay[coord[1]:coord[1]+patch_size[1], coord[0]:coord[0]+patch_size[0]]\n",
        "                \n",
        "                # image block (either blank canvas or orig image)\n",
        "                img_block = img[coord[1]:coord[1]+patch_size[1], coord[0]:coord[0]+patch_size[0]].copy()\n",
        "\n",
        "                # color block (cmap applied to attention block)\n",
        "                color_block = (cmap(raw_block) * 255)[:,:,:3].astype(np.uint8)\n",
        "\n",
        "                if segment:\n",
        "                    # tissue mask block\n",
        "                    mask_block = tissue_mask[coord[1]:coord[1]+patch_size[1], coord[0]:coord[0]+patch_size[0]] \n",
        "                    # copy over only tissue masked portion of color block\n",
        "                    img_block[mask_block] = color_block[mask_block]\n",
        "                else:\n",
        "                    # copy over entire color block\n",
        "                    img_block = color_block\n",
        "\n",
        "                # rewrite image block\n",
        "                img[coord[1]:coord[1]+patch_size[1], coord[0]:coord[0]+patch_size[0]] = img_block.copy()\n",
        "        \n",
        "        #return Image.fromarray(img) #overlay\n",
        "        print('Done')\n",
        "        del overlay\n",
        "\n",
        "        if blur:\n",
        "            img = cv2.GaussianBlur(img,tuple((patch_size * (1-overlap)).astype(int) * 2 +1),0)  \n",
        "\n",
        "        if alpha < 1.0:\n",
        "            img = self.block_blending(img, vis_level, top_left, bot_right, alpha=alpha, blank_canvas=blank_canvas, block_size=1024)\n",
        "        \n",
        "        img = Image.fromarray(img)\n",
        "        w, h = img.size\n",
        "\n",
        "        if custom_downsample > 1:\n",
        "            img = img.resize((int(w/custom_downsample), int(h/custom_downsample)))\n",
        "\n",
        "        if max_size is not None and (w > max_size or h > max_size):\n",
        "            resizeFactor = max_size/w if w > h else max_size/h\n",
        "            img = img.resize((int(w*resizeFactor), int(h*resizeFactor)))\n",
        "       \n",
        "        return img\n",
        "\n",
        "    \n",
        "    def block_blending(self, img, vis_level, top_left, bot_right, alpha=0.5, blank_canvas=False, block_size=1024):\n",
        "        print('\\ncomputing blend')\n",
        "        downsample = self.level_downsamples[vis_level]\n",
        "        w = img.shape[1]\n",
        "        h = img.shape[0]\n",
        "        block_size_x = min(block_size, w)\n",
        "        block_size_y = min(block_size, h)\n",
        "        print('using block size: {} x {}'.format(block_size_x, block_size_y))\n",
        "\n",
        "        shift = top_left # amount shifted w.r.t. (0,0)\n",
        "        for x_start in range(top_left[0], bot_right[0], block_size_x * int(downsample[0])):\n",
        "            for y_start in range(top_left[1], bot_right[1], block_size_y * int(downsample[1])):\n",
        "                #print(x_start, y_start)\n",
        "\n",
        "                # 1. convert wsi coordinates to image coordinates via shift and scale\n",
        "                x_start_img = int((x_start - shift[0]) / int(downsample[0]))\n",
        "                y_start_img = int((y_start - shift[1]) / int(downsample[1]))\n",
        "                \n",
        "                # 2. compute end points of blend tile, careful not to go over the edge of the image\n",
        "                y_end_img = min(h, y_start_img+block_size_y)\n",
        "                x_end_img = min(w, x_start_img+block_size_x)\n",
        "\n",
        "                if y_end_img == y_start_img or x_end_img == x_start_img:\n",
        "                    continue\n",
        "                #print('start_coord: {} end_coord: {}'.format((x_start_img, y_start_img), (x_end_img, y_end_img)))\n",
        "                \n",
        "                # 3. fetch blend block and size\n",
        "                blend_block = img[y_start_img:y_end_img, x_start_img:x_end_img] \n",
        "                blend_block_size = (x_end_img-x_start_img, y_end_img-y_start_img)\n",
        "                \n",
        "                if not blank_canvas:\n",
        "                    # 4. read actual wsi block as canvas block\n",
        "                    pt = (x_start, y_start)\n",
        "                    canvas = np.array(self.wsi.read_region(pt, vis_level, blend_block_size).convert(\"RGB\"))     \n",
        "                else:\n",
        "                    # 4. OR create blank canvas block\n",
        "                    canvas = np.array(Image.new(size=blend_block_size, mode=\"RGB\", color=(255,255,255)))\n",
        "\n",
        "                # 5. blend color block and canvas block\n",
        "                img[y_start_img:y_end_img, x_start_img:x_end_img] = cv2.addWeighted(blend_block, alpha, canvas, 1 - alpha, 0, canvas)\n",
        "        return img\n",
        "\n",
        "    def get_seg_mask(self, region_size, scale, use_holes=False, offset=(0,0)):\n",
        "        print('\\ncomputing foreground tissue mask')\n",
        "        tissue_mask = np.full(np.flip(region_size), 0).astype(np.uint8)\n",
        "        contours_tissue = self.scaleContourDim(self.contours_tissue, scale)\n",
        "        offset = tuple((np.array(offset) * np.array(scale) * -1).astype(np.int32))\n",
        "\n",
        "        contours_holes = self.scaleHolesDim(self.holes_tissue, scale)\n",
        "        contours_tissue, contours_holes = zip(*sorted(zip(contours_tissue, contours_holes), key=lambda x: cv2.contourArea(x[0]), reverse=True))\n",
        "        for idx in range(len(contours_tissue)):\n",
        "            cv2.drawContours(image=tissue_mask, contours=contours_tissue, contourIdx=idx, color=(1), offset=offset, thickness=-1)\n",
        "\n",
        "            if use_holes:\n",
        "                cv2.drawContours(image=tissue_mask, contours=contours_holes[idx], contourIdx=-1, color=(0), offset=offset, thickness=-1)\n",
        "            # contours_holes = self._scaleContourDim(self.holes_tissue, scale, holes=True, area_thresh=area_thresh)\n",
        "                \n",
        "        tissue_mask = tissue_mask.astype(bool)\n",
        "        print('detected {}/{} of region as tissue'.format(tissue_mask.sum(), tissue_mask.size))\n",
        "        return tissue_mask"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldkOr4bQHXo3"
      },
      "source": [
        "def stitching(file_path, wsi_object, downscale=64):\n",
        "  start = time.time()\n",
        "  heatmap = StitchCoords(\n",
        "      file_path,\n",
        "      wsi_object,\n",
        "      downscale=downscale,\n",
        "      bg_color=(0, 0, 0),\n",
        "      alpha=-1,\n",
        "      draw_grid=False,\n",
        "  )\n",
        "  total_time = time.time() - start\n",
        "\n",
        "  return heatmap, total_time\n",
        "\n",
        "\n",
        "def segment(WSI_object, seg_params, filter_params):\n",
        "  ### Start Seg Timer\n",
        "  start_time = time.time()\n",
        "\n",
        "  # Segment\n",
        "  WSI_object.segmentTissue(**seg_params, filter_params=filter_params)\n",
        "\n",
        "  ### Stop Seg Timers\n",
        "  seg_time_elapsed = time.time() - start_time\n",
        "  return WSI_object, seg_time_elapsed\n",
        "\n",
        "\n",
        "def patching(WSI_object, **kwargs):\n",
        "  ### Start Patch Timer\n",
        "  start_time = time.time()\n",
        "\n",
        "  # Patch\n",
        "  file_path = WSI_object.process_contours(**kwargs)\n",
        "\n",
        "  ### Stop Patch Timer\n",
        "  patch_time_elapsed = time.time() - start_time\n",
        "  return file_path, patch_time_elapsed\n",
        "\n",
        "\n",
        "def seg_and_patch(source, save_dir, patch_save_dir, mask_save_dir, stitch_save_dir, \n",
        "\t\t\t\t  patch_size = 256, step_size = 256, \n",
        "\t\t\t\t  seg_params = {'seg_level': -1, 'sthresh': 8, 'mthresh': 7, 'close': 4, 'use_otsu': False,\n",
        "\t\t\t\t  'keep_ids': 'none', 'exclude_ids': 'none'},\n",
        "\t\t\t\t  filter_params = {'a_t':100, 'a_h': 16, 'max_n_holes':8}, \n",
        "\t\t\t\t  vis_params = {'vis_level': -1, 'line_thickness': 500},\n",
        "\t\t\t\t  patch_params = {'use_padding': True, 'contour_fn': 'four_pt'},\n",
        "\t\t\t\t  patch_level = 0,\n",
        "\t\t\t\t  use_default_params = False, \n",
        "\t\t\t\t  seg = True, save_mask = True, \n",
        "\t\t\t\t  stitch= True, \n",
        "\t\t\t\t  patch = True, auto_skip=True, process_list = None):\n",
        "\t\n",
        "\n",
        "\n",
        "\tslides = sorted(os.listdir(source))\n",
        "\tslides = [slide for slide in slides if os.path.isfile(os.path.join(source, slide))]\n",
        "\tif process_list is None:\n",
        "\t\tdf = initialize_df(slides, seg_params, filter_params, vis_params, patch_params)\n",
        "\t\n",
        "\telse:\n",
        "\t\tdf = pd.read_csv(process_list)\n",
        "\t\tdf = initialize_df(df, seg_params, filter_params, vis_params, patch_params)\n",
        "\n",
        "\tmask = df['process'] == 1\n",
        "\tprocess_stack = df[mask]\n",
        "\n",
        "\ttotal = len(process_stack)\n",
        "\n",
        "\tlegacy_support = 'a' in df.keys()\n",
        "\tif legacy_support:\n",
        "\t\tprint('detected legacy segmentation csv file, legacy support enabled')\n",
        "\t\tdf = df.assign(**{'a_t': np.full((len(df)), int(filter_params['a_t']), dtype=np.uint32),\n",
        "\t\t'a_h': np.full((len(df)), int(filter_params['a_h']), dtype=np.uint32),\n",
        "\t\t'max_n_holes': np.full((len(df)), int(filter_params['max_n_holes']), dtype=np.uint32),\n",
        "\t\t'line_thickness': np.full((len(df)), int(vis_params['line_thickness']), dtype=np.uint32),\n",
        "\t\t'contour_fn': np.full((len(df)), patch_params['contour_fn'])})\n",
        "\n",
        "\tseg_times = 0.\n",
        "\tpatch_times = 0.\n",
        "\tstitch_times = 0.\n",
        "\n",
        "\tfor i in range(total):\n",
        "\t\tdf.to_csv(os.path.join(save_dir, 'process_list_autogen.csv'), index=False)\n",
        "\t\tidx = process_stack.index[i]\n",
        "\t\tslide = process_stack.loc[idx, 'slide_id']\n",
        "\t\tprint(\"\\n\\nprogress: {:.2f}, {}/{}\".format(i/total, i, total))\n",
        "\t\tprint('processing {}'.format(slide))\n",
        "\t\t\n",
        "\t\tdf.loc[idx, 'process'] = 0\n",
        "\t\tslide_id, _ = os.path.splitext(slide)\n",
        "\n",
        "\t\tif auto_skip and os.path.isfile(os.path.join(patch_save_dir, slide_id + '.h5')):\n",
        "\t\t\tprint('{} already exist in destination location, skipped'.format(slide_id))\n",
        "\t\t\tdf.loc[idx, 'status'] = 'already_exist'\n",
        "\t\t\tcontinue\n",
        "\n",
        "\t\t# Inialize WSI\n",
        "\t\tfull_path = os.path.join(source, slide)\n",
        "\t\tWSI_object = WholeSlideImage(full_path)\n",
        "\n",
        "\t\tif use_default_params:\n",
        "\t\t\tcurrent_vis_params = vis_params.copy()\n",
        "\t\t\tcurrent_filter_params = filter_params.copy()\n",
        "\t\t\tcurrent_seg_params = seg_params.copy()\n",
        "\t\t\tcurrent_patch_params = patch_params.copy()\n",
        "\t\t\t\n",
        "\t\telse:\n",
        "\t\t\tcurrent_vis_params = {}\n",
        "\t\t\tcurrent_filter_params = {}\n",
        "\t\t\tcurrent_seg_params = {}\n",
        "\t\t\tcurrent_patch_params = {}\n",
        "\n",
        "\n",
        "\t\t\tfor key in vis_params.keys():\n",
        "\t\t\t\tif legacy_support and key == 'vis_level':\n",
        "\t\t\t\t\tdf.loc[idx, key] = -1\n",
        "\t\t\t\tcurrent_vis_params.update({key: df.loc[idx, key]})\n",
        "\n",
        "\t\t\tfor key in filter_params.keys():\n",
        "\t\t\t\tif legacy_support and key == 'a_t':\n",
        "\t\t\t\t\told_area = df.loc[idx, 'a']\n",
        "\t\t\t\t\tseg_level = df.loc[idx, 'seg_level']\n",
        "\t\t\t\t\tscale = WSI_object.level_downsamples[seg_level]\n",
        "\t\t\t\t\tadjusted_area = int(old_area * (scale[0] * scale[1]) / (512 * 512))\n",
        "\t\t\t\t\tcurrent_filter_params.update({key: adjusted_area})\n",
        "\t\t\t\t\tdf.loc[idx, key] = adjusted_area\n",
        "\t\t\t\tcurrent_filter_params.update({key: df.loc[idx, key]})\n",
        "\n",
        "\t\t\tfor key in seg_params.keys():\n",
        "\t\t\t\tif legacy_support and key == 'seg_level':\n",
        "\t\t\t\t\tdf.loc[idx, key] = -1\n",
        "\t\t\t\tcurrent_seg_params.update({key: df.loc[idx, key]})\n",
        "\n",
        "\t\t\tfor key in patch_params.keys():\n",
        "\t\t\t\tcurrent_patch_params.update({key: df.loc[idx, key]})\n",
        "\n",
        "\t\tif current_vis_params['vis_level'] < 0:\n",
        "\t\t\tif len(WSI_object.level_dim) == 1:\n",
        "\t\t\t\tcurrent_vis_params['vis_level'] = 0\n",
        "\t\t\t\n",
        "\t\t\telse:\t\n",
        "\t\t\t\twsi = WSI_object.getOpenSlide()\n",
        "\t\t\t\tbest_level = wsi.get_best_level_for_downsample(64)\n",
        "\t\t\t\tcurrent_vis_params['vis_level'] = best_level\n",
        "\n",
        "\t\tif current_seg_params['seg_level'] < 0:\n",
        "\t\t\tif len(WSI_object.level_dim) == 1:\n",
        "\t\t\t\tcurrent_seg_params['seg_level'] = 0\n",
        "\t\t\t\n",
        "\t\t\telse:\n",
        "\t\t\t\twsi = WSI_object.getOpenSlide()\n",
        "\t\t\t\tbest_level = wsi.get_best_level_for_downsample(64)\n",
        "\t\t\t\tcurrent_seg_params['seg_level'] = best_level\n",
        "\n",
        "\t\tkeep_ids = str(current_seg_params['keep_ids'])\n",
        "\t\tif keep_ids != 'none' and len(keep_ids) > 0:\n",
        "\t\t\tstr_ids = current_seg_params['keep_ids']\n",
        "\t\t\tcurrent_seg_params['keep_ids'] = np.array(str_ids.split(',')).astype(int)\n",
        "\t\telse:\n",
        "\t\t\tcurrent_seg_params['keep_ids'] = []\n",
        "\n",
        "\t\texclude_ids = str(current_seg_params['exclude_ids'])\n",
        "\t\tif exclude_ids != 'none' and len(exclude_ids) > 0:\n",
        "\t\t\tstr_ids = current_seg_params['exclude_ids']\n",
        "\t\t\tcurrent_seg_params['exclude_ids'] = np.array(str_ids.split(',')).astype(int)\n",
        "\t\telse:\n",
        "\t\t\tcurrent_seg_params['exclude_ids'] = []\n",
        "\n",
        "\t\tw, h = WSI_object.level_dim[current_seg_params['seg_level']] \n",
        "\t\tif w * h > 1e15:\n",
        "\t\t\tprint('level_dim {} x {} is likely too large for successful segmentation, aborting'.format(w, h))\n",
        "\t\t\tdf.loc[idx, 'status'] = 'failed_seg'\n",
        "\t\t\tcontinue\n",
        "\n",
        "\t\tdf.loc[idx, 'vis_level'] = current_vis_params['vis_level']\n",
        "\t\tdf.loc[idx, 'seg_level'] = current_seg_params['seg_level']\n",
        "\n",
        "\n",
        "\t\tseg_time_elapsed = -1\n",
        "\t\tif seg:\n",
        "\t\t\tWSI_object, seg_time_elapsed = segment(WSI_object, current_seg_params, current_filter_params) \n",
        "\n",
        "\t\tif save_mask:\n",
        "\t\t\tmask = WSI_object.visWSI(**current_vis_params)\n",
        "\t\t\tmask_path = os.path.join(mask_save_dir, slide_id+'.jpg')\n",
        "\t\t\tmask.save(mask_path)\n",
        "\n",
        "\t\tpatch_time_elapsed = -1 # Default time\n",
        "\t\tif patch:\n",
        "\t\t\tcurrent_patch_params.update({'patch_level': patch_level, 'patch_size': patch_size, 'step_size': step_size, \n",
        "\t\t\t\t\t\t\t\t\t\t 'save_path': patch_save_dir})\n",
        "\t\t\tfile_path, patch_time_elapsed = patching(WSI_object = WSI_object,  **current_patch_params,)\n",
        "\t\t\n",
        "\t\tstitch_time_elapsed = -1\n",
        "\t\tif stitch:\n",
        "\t\t\tfile_path = os.path.join(patch_save_dir, slide_id+'.h5')\n",
        "\t\t\tif os.path.isfile(file_path):\n",
        "\t\t\t\theatmap, stitch_time_elapsed = stitching(file_path, WSI_object, downscale=64)\n",
        "\t\t\t\tstitch_path = os.path.join(stitch_save_dir, slide_id+'.jpg')\n",
        "\t\t\t\theatmap.save(stitch_path)\n",
        "\n",
        "\t\tprint(\"segmentation took {} seconds\".format(seg_time_elapsed))\n",
        "\t\tprint(\"patching took {} seconds\".format(patch_time_elapsed))\n",
        "\t\tprint(\"stitching took {} seconds\".format(stitch_time_elapsed))\n",
        "\t\tdf.loc[idx, 'status'] = 'processed'\n",
        "\n",
        "\t\tseg_times += seg_time_elapsed\n",
        "\t\tpatch_times += patch_time_elapsed\n",
        "\t\tstitch_times += stitch_time_elapsed\n",
        "\n",
        "\tseg_times /= total\n",
        "\tpatch_times /= total\n",
        "\tstitch_times /= total\n",
        "\n",
        "\tdf.to_csv(os.path.join(save_dir, 'process_list_autogen.csv'), index=False)\n",
        "\tprint(\"average segmentation time in s per slide: {}\".format(seg_times))\n",
        "\tprint(\"average patching time in s per slide: {}\".format(patch_times))\n",
        "\tprint(\"average stiching time in s per slide: {}\".format(stitch_times))\n",
        "\t\t\n",
        "\treturn seg_times, patch_times"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VS_HkJ6HcYL",
        "outputId": "5454b0c6-9274-43ab-8585-36412838699e"
      },
      "source": [
        "# 'gdrive/My Drive/Data_Directory'\n",
        "source = 'gdrive/My Drive/Regions'\n",
        "save_dir = 'gdrive/My Drive/RESULTS_DIRECTORY'\n",
        "#process_list = 'gdrive/My Drive/RESULTS_DIRECTORY/bwh_biopsy.csv'\n",
        "patch_save_dir = os.path.join(save_dir, 'patches') #  \n",
        "mask_save_dir = os.path.join(save_dir, 'masks')\n",
        "stitch_save_dir = os.path.join(save_dir, 'stiches')\n",
        "\n",
        "directories = {'source': source, \n",
        "\t\t\t\t   'save_dir': save_dir,\n",
        "\t\t\t\t   'patch_save_dir': patch_save_dir, \n",
        "\t\t\t\t   'mask_save_dir' : mask_save_dir, \n",
        "\t\t\t\t   'stitch_save_dir': stitch_save_dir} \n",
        "\n",
        "for key, val in directories.items():\n",
        "\t\tprint(\"{} : {}\".format(key, val))\n",
        "\t\tif key not in ['source']:\n",
        "\t\t\tos.makedirs(val, exist_ok=True)\n",
        "   \n",
        "seg_params = {'seg_level': -1, 'sthresh': 15, 'mthresh': 11, 'close': 2, 'use_otsu': False,'keep_ids': 'none', 'exclude_ids': 'none'}\n",
        "filter_params = {'a_t':1, 'a_h': 1, 'max_n_holes':2}\n",
        "vis_params = {'vis_level': -1, 'line_thickness': 50}\n",
        "patch_params = {'use_padding': True, 'contour_fn': 'four_pt',} # four_pt_hard\n",
        "parameters = {'seg_params': seg_params,\n",
        "\t\t\t\t      'filter_params': filter_params,\n",
        "\t \t\t\t      'patch_params': patch_params,\n",
        "\t\t\t\t      'vis_params': vis_params}"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "source : gdrive/My Drive/Regions\n",
            "save_dir : gdrive/My Drive/RESULTS_DIRECTORY\n",
            "patch_save_dir : gdrive/My Drive/RESULTS_DIRECTORY/patches\n",
            "mask_save_dir : gdrive/My Drive/RESULTS_DIRECTORY/masks\n",
            "stitch_save_dir : gdrive/My Drive/RESULTS_DIRECTORY/stiches\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmi4KD8WbMh5"
      },
      "source": [
        "**Step 1**\n",
        "Run only segmentation with preset(process list) as bwh_biopsy.csv."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OogGRKwCPAdi",
        "outputId": "37221810-6d3e-4ddc-a4bd-5367a9ed9a81"
      },
      "source": [
        "patch_size = 256\n",
        "step_size = 256\n",
        "seg = True\n",
        "stitch = True\n",
        "patch  = True\n",
        "patch_level = 0\n",
        "no_auto_skip = True\n",
        "process_list = None\n",
        "seg_times, patch_times = seg_and_patch(**directories, **parameters,\n",
        "\t\t\t\t\t\t\t\t\t\t\tpatch_size = patch_size, step_size=step_size, \n",
        "\t\t\t\t\t\t\t\t\t\t\tseg = seg,  use_default_params=False, save_mask = True, \n",
        "\t\t\t\t\t\t\t\t\t\t\tstitch= stitch,\n",
        "\t\t\t\t\t\t\t\t\t\t\tpatch_level=patch_level, patch = patch,\n",
        "\t\t\t\t\t\t\t\t\t\t\tprocess_list = process_list, auto_skip=no_auto_skip)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "progress: 0.00, 0/8779\n",
            "processing CPM19_CBICA_AAB_1-0_0.tiff\n",
            "Name:CPM19_CBICA_AAB_1-0_0\n",
            "Creating patches for:  CPM19_CBICA_AAB_1-0_0 ...\n",
            "Total number of contours to process:  0\n",
            "segmentation took 1.5670390129089355 seconds\n",
            "patching took 0.003059864044189453 seconds\n",
            "stitching took -1 seconds\n",
            "\n",
            "\n",
            "progress: 0.00, 1/8779\n",
            "processing CPM19_CBICA_AAB_1-0_12000.tiff\n",
            "Name:CPM19_CBICA_AAB_1-0_12000\n",
            "Creating patches for:  CPM19_CBICA_AAB_1-0_12000 ...\n",
            "Total number of contours to process:  0\n",
            "segmentation took 2.0004377365112305 seconds\n",
            "patching took 0.001033782958984375 seconds\n",
            "stitching took -1 seconds\n",
            "\n",
            "\n",
            "progress: 0.00, 2/8779\n",
            "processing CPM19_CBICA_AAB_1-0_16000.tiff\n",
            "Name:CPM19_CBICA_AAB_1-0_16000\n",
            "Creating patches for:  CPM19_CBICA_AAB_1-0_16000 ...\n",
            "Total number of contours to process:  0\n",
            "segmentation took 2.2896862030029297 seconds\n",
            "patching took 0.0024101734161376953 seconds\n",
            "stitching took -1 seconds\n",
            "\n",
            "\n",
            "progress: 0.00, 3/8779\n",
            "processing CPM19_CBICA_AAB_1-0_20000.tiff\n",
            "Name:CPM19_CBICA_AAB_1-0_20000\n",
            "Creating patches for:  CPM19_CBICA_AAB_1-0_20000 ...\n",
            "Total number of contours to process:  0\n",
            "segmentation took 1.858208417892456 seconds\n",
            "patching took 0.001918792724609375 seconds\n",
            "stitching took -1 seconds\n",
            "\n",
            "\n",
            "progress: 0.00, 4/8779\n",
            "processing CPM19_CBICA_AAB_1-0_24000.tiff\n",
            "Name:CPM19_CBICA_AAB_1-0_24000\n",
            "Creating patches for:  CPM19_CBICA_AAB_1-0_24000 ...\n",
            "Total number of contours to process:  0\n",
            "segmentation took 1.060715675354004 seconds\n",
            "patching took 0.00029730796813964844 seconds\n",
            "stitching took -1 seconds\n",
            "\n",
            "\n",
            "progress: 0.00, 5/8779\n",
            "processing CPM19_CBICA_AAB_1-0_28000.tiff\n",
            "Name:CPM19_CBICA_AAB_1-0_28000\n",
            "Creating patches for:  CPM19_CBICA_AAB_1-0_28000 ...\n",
            "Total number of contours to process:  0\n",
            "segmentation took 1.8125922679901123 seconds\n",
            "patching took 0.002279996871948242 seconds\n",
            "stitching took -1 seconds\n",
            "\n",
            "\n",
            "progress: 0.00, 6/8779\n",
            "processing CPM19_CBICA_AAB_1-0_32000.tiff\n",
            "Name:CPM19_CBICA_AAB_1-0_32000\n",
            "Creating patches for:  CPM19_CBICA_AAB_1-0_32000 ...\n",
            "Total number of contours to process:  0\n",
            "segmentation took 2.0410778522491455 seconds\n",
            "patching took 0.0030260086059570312 seconds\n",
            "stitching took -1 seconds\n",
            "\n",
            "\n",
            "progress: 0.00, 7/8779\n",
            "processing CPM19_CBICA_AAB_1-0_36000.tiff\n",
            "Name:CPM19_CBICA_AAB_1-0_36000\n",
            "Creating patches for:  CPM19_CBICA_AAB_1-0_36000 ...\n",
            "Total number of contours to process:  0\n",
            "segmentation took 1.9197988510131836 seconds\n",
            "patching took 0.0032644271850585938 seconds\n",
            "stitching took -1 seconds\n",
            "\n",
            "\n",
            "progress: 0.00, 8/8779\n",
            "processing CPM19_CBICA_AAB_1-0_4000.tiff\n",
            "Name:CPM19_CBICA_AAB_1-0_4000\n",
            "Creating patches for:  CPM19_CBICA_AAB_1-0_4000 ...\n",
            "Total number of contours to process:  0\n",
            "segmentation took 1.812798261642456 seconds\n",
            "patching took 0.0025811195373535156 seconds\n",
            "stitching took -1 seconds\n",
            "\n",
            "\n",
            "progress: 0.00, 9/8779\n",
            "processing CPM19_CBICA_AAB_1-0_40000.tiff\n",
            "Name:CPM19_CBICA_AAB_1-0_40000\n",
            "Creating patches for:  CPM19_CBICA_AAB_1-0_40000 ...\n",
            "Total number of contours to process:  0\n",
            "segmentation took 1.5423545837402344 seconds\n",
            "patching took 0.0010609626770019531 seconds\n",
            "stitching took -1 seconds\n",
            "\n",
            "\n",
            "progress: 0.00, 10/8779\n",
            "processing CPM19_CBICA_AAB_1-0_44000.tiff\n",
            "Name:CPM19_CBICA_AAB_1-0_44000\n",
            "Creating patches for:  CPM19_CBICA_AAB_1-0_44000 ...\n",
            "Total number of contours to process:  0\n",
            "segmentation took 1.8481652736663818 seconds\n",
            "patching took 0.003148794174194336 seconds\n",
            "stitching took -1 seconds\n",
            "\n",
            "\n",
            "progress: 0.00, 11/8779\n",
            "processing CPM19_CBICA_AAB_1-0_48000.tiff\n",
            "Name:CPM19_CBICA_AAB_1-0_48000\n",
            "Creating patches for:  CPM19_CBICA_AAB_1-0_48000 ...\n",
            "Total number of contours to process:  0\n",
            "segmentation took 2.2783119678497314 seconds\n",
            "patching took 0.001073598861694336 seconds\n",
            "stitching took -1 seconds\n",
            "\n",
            "\n",
            "progress: 0.00, 12/8779\n",
            "processing CPM19_CBICA_AAB_1-0_52000.tiff\n",
            "Name:CPM19_CBICA_AAB_1-0_52000\n",
            "Creating patches for:  CPM19_CBICA_AAB_1-0_52000 ...\n",
            "Total number of contours to process:  0\n",
            "segmentation took 1.8322012424468994 seconds\n",
            "patching took 0.0025246143341064453 seconds\n",
            "stitching took -1 seconds\n",
            "\n",
            "\n",
            "progress: 0.00, 13/8779\n",
            "processing CPM19_CBICA_AAB_1-0_56000.tiff\n",
            "Name:CPM19_CBICA_AAB_1-0_56000\n",
            "Creating patches for:  CPM19_CBICA_AAB_1-0_56000 ...\n",
            "Total number of contours to process:  0\n",
            "segmentation took 1.8349063396453857 seconds\n",
            "patching took 0.0009810924530029297 seconds\n",
            "stitching took -1 seconds\n",
            "\n",
            "\n",
            "progress: 0.00, 14/8779\n",
            "processing CPM19_CBICA_AAB_1-0_60000.tiff\n",
            "Name:CPM19_CBICA_AAB_1-0_60000\n",
            "Creating patches for:  CPM19_CBICA_AAB_1-0_60000 ...\n",
            "Total number of contours to process:  0\n",
            "segmentation took 1.998478889465332 seconds\n",
            "patching took 0.001516580581665039 seconds\n",
            "stitching took -1 seconds\n",
            "\n",
            "\n",
            "progress: 0.00, 15/8779\n",
            "processing CPM19_CBICA_AAB_1-0_64000.tiff\n",
            "Name:CPM19_CBICA_AAB_1-0_64000\n",
            "Creating patches for:  CPM19_CBICA_AAB_1-0_64000 ...\n",
            "Total number of contours to process:  0\n",
            "segmentation took 1.976771354675293 seconds\n",
            "patching took 0.00031065940856933594 seconds\n",
            "stitching took -1 seconds\n",
            "\n",
            "\n",
            "progress: 0.00, 16/8779\n",
            "processing CPM19_CBICA_AAB_1-0_68000.tiff\n",
            "Name:CPM19_CBICA_AAB_1-0_68000\n",
            "Creating patches for:  CPM19_CBICA_AAB_1-0_68000 ...\n",
            "Total number of contours to process:  0\n",
            "segmentation took 1.939819097518921 seconds\n",
            "patching took 0.0012543201446533203 seconds\n",
            "stitching took -1 seconds\n",
            "\n",
            "\n",
            "progress: 0.00, 17/8779\n",
            "processing CPM19_CBICA_AAB_1-0_72000.tiff\n",
            "Name:CPM19_CBICA_AAB_1-0_72000\n",
            "Creating patches for:  CPM19_CBICA_AAB_1-0_72000 ...\n",
            "Total number of contours to process:  0\n",
            "segmentation took 2.088056802749634 seconds\n",
            "patching took 0.0015347003936767578 seconds\n",
            "stitching took -1 seconds\n",
            "\n",
            "\n",
            "progress: 0.00, 18/8779\n",
            "processing CPM19_CBICA_AAB_1-0_76000.tiff\n",
            "Name:CPM19_CBICA_AAB_1-0_76000\n",
            "Creating patches for:  CPM19_CBICA_AAB_1-0_76000 ...\n",
            "Total number of contours to process:  0\n",
            "segmentation took 2.328115224838257 seconds\n",
            "patching took 0.0011420249938964844 seconds\n",
            "stitching took -1 seconds\n",
            "\n",
            "\n",
            "progress: 0.00, 19/8779\n",
            "processing CPM19_CBICA_AAB_1-0_8000.tiff\n",
            "Name:CPM19_CBICA_AAB_1-0_8000\n",
            "Creating patches for:  CPM19_CBICA_AAB_1-0_8000 ...\n",
            "Total number of contours to process:  0\n",
            "segmentation took 1.771719217300415 seconds\n",
            "patching took 0.0013377666473388672 seconds\n",
            "stitching took -1 seconds\n",
            "\n",
            "\n",
            "progress: 0.00, 20/8779\n",
            "processing CPM19_CBICA_AAB_1-0_80000.tiff\n",
            "Name:CPM19_CBICA_AAB_1-0_80000\n",
            "Creating patches for:  CPM19_CBICA_AAB_1-0_80000 ...\n",
            "Total number of contours to process:  0\n",
            "segmentation took 1.402512788772583 seconds\n",
            "patching took 0.0026972293853759766 seconds\n",
            "stitching took -1 seconds\n",
            "\n",
            "\n",
            "progress: 0.00, 21/8779\n",
            "processing CPM19_CBICA_AAB_1-100000_0.tiff\n",
            "Name:CPM19_CBICA_AAB_1-100000_0\n",
            "Creating patches for:  CPM19_CBICA_AAB_1-100000_0 ...\n",
            "Total number of contours to process:  0\n",
            "segmentation took 1.9007704257965088 seconds\n",
            "patching took 0.0016889572143554688 seconds\n",
            "stitching took -1 seconds\n",
            "\n",
            "\n",
            "progress: 0.00, 22/8779\n",
            "processing CPM19_CBICA_AAB_1-100000_12000.tiff\n",
            "Name:CPM19_CBICA_AAB_1-100000_12000\n",
            "Creating patches for:  CPM19_CBICA_AAB_1-100000_12000 ...\n",
            "Total number of contours to process:  0\n",
            "segmentation took 1.4632337093353271 seconds\n",
            "patching took 0.0002942085266113281 seconds\n",
            "stitching took -1 seconds\n",
            "\n",
            "\n",
            "progress: 0.00, 23/8779\n",
            "processing CPM19_CBICA_AAB_1-100000_16000.tiff\n",
            "Name:CPM19_CBICA_AAB_1-100000_16000\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AxisError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36msqueeze\u001b[0;34m(a, axis)\u001b[0m\n\u001b[1;32m   1488\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1489\u001b[0;31m         \u001b[0msqueeze\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1490\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'squeeze'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-947d5f1a4737>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m                                                                                         \u001b[0mstitch\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mstitch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                                                                                         \u001b[0mpatch_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpatch_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \t\t\t\t\t\t\t\t\t\t\tprocess_list = process_list, auto_skip=no_auto_skip)\n\u001b[0m",
            "\u001b[0;32m<ipython-input-9-9976f2e3a037>\u001b[0m in \u001b[0;36mseg_and_patch\u001b[0;34m(source, save_dir, patch_save_dir, mask_save_dir, stitch_save_dir, patch_size, step_size, seg_params, filter_params, vis_params, patch_params, patch_level, use_default_params, seg, save_mask, stitch, patch, auto_skip, process_list)\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0mseg_time_elapsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mseg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                         \u001b[0mWSI_object\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseg_time_elapsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msegment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWSI_object\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_seg_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_filter_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msave_mask\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-9976f2e3a037>\u001b[0m in \u001b[0;36msegment\u001b[0;34m(WSI_object, seg_params, filter_params)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0;31m# Segment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m   \u001b[0mWSI_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msegmentTissue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mseg_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilter_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m   \u001b[0;31m### Stop Seg Timers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-6d573efea24b>\u001b[0m in \u001b[0;36msegmentTissue\u001b[0;34m(self, seg_level, sthresh, sthresh_up, mthresh, close, use_otsu, filter_params, ref_patch_size, exclude_ids, keep_ids)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;31m# Find and filter contours\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mcontours\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhierarchy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindContours\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_otsu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETR_CCOMP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCHAIN_APPROX_NONE\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Find contours\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0mhierarchy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhierarchy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfilter_params\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mforeground_contours\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhole_contours\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_filter_contours\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontours\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhierarchy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_params\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Necessary for filtering out artifacts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msqueeze\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36msqueeze\u001b[0;34m(a, axis)\u001b[0m\n\u001b[1;32m   1489\u001b[0m         \u001b[0msqueeze\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1490\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1491\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'squeeze'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1492\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1493\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapit\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mwrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAxisError\u001b[0m: axis 0 is out of bounds for array of dimension 0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1bTPYaheDc2"
      },
      "source": [
        "'''files = os.listdir('gdrive/My Drive/Regions')\n",
        "\n",
        "for f in files:\n",
        "\tprint(f)'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Aqr5NQeS--W"
      },
      "source": [
        "'''print(seg_times, patch_times)'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzNcPOFY2WVJ"
      },
      "source": [
        "'''process_list = 'gdrive/My Drive/RESULTS_DIRECTORY/bwh_biopsy.csv''''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uy-B48FPdGYN"
      },
      "source": [
        "'''df = pd.read_csv(process_list,index_col=False)'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AM5gxu02Yji",
        "outputId": "6cafde09-e121-425c-c6e5-1aaadcd2c9d6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "downsample [1. 1.]\n",
            "downsampled_level_dim [4000 4000]\n",
            "level_dim [4000 4000]\n",
            "name CPM19_CBICA_AAB_1_8000_60000\n",
            "patch_level 0\n",
            "patch_size 256\n",
            "save_path gdrive/My Drive/RESULTS_DIRECTORY/patches\n",
            "ValuesViewHDF5(<Attributes of HDF5 object at 140627055959024>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "id": "FYygrzTCThBn",
        "outputId": "faf6d46d-235c-4777-ebc3-39e936273749"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-f80d1b2ce0d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/h5py/_hl/group.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    286\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid HDF5 object reference\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             \u001b[0moid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_e\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0motype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/h5py/_hl/base.py\u001b[0m in \u001b[0;36m_e\u001b[0;34m(self, name, lcpl)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m                 \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ascii'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m                 \u001b[0mcoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCSET_ASCII\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mUnicodeEncodeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'encode'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOPil_1S4CSM",
        "outputId": "099814e4-3265-4009-d45b-a79b905dfb8d"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([], dtype=float64)"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5zhVcbjU8F1",
        "outputId": "9671539f-e743-49f0-a2c3-d4afed8498ae"
      },
      "source": [
        "'''import os\n",
        "files = os.listdir('gdrive/My Drive/RESULTS_DIRECTORY/patches') \n",
        "allCoordinates = np.empty((0,2), int)\n",
        "for f in files:\n",
        "    file_path = os.path.join('gdrive/My Drive/RESULTS_DIRECTORY/patches', f)   \n",
        "    fileName = f.split(\".\")\n",
        "    fileName = fileName[0].split(\"-\")\n",
        "    coordinates = [int(x) for x in fileName[1].split(\"_\")]\n",
        "    \n",
        "    with h5py.File(file_path,'r') as hdf5_file:\n",
        "        ls = list(hdf5_file.keys())\n",
        "        dset = hdf5_file['coords']\n",
        "        print(type(dset))\n",
        "        for i in dset:\n",
        "            allCoordinates = np.append(allCoordinates,[[i[0]+coordinates[0] , i[1]+coordinates[1]]], axis = 0)\n",
        "            print(i[0]+coordinates[0] , i[1]+coordinates[1])\n",
        "        #for name, value in dset.attrs.items():\n",
        "        #    print(name, value)\n",
        "        #print(np.array(dset))\n",
        "        #print(dset[:],np.array(dset))\n",
        "    print(\"\\n\\n\") \n",
        "#print(allCoordinates) '''\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'h5py._hl.dataset.Dataset'>\n",
            "12000 17536\n",
            "12000 17792\n",
            "12000 18048\n",
            "12000 18304\n",
            "12000 18560\n",
            "12000 18816\n",
            "12000 19072\n",
            "12000 19328\n",
            "12000 19584\n",
            "12000 19840\n",
            "12256 17024\n",
            "12256 17280\n",
            "12256 17536\n",
            "12256 17792\n",
            "12256 18048\n",
            "12256 18304\n",
            "12256 18560\n",
            "12256 18816\n",
            "12256 19072\n",
            "12256 19328\n",
            "12256 19584\n",
            "12256 19840\n",
            "12512 16512\n",
            "12512 16768\n",
            "12512 17024\n",
            "12512 17280\n",
            "12512 17536\n",
            "12512 17792\n",
            "12512 18048\n",
            "12512 18304\n",
            "12512 18560\n",
            "12512 18816\n",
            "12512 19072\n",
            "12512 19328\n",
            "12512 19584\n",
            "12512 19840\n",
            "12768 16256\n",
            "12768 16512\n",
            "12768 16768\n",
            "12768 17024\n",
            "12768 17280\n",
            "12768 17536\n",
            "12768 17792\n",
            "12768 18048\n",
            "12768 18304\n",
            "12768 18560\n",
            "12768 18816\n",
            "12768 19072\n",
            "12768 19328\n",
            "12768 19584\n",
            "12768 19840\n",
            "13024 16256\n",
            "13024 16512\n",
            "13024 16768\n",
            "13024 17024\n",
            "13024 17280\n",
            "13024 17536\n",
            "13024 17792\n",
            "13024 18048\n",
            "13024 18304\n",
            "13024 18560\n",
            "13024 18816\n",
            "13024 19072\n",
            "13024 19328\n",
            "13024 19584\n",
            "13024 19840\n",
            "13280 16000\n",
            "13280 16256\n",
            "13280 16512\n",
            "13280 16768\n",
            "13280 17024\n",
            "13280 17280\n",
            "13280 17536\n",
            "13280 17792\n",
            "13280 18048\n",
            "13280 18304\n",
            "13280 18560\n",
            "13280 18816\n",
            "13280 19072\n",
            "13280 19328\n",
            "13280 19584\n",
            "13280 19840\n",
            "13536 16000\n",
            "13536 16256\n",
            "13536 16512\n",
            "13536 16768\n",
            "13536 17024\n",
            "13536 17280\n",
            "13536 17536\n",
            "13536 17792\n",
            "13536 18048\n",
            "13536 18304\n",
            "13536 18560\n",
            "13536 18816\n",
            "13536 19072\n",
            "13536 19328\n",
            "13536 19584\n",
            "13536 19840\n",
            "13792 16000\n",
            "13792 16256\n",
            "13792 16512\n",
            "13792 16768\n",
            "13792 17024\n",
            "13792 17280\n",
            "13792 17536\n",
            "13792 17792\n",
            "13792 18048\n",
            "13792 18304\n",
            "13792 18560\n",
            "13792 18816\n",
            "13792 19072\n",
            "13792 19328\n",
            "13792 19584\n",
            "13792 19840\n",
            "14048 16000\n",
            "14048 16256\n",
            "14048 16512\n",
            "14048 16768\n",
            "14048 17024\n",
            "14048 17280\n",
            "14048 17536\n",
            "14048 17792\n",
            "14048 18048\n",
            "14048 18304\n",
            "14048 18560\n",
            "14048 18816\n",
            "14048 19072\n",
            "14048 19328\n",
            "14048 19584\n",
            "14048 19840\n",
            "14304 16000\n",
            "14304 16256\n",
            "14304 16512\n",
            "14304 16768\n",
            "14304 17024\n",
            "14304 17280\n",
            "14304 17536\n",
            "14304 17792\n",
            "14304 18048\n",
            "14304 18304\n",
            "14304 18560\n",
            "14304 18816\n",
            "14304 19072\n",
            "14304 19328\n",
            "14304 19584\n",
            "14304 19840\n",
            "14560 16000\n",
            "14560 16256\n",
            "14560 16512\n",
            "14560 16768\n",
            "14560 17024\n",
            "14560 17280\n",
            "14560 17536\n",
            "14560 17792\n",
            "14560 18048\n",
            "14560 18304\n",
            "14560 18560\n",
            "14560 18816\n",
            "14560 19072\n",
            "14560 19328\n",
            "14560 19584\n",
            "14560 19840\n",
            "14816 16000\n",
            "14816 16256\n",
            "14816 16512\n",
            "14816 16768\n",
            "14816 17024\n",
            "14816 17280\n",
            "14816 17536\n",
            "14816 17792\n",
            "14816 18048\n",
            "14816 18304\n",
            "14816 18560\n",
            "14816 18816\n",
            "14816 19072\n",
            "14816 19328\n",
            "14816 19584\n",
            "14816 19840\n",
            "15072 16000\n",
            "15072 16256\n",
            "15072 16512\n",
            "15072 16768\n",
            "15072 17024\n",
            "15072 17280\n",
            "15072 17536\n",
            "15072 17792\n",
            "15072 18048\n",
            "15072 18304\n",
            "15072 18560\n",
            "15072 18816\n",
            "15072 19072\n",
            "15072 19328\n",
            "15072 19584\n",
            "15072 19840\n",
            "15328 16000\n",
            "15328 16256\n",
            "15328 16512\n",
            "15328 16768\n",
            "15328 17024\n",
            "15328 17280\n",
            "15328 17536\n",
            "15328 17792\n",
            "15328 18048\n",
            "15328 18304\n",
            "15328 18560\n",
            "15328 18816\n",
            "15328 19072\n",
            "15328 19328\n",
            "15328 19584\n",
            "15328 19840\n",
            "15584 16000\n",
            "15584 16256\n",
            "15584 16512\n",
            "15584 16768\n",
            "15584 17024\n",
            "15584 17280\n",
            "15584 17536\n",
            "15584 17792\n",
            "15584 18048\n",
            "15584 18304\n",
            "15584 18560\n",
            "15584 18816\n",
            "15584 19072\n",
            "15584 19328\n",
            "15584 19584\n",
            "15584 19840\n",
            "15840 16000\n",
            "15840 16256\n",
            "15840 16512\n",
            "15840 16768\n",
            "15840 17024\n",
            "15840 17280\n",
            "15840 17536\n",
            "15840 17792\n",
            "15840 18048\n",
            "15840 18304\n",
            "15840 18560\n",
            "15840 18816\n",
            "15840 19072\n",
            "15840 19328\n",
            "15840 19584\n",
            "15840 19840\n",
            "\n",
            "\n",
            "\n",
            "<class 'h5py._hl.dataset.Dataset'>\n",
            "12000 20000\n",
            "12000 20256\n",
            "12000 20512\n",
            "12000 20768\n",
            "12000 21024\n",
            "12000 21280\n",
            "12000 21536\n",
            "12000 21792\n",
            "12000 22048\n",
            "12000 22304\n",
            "12000 22560\n",
            "12000 22816\n",
            "12000 23072\n",
            "12000 23328\n",
            "12000 23584\n",
            "12000 23840\n",
            "12256 20000\n",
            "12256 20256\n",
            "12256 20512\n",
            "12256 20768\n",
            "12256 21024\n",
            "12256 21280\n",
            "12256 21536\n",
            "12256 21792\n",
            "12256 22048\n",
            "12256 22304\n",
            "12256 22560\n",
            "12256 22816\n",
            "12256 23072\n",
            "12256 23328\n",
            "12256 23584\n",
            "12256 23840\n",
            "12512 20000\n",
            "12512 20256\n",
            "12512 20512\n",
            "12512 20768\n",
            "12512 21024\n",
            "12512 21280\n",
            "12512 21536\n",
            "12512 21792\n",
            "12512 22048\n",
            "12512 22304\n",
            "12512 22560\n",
            "12512 22816\n",
            "12512 23072\n",
            "12512 23328\n",
            "12512 23584\n",
            "12512 23840\n",
            "12768 20000\n",
            "12768 20256\n",
            "12768 20512\n",
            "12768 20768\n",
            "12768 21024\n",
            "12768 21280\n",
            "12768 21536\n",
            "12768 21792\n",
            "12768 22048\n",
            "12768 22304\n",
            "12768 22560\n",
            "12768 22816\n",
            "12768 23072\n",
            "12768 23328\n",
            "12768 23584\n",
            "12768 23840\n",
            "13024 20000\n",
            "13024 20256\n",
            "13024 20512\n",
            "13024 20768\n",
            "13024 21024\n",
            "13024 21280\n",
            "13024 21536\n",
            "13024 21792\n",
            "13024 22048\n",
            "13024 22304\n",
            "13024 22560\n",
            "13024 22816\n",
            "13024 23072\n",
            "13024 23328\n",
            "13024 23584\n",
            "13024 23840\n",
            "13280 20000\n",
            "13280 20256\n",
            "13280 20512\n",
            "13280 20768\n",
            "13280 21024\n",
            "13280 21280\n",
            "13280 21536\n",
            "13280 21792\n",
            "13280 22048\n",
            "13280 22304\n",
            "13280 22560\n",
            "13280 22816\n",
            "13280 23072\n",
            "13280 23328\n",
            "13280 23584\n",
            "13280 23840\n",
            "13536 20000\n",
            "13536 20256\n",
            "13536 20512\n",
            "13536 20768\n",
            "13536 21024\n",
            "13536 21280\n",
            "13536 21536\n",
            "13536 21792\n",
            "13536 22048\n",
            "13536 22304\n",
            "13536 22560\n",
            "13536 22816\n",
            "13536 23072\n",
            "13536 23328\n",
            "13536 23584\n",
            "13536 23840\n",
            "13792 20000\n",
            "13792 20256\n",
            "13792 20512\n",
            "13792 20768\n",
            "13792 21024\n",
            "13792 21280\n",
            "13792 21536\n",
            "13792 21792\n",
            "13792 22048\n",
            "13792 22304\n",
            "13792 22560\n",
            "13792 22816\n",
            "13792 23072\n",
            "13792 23328\n",
            "13792 23584\n",
            "13792 23840\n",
            "14048 20000\n",
            "14048 20256\n",
            "14048 20512\n",
            "14048 20768\n",
            "14048 21024\n",
            "14048 21280\n",
            "14048 21536\n",
            "14048 21792\n",
            "14048 22048\n",
            "14048 22304\n",
            "14048 22560\n",
            "14048 22816\n",
            "14048 23072\n",
            "14048 23328\n",
            "14048 23584\n",
            "14048 23840\n",
            "14304 20000\n",
            "14304 20256\n",
            "14304 20512\n",
            "14304 20768\n",
            "14304 21024\n",
            "14304 21280\n",
            "14304 21536\n",
            "14304 21792\n",
            "14304 22048\n",
            "14304 22304\n",
            "14304 22560\n",
            "14304 22816\n",
            "14304 23072\n",
            "14304 23328\n",
            "14304 23584\n",
            "14304 23840\n",
            "14560 20000\n",
            "14560 20256\n",
            "14560 20512\n",
            "14560 20768\n",
            "14560 21024\n",
            "14560 21280\n",
            "14560 21536\n",
            "14560 21792\n",
            "14560 22048\n",
            "14560 22304\n",
            "14560 22560\n",
            "14560 22816\n",
            "14560 23072\n",
            "14560 23328\n",
            "14560 23584\n",
            "14560 23840\n",
            "14816 20000\n",
            "14816 20256\n",
            "14816 20512\n",
            "14816 20768\n",
            "14816 21024\n",
            "14816 21280\n",
            "14816 21536\n",
            "14816 21792\n",
            "14816 22048\n",
            "14816 22304\n",
            "14816 22560\n",
            "14816 22816\n",
            "14816 23072\n",
            "14816 23328\n",
            "14816 23584\n",
            "14816 23840\n",
            "15072 20000\n",
            "15072 20256\n",
            "15072 20512\n",
            "15072 20768\n",
            "15072 21024\n",
            "15072 21280\n",
            "15072 21536\n",
            "15072 21792\n",
            "15072 22048\n",
            "15072 22304\n",
            "15072 22560\n",
            "15072 22816\n",
            "15072 23072\n",
            "15072 23328\n",
            "15072 23584\n",
            "15072 23840\n",
            "15328 20000\n",
            "15328 20256\n",
            "15328 20512\n",
            "15328 20768\n",
            "15328 21024\n",
            "15328 21280\n",
            "15328 21536\n",
            "15328 21792\n",
            "15328 22048\n",
            "15328 22304\n",
            "15328 22560\n",
            "15328 22816\n",
            "15328 23072\n",
            "15328 23328\n",
            "15328 23584\n",
            "15328 23840\n",
            "15584 20000\n",
            "15584 20256\n",
            "15584 20512\n",
            "15584 20768\n",
            "15584 21024\n",
            "15584 21280\n",
            "15584 21536\n",
            "15584 21792\n",
            "15584 22048\n",
            "15584 22304\n",
            "15584 22560\n",
            "15584 22816\n",
            "15584 23072\n",
            "15584 23328\n",
            "15584 23584\n",
            "15584 23840\n",
            "15840 20000\n",
            "15840 20256\n",
            "15840 20512\n",
            "15840 20768\n",
            "15840 21024\n",
            "15840 21280\n",
            "15840 21536\n",
            "15840 21792\n",
            "15840 22048\n",
            "15840 22304\n",
            "15840 22560\n",
            "15840 22816\n",
            "15840 23072\n",
            "15840 23328\n",
            "15840 23584\n",
            "15840 23840\n",
            "\n",
            "\n",
            "\n",
            "<class 'h5py._hl.dataset.Dataset'>\n",
            "16000 44256\n",
            "16000 44512\n",
            "16000 44768\n",
            "16000 45024\n",
            "16000 45280\n",
            "16000 45536\n",
            "16000 45792\n",
            "16000 46048\n",
            "16000 46304\n",
            "16000 46560\n",
            "16000 46816\n",
            "16000 47072\n",
            "16000 47328\n",
            "16000 47584\n",
            "16000 47840\n",
            "16256 44256\n",
            "16256 44512\n",
            "16256 44768\n",
            "16256 45024\n",
            "16256 45280\n",
            "16256 45536\n",
            "16256 45792\n",
            "16256 46048\n",
            "16256 46304\n",
            "16256 46560\n",
            "16256 46816\n",
            "16256 47072\n",
            "16256 47328\n",
            "16256 47584\n",
            "16256 47840\n",
            "16512 44000\n",
            "16512 44256\n",
            "16512 44512\n",
            "16512 44768\n",
            "16512 45024\n",
            "16512 45280\n",
            "16512 45536\n",
            "16512 45792\n",
            "16512 46048\n",
            "16512 46304\n",
            "16512 46560\n",
            "16512 46816\n",
            "16512 47072\n",
            "16512 47328\n",
            "16512 47584\n",
            "16512 47840\n",
            "16768 44000\n",
            "16768 44256\n",
            "16768 44512\n",
            "16768 44768\n",
            "16768 45024\n",
            "16768 45280\n",
            "16768 45536\n",
            "16768 45792\n",
            "16768 46048\n",
            "16768 46304\n",
            "16768 46560\n",
            "16768 46816\n",
            "16768 47072\n",
            "16768 47328\n",
            "16768 47584\n",
            "16768 47840\n",
            "17024 44000\n",
            "17024 44256\n",
            "17024 44512\n",
            "17024 44768\n",
            "17024 45024\n",
            "17024 45280\n",
            "17024 45536\n",
            "17024 45792\n",
            "17024 46048\n",
            "17024 46304\n",
            "17024 46560\n",
            "17024 46816\n",
            "17024 47072\n",
            "17024 47328\n",
            "17024 47584\n",
            "17024 47840\n",
            "17280 44000\n",
            "17280 44256\n",
            "17280 44512\n",
            "17280 44768\n",
            "17280 45024\n",
            "17280 45280\n",
            "17280 45536\n",
            "17280 45792\n",
            "17280 46048\n",
            "17280 46304\n",
            "17280 46560\n",
            "17280 46816\n",
            "17280 47072\n",
            "17280 47328\n",
            "17280 47584\n",
            "17280 47840\n",
            "17536 44000\n",
            "17536 44256\n",
            "17536 44512\n",
            "17536 44768\n",
            "17536 45024\n",
            "17536 45280\n",
            "17536 45536\n",
            "17536 45792\n",
            "17536 46048\n",
            "17536 46304\n",
            "17536 46560\n",
            "17536 46816\n",
            "17536 47072\n",
            "17536 47328\n",
            "17536 47584\n",
            "17536 47840\n",
            "17792 44000\n",
            "17792 44256\n",
            "17792 44512\n",
            "17792 44768\n",
            "17792 45024\n",
            "17792 45280\n",
            "17792 45536\n",
            "17792 45792\n",
            "17792 46048\n",
            "17792 46304\n",
            "17792 46560\n",
            "17792 46816\n",
            "17792 47072\n",
            "17792 47328\n",
            "17792 47584\n",
            "17792 47840\n",
            "18048 44000\n",
            "18048 44256\n",
            "18048 44512\n",
            "18048 44768\n",
            "18048 45024\n",
            "18048 45280\n",
            "18048 45536\n",
            "18048 45792\n",
            "18048 46048\n",
            "18048 46304\n",
            "18048 46560\n",
            "18048 46816\n",
            "18048 47072\n",
            "18048 47328\n",
            "18048 47584\n",
            "18048 47840\n",
            "18304 44000\n",
            "18304 44256\n",
            "18304 44512\n",
            "18304 44768\n",
            "18304 45024\n",
            "18304 45280\n",
            "18304 45536\n",
            "18304 45792\n",
            "18304 46048\n",
            "18304 46304\n",
            "18304 46560\n",
            "18304 46816\n",
            "18304 47072\n",
            "18304 47328\n",
            "18304 47584\n",
            "18304 47840\n",
            "18560 44000\n",
            "18560 44256\n",
            "18560 44512\n",
            "18560 44768\n",
            "18560 45024\n",
            "18560 45280\n",
            "18560 45536\n",
            "18560 45792\n",
            "18560 46048\n",
            "18560 46304\n",
            "18560 46560\n",
            "18560 46816\n",
            "18560 47072\n",
            "18560 47328\n",
            "18560 47584\n",
            "18560 47840\n",
            "18816 44000\n",
            "18816 44256\n",
            "18816 44512\n",
            "18816 44768\n",
            "18816 45024\n",
            "18816 45280\n",
            "18816 45536\n",
            "18816 45792\n",
            "18816 46048\n",
            "18816 46304\n",
            "18816 46560\n",
            "18816 46816\n",
            "18816 47072\n",
            "18816 47328\n",
            "18816 47584\n",
            "18816 47840\n",
            "19072 44000\n",
            "19072 44256\n",
            "19072 44512\n",
            "19072 44768\n",
            "19072 45024\n",
            "19072 45280\n",
            "19072 45536\n",
            "19072 45792\n",
            "19072 46048\n",
            "19072 46304\n",
            "19072 46560\n",
            "19072 46816\n",
            "19072 47072\n",
            "19072 47328\n",
            "19072 47584\n",
            "19072 47840\n",
            "19328 44000\n",
            "19328 44256\n",
            "19328 44512\n",
            "19328 44768\n",
            "19328 45024\n",
            "19328 45280\n",
            "19328 45536\n",
            "19328 45792\n",
            "19328 46048\n",
            "19328 46304\n",
            "19328 46560\n",
            "19328 46816\n",
            "19328 47072\n",
            "19328 47328\n",
            "19328 47584\n",
            "19328 47840\n",
            "19584 44000\n",
            "19584 44256\n",
            "19584 44512\n",
            "19584 44768\n",
            "19584 45024\n",
            "19584 45280\n",
            "19584 45536\n",
            "19584 45792\n",
            "19584 46048\n",
            "19584 46304\n",
            "19584 46560\n",
            "19584 46816\n",
            "19584 47072\n",
            "19584 47328\n",
            "19584 47584\n",
            "19584 47840\n",
            "19840 44000\n",
            "19840 44256\n",
            "19840 44512\n",
            "19840 44768\n",
            "19840 45024\n",
            "19840 45280\n",
            "19840 45536\n",
            "19840 45792\n",
            "19840 46048\n",
            "19840 46304\n",
            "19840 46560\n",
            "19840 46816\n",
            "19840 47072\n",
            "19840 47328\n",
            "19840 47584\n",
            "19840 47840\n",
            "\n",
            "\n",
            "\n",
            "<class 'h5py._hl.dataset.Dataset'>\n",
            "16000 54966\n",
            "16000 55222\n",
            "16000 55478\n",
            "16000 55734\n",
            "16256 55222\n",
            "16256 55478\n",
            "16256 55734\n",
            "16512 55222\n",
            "16512 55478\n",
            "16512 55734\n",
            "16768 55734\n",
            "17024 55734\n",
            "18404 53280\n",
            "18404 53536\n",
            "18404 53792\n",
            "18660 52512\n",
            "18660 52768\n",
            "18660 53024\n",
            "18660 53280\n",
            "18660 53536\n",
            "18660 53792\n",
            "18660 54048\n",
            "18660 54304\n",
            "18916 52000\n",
            "18916 52256\n",
            "18916 52512\n",
            "18916 52768\n",
            "18916 53024\n",
            "18916 53280\n",
            "18916 53536\n",
            "18916 53792\n",
            "18916 54048\n",
            "18916 54304\n",
            "18916 54560\n",
            "18916 54816\n",
            "19172 52000\n",
            "19172 52256\n",
            "19172 52512\n",
            "19172 52768\n",
            "19172 53024\n",
            "19172 53280\n",
            "19172 53536\n",
            "19172 53792\n",
            "19172 54048\n",
            "19172 54304\n",
            "19172 54560\n",
            "19172 54816\n",
            "19172 55072\n",
            "19428 52000\n",
            "19428 52256\n",
            "19428 52512\n",
            "19428 52768\n",
            "19428 53024\n",
            "19428 53280\n",
            "19428 53536\n",
            "19428 53792\n",
            "19428 54048\n",
            "19428 54304\n",
            "19428 54560\n",
            "19428 54816\n",
            "19428 55072\n",
            "19428 55328\n",
            "19684 52000\n",
            "19684 52256\n",
            "19684 52512\n",
            "19684 52768\n",
            "19684 53024\n",
            "19684 53280\n",
            "19684 53536\n",
            "19684 53792\n",
            "19684 54048\n",
            "19684 54304\n",
            "19684 54560\n",
            "19684 54816\n",
            "19684 55072\n",
            "19684 55328\n",
            "16002 52000\n",
            "16258 52000\n",
            "16258 52256\n",
            "16258 52512\n",
            "16258 52768\n",
            "16514 52000\n",
            "16514 52256\n",
            "16514 52512\n",
            "16514 52768\n",
            "16770 52000\n",
            "16770 52256\n",
            "16770 52512\n",
            "16770 52768\n",
            "17026 52000\n",
            "17026 52256\n",
            "17026 52512\n",
            "17026 52768\n",
            "17282 52000\n",
            "17282 52256\n",
            "17282 52512\n",
            "17282 52768\n",
            "17282 53024\n",
            "17282 53280\n",
            "17538 52000\n",
            "17538 52256\n",
            "17538 52512\n",
            "17538 52768\n",
            "17538 53024\n",
            "17538 53280\n",
            "17538 53536\n",
            "17794 52000\n",
            "17794 52256\n",
            "17794 52512\n",
            "17794 52768\n",
            "17794 53024\n",
            "17794 53280\n",
            "17794 53536\n",
            "18050 52000\n",
            "18050 52256\n",
            "18050 52512\n",
            "18050 52768\n",
            "18050 53024\n",
            "18050 53280\n",
            "18050 53536\n",
            "18306 52000\n",
            "18306 52256\n",
            "18306 52512\n",
            "18306 52768\n",
            "18306 53024\n",
            "18306 53280\n",
            "18562 52000\n",
            "\n",
            "\n",
            "\n",
            "<class 'h5py._hl.dataset.Dataset'>\n",
            "20000 40000\n",
            "20000 40256\n",
            "20000 40512\n",
            "20000 40768\n",
            "20000 41024\n",
            "20000 41280\n",
            "20000 41536\n",
            "20000 41792\n",
            "20000 42048\n",
            "20000 42304\n",
            "20000 42560\n",
            "20000 42816\n",
            "20000 43072\n",
            "20000 43328\n",
            "20000 43584\n",
            "20000 43840\n",
            "20256 40000\n",
            "20256 40256\n",
            "20256 40512\n",
            "20256 40768\n",
            "20256 41024\n",
            "20256 41280\n",
            "20256 41536\n",
            "20256 41792\n",
            "20256 42048\n",
            "20256 42304\n",
            "20256 42560\n",
            "20256 42816\n",
            "20256 43072\n",
            "20256 43328\n",
            "20256 43584\n",
            "20256 43840\n",
            "20512 40000\n",
            "20512 40256\n",
            "20512 40512\n",
            "20512 40768\n",
            "20512 41024\n",
            "20512 41280\n",
            "20512 41536\n",
            "20512 41792\n",
            "20512 42048\n",
            "20512 42304\n",
            "20512 42560\n",
            "20512 42816\n",
            "20512 43072\n",
            "20512 43328\n",
            "20512 43584\n",
            "20512 43840\n",
            "20768 40000\n",
            "20768 40256\n",
            "20768 40512\n",
            "20768 40768\n",
            "20768 41024\n",
            "20768 41280\n",
            "20768 41536\n",
            "20768 41792\n",
            "20768 42048\n",
            "20768 42304\n",
            "20768 42560\n",
            "20768 42816\n",
            "20768 43072\n",
            "20768 43328\n",
            "20768 43584\n",
            "20768 43840\n",
            "21024 40000\n",
            "21024 40256\n",
            "21024 40512\n",
            "21024 40768\n",
            "21024 41024\n",
            "21024 41280\n",
            "21024 41536\n",
            "21024 41792\n",
            "21024 42048\n",
            "21024 42304\n",
            "21024 42560\n",
            "21024 42816\n",
            "21024 43072\n",
            "21024 43328\n",
            "21024 43584\n",
            "21024 43840\n",
            "21280 40000\n",
            "21280 40256\n",
            "21280 40512\n",
            "21280 40768\n",
            "21280 41024\n",
            "21280 41280\n",
            "21280 41536\n",
            "21280 41792\n",
            "21280 42048\n",
            "21280 42304\n",
            "21280 42560\n",
            "21280 42816\n",
            "21280 43072\n",
            "21280 43328\n",
            "21280 43584\n",
            "21280 43840\n",
            "21536 40000\n",
            "21536 40256\n",
            "21536 40512\n",
            "21536 40768\n",
            "21536 41024\n",
            "21536 41280\n",
            "21536 41536\n",
            "21536 41792\n",
            "21536 42048\n",
            "21536 42304\n",
            "21536 42560\n",
            "21536 42816\n",
            "21536 43072\n",
            "21536 43328\n",
            "21536 43584\n",
            "21536 43840\n",
            "21792 40000\n",
            "21792 40256\n",
            "21792 40512\n",
            "21792 40768\n",
            "21792 41024\n",
            "21792 41280\n",
            "21792 41536\n",
            "21792 41792\n",
            "21792 42048\n",
            "21792 42304\n",
            "21792 42560\n",
            "21792 42816\n",
            "21792 43072\n",
            "21792 43328\n",
            "21792 43584\n",
            "21792 43840\n",
            "22048 40000\n",
            "22048 40256\n",
            "22048 40512\n",
            "22048 40768\n",
            "22048 41024\n",
            "22048 41280\n",
            "22048 41536\n",
            "22048 41792\n",
            "22048 42048\n",
            "22048 42304\n",
            "22048 42560\n",
            "22048 42816\n",
            "22048 43072\n",
            "22048 43328\n",
            "22048 43584\n",
            "22048 43840\n",
            "22304 40000\n",
            "22304 40256\n",
            "22304 40512\n",
            "22304 40768\n",
            "22304 41024\n",
            "22304 41280\n",
            "22304 41536\n",
            "22304 41792\n",
            "22304 42048\n",
            "22304 42304\n",
            "22304 42560\n",
            "22304 42816\n",
            "22304 43072\n",
            "22304 43328\n",
            "22304 43584\n",
            "22304 43840\n",
            "22560 40000\n",
            "22560 40256\n",
            "22560 40512\n",
            "22560 40768\n",
            "22560 41024\n",
            "22560 41280\n",
            "22560 41536\n",
            "22560 41792\n",
            "22560 42048\n",
            "22560 42304\n",
            "22560 42560\n",
            "22560 42816\n",
            "22560 43072\n",
            "22560 43328\n",
            "22560 43584\n",
            "22560 43840\n",
            "22816 40000\n",
            "22816 40256\n",
            "22816 40512\n",
            "22816 40768\n",
            "22816 41024\n",
            "22816 41280\n",
            "22816 41536\n",
            "22816 41792\n",
            "22816 42048\n",
            "22816 42304\n",
            "22816 42560\n",
            "22816 42816\n",
            "22816 43072\n",
            "22816 43328\n",
            "22816 43584\n",
            "22816 43840\n",
            "23072 40000\n",
            "23072 40256\n",
            "23072 40512\n",
            "23072 40768\n",
            "23072 41024\n",
            "23072 41280\n",
            "23072 41536\n",
            "23072 41792\n",
            "23072 42048\n",
            "23072 42304\n",
            "23072 42560\n",
            "23072 42816\n",
            "23072 43072\n",
            "23072 43328\n",
            "23072 43584\n",
            "23072 43840\n",
            "23328 40000\n",
            "23328 40256\n",
            "23328 40512\n",
            "23328 40768\n",
            "23328 41024\n",
            "23328 41280\n",
            "23328 41536\n",
            "23328 41792\n",
            "23328 42048\n",
            "23328 42304\n",
            "23328 42560\n",
            "23328 42816\n",
            "23328 43072\n",
            "23328 43328\n",
            "23328 43584\n",
            "23328 43840\n",
            "23584 40000\n",
            "23584 40256\n",
            "23584 40512\n",
            "23584 40768\n",
            "23584 41024\n",
            "23584 41280\n",
            "23584 41536\n",
            "23584 41792\n",
            "23584 42048\n",
            "23584 42304\n",
            "23584 42560\n",
            "23584 42816\n",
            "23584 43072\n",
            "23584 43328\n",
            "23584 43584\n",
            "23584 43840\n",
            "23840 40000\n",
            "23840 40256\n",
            "23840 40512\n",
            "23840 40768\n",
            "23840 41024\n",
            "23840 41280\n",
            "23840 41536\n",
            "23840 41792\n",
            "23840 42048\n",
            "23840 42304\n",
            "23840 42560\n",
            "23840 42816\n",
            "23840 43072\n",
            "23840 43328\n",
            "23840 43584\n",
            "23840 43840\n",
            "\n",
            "\n",
            "\n",
            "<class 'h5py._hl.dataset.Dataset'>\n",
            "20000 44000\n",
            "20000 44256\n",
            "20000 44512\n",
            "20000 44768\n",
            "20000 45024\n",
            "20000 45280\n",
            "20000 45536\n",
            "20000 45792\n",
            "20000 46048\n",
            "20000 46304\n",
            "20000 46560\n",
            "20000 46816\n",
            "20000 47072\n",
            "20000 47328\n",
            "20000 47584\n",
            "20000 47840\n",
            "20256 44000\n",
            "20256 44256\n",
            "20256 44512\n",
            "20256 44768\n",
            "20256 45024\n",
            "20256 45280\n",
            "20256 45536\n",
            "20256 45792\n",
            "20256 46048\n",
            "20256 46304\n",
            "20256 46560\n",
            "20256 46816\n",
            "20256 47072\n",
            "20256 47328\n",
            "20256 47584\n",
            "20256 47840\n",
            "20512 44000\n",
            "20512 44256\n",
            "20512 44512\n",
            "20512 44768\n",
            "20512 45024\n",
            "20512 45280\n",
            "20512 45536\n",
            "20512 45792\n",
            "20512 46048\n",
            "20512 46304\n",
            "20512 46560\n",
            "20512 46816\n",
            "20512 47072\n",
            "20512 47328\n",
            "20512 47584\n",
            "20512 47840\n",
            "20768 44000\n",
            "20768 44256\n",
            "20768 44512\n",
            "20768 44768\n",
            "20768 45024\n",
            "20768 45280\n",
            "20768 45536\n",
            "20768 45792\n",
            "20768 46048\n",
            "20768 46304\n",
            "20768 46560\n",
            "20768 46816\n",
            "20768 47072\n",
            "20768 47328\n",
            "20768 47584\n",
            "20768 47840\n",
            "21024 44000\n",
            "21024 44256\n",
            "21024 44512\n",
            "21024 44768\n",
            "21024 45024\n",
            "21024 45280\n",
            "21024 45536\n",
            "21024 45792\n",
            "21024 46048\n",
            "21024 46304\n",
            "21024 46560\n",
            "21024 46816\n",
            "21024 47072\n",
            "21024 47328\n",
            "21024 47584\n",
            "21024 47840\n",
            "21280 44000\n",
            "21280 44256\n",
            "21280 44512\n",
            "21280 44768\n",
            "21280 45024\n",
            "21280 45280\n",
            "21280 45536\n",
            "21280 45792\n",
            "21280 46048\n",
            "21280 46304\n",
            "21280 46560\n",
            "21280 46816\n",
            "21280 47072\n",
            "21280 47328\n",
            "21280 47584\n",
            "21280 47840\n",
            "21536 44000\n",
            "21536 44256\n",
            "21536 44512\n",
            "21536 44768\n",
            "21536 45024\n",
            "21536 45280\n",
            "21536 45536\n",
            "21536 45792\n",
            "21536 46048\n",
            "21536 46304\n",
            "21536 46560\n",
            "21536 46816\n",
            "21536 47072\n",
            "21536 47328\n",
            "21536 47584\n",
            "21536 47840\n",
            "21792 44000\n",
            "21792 44256\n",
            "21792 44512\n",
            "21792 44768\n",
            "21792 45024\n",
            "21792 45280\n",
            "21792 45536\n",
            "21792 45792\n",
            "21792 46048\n",
            "21792 46304\n",
            "21792 46560\n",
            "21792 46816\n",
            "21792 47072\n",
            "21792 47328\n",
            "21792 47584\n",
            "21792 47840\n",
            "22048 44000\n",
            "22048 44256\n",
            "22048 44512\n",
            "22048 44768\n",
            "22048 45024\n",
            "22048 45280\n",
            "22048 45536\n",
            "22048 45792\n",
            "22048 46048\n",
            "22048 46304\n",
            "22048 46560\n",
            "22048 46816\n",
            "22048 47072\n",
            "22048 47328\n",
            "22048 47584\n",
            "22048 47840\n",
            "22304 44000\n",
            "22304 44256\n",
            "22304 44512\n",
            "22304 44768\n",
            "22304 45024\n",
            "22304 45280\n",
            "22304 45536\n",
            "22304 45792\n",
            "22304 46048\n",
            "22304 46304\n",
            "22304 46560\n",
            "22304 46816\n",
            "22304 47072\n",
            "22304 47328\n",
            "22304 47584\n",
            "22304 47840\n",
            "22560 44000\n",
            "22560 44256\n",
            "22560 44512\n",
            "22560 44768\n",
            "22560 45024\n",
            "22560 45280\n",
            "22560 45536\n",
            "22560 45792\n",
            "22560 46048\n",
            "22560 46304\n",
            "22560 46560\n",
            "22560 46816\n",
            "22560 47072\n",
            "22560 47328\n",
            "22560 47584\n",
            "22560 47840\n",
            "22816 44000\n",
            "22816 44256\n",
            "22816 44512\n",
            "22816 44768\n",
            "22816 45024\n",
            "22816 45280\n",
            "22816 45536\n",
            "22816 45792\n",
            "22816 46048\n",
            "22816 46304\n",
            "22816 46560\n",
            "22816 46816\n",
            "22816 47072\n",
            "22816 47328\n",
            "22816 47584\n",
            "22816 47840\n",
            "23072 44000\n",
            "23072 44256\n",
            "23072 44512\n",
            "23072 44768\n",
            "23072 45024\n",
            "23072 45280\n",
            "23072 45536\n",
            "23072 45792\n",
            "23072 46048\n",
            "23072 46304\n",
            "23072 46560\n",
            "23072 46816\n",
            "23072 47072\n",
            "23072 47328\n",
            "23072 47584\n",
            "23072 47840\n",
            "23328 44000\n",
            "23328 44256\n",
            "23328 44512\n",
            "23328 44768\n",
            "23328 45024\n",
            "23328 45280\n",
            "23328 45536\n",
            "23328 45792\n",
            "23328 46048\n",
            "23328 46304\n",
            "23328 46560\n",
            "23328 46816\n",
            "23328 47072\n",
            "23328 47328\n",
            "23328 47584\n",
            "23328 47840\n",
            "23584 44000\n",
            "23584 44256\n",
            "23584 44512\n",
            "23584 44768\n",
            "23584 45024\n",
            "23584 45280\n",
            "23584 45536\n",
            "23584 45792\n",
            "23584 46048\n",
            "23584 46304\n",
            "23584 46560\n",
            "23584 46816\n",
            "23584 47072\n",
            "23584 47328\n",
            "23584 47584\n",
            "23584 47840\n",
            "23840 44000\n",
            "23840 44256\n",
            "23840 44512\n",
            "23840 44768\n",
            "23840 45024\n",
            "23840 45280\n",
            "23840 45536\n",
            "23840 45792\n",
            "23840 46048\n",
            "23840 46304\n",
            "23840 46560\n",
            "23840 46816\n",
            "23840 47072\n",
            "23840 47328\n",
            "23840 47584\n",
            "23840 47840\n",
            "\n",
            "\n",
            "\n",
            "<class 'h5py._hl.dataset.Dataset'>\n",
            "9393 27905\n",
            "9649 27137\n",
            "9649 27393\n",
            "9649 27649\n",
            "9649 27905\n",
            "9905 27137\n",
            "9905 27393\n",
            "9905 27649\n",
            "9905 27905\n",
            "10161 27137\n",
            "10161 27393\n",
            "10161 27649\n",
            "10161 27905\n",
            "10417 27905\n",
            "8000 25536\n",
            "8000 25792\n",
            "8000 26048\n",
            "8000 26304\n",
            "8000 26560\n",
            "8256 25792\n",
            "8256 26048\n",
            "8256 26304\n",
            "8256 26560\n",
            "8512 25024\n",
            "8512 25280\n",
            "8512 25792\n",
            "8512 26048\n",
            "8512 26304\n",
            "8512 26560\n",
            "8768 24256\n",
            "8768 24512\n",
            "8768 24768\n",
            "8768 25024\n",
            "8768 25280\n",
            "8768 25792\n",
            "8768 26048\n",
            "8768 26304\n",
            "8768 26560\n",
            "9024 24000\n",
            "9024 24256\n",
            "9024 24512\n",
            "9024 24768\n",
            "9024 25024\n",
            "9024 25280\n",
            "9024 25536\n",
            "9024 26048\n",
            "9024 26304\n",
            "9024 26560\n",
            "9280 24000\n",
            "9280 24256\n",
            "9280 24512\n",
            "9280 24768\n",
            "9280 25024\n",
            "9280 25280\n",
            "9280 25536\n",
            "9280 26048\n",
            "9280 26304\n",
            "9280 26560\n",
            "9280 26816\n",
            "9536 24000\n",
            "9536 24256\n",
            "9536 24512\n",
            "9536 24768\n",
            "9536 25024\n",
            "9536 25280\n",
            "9536 25536\n",
            "9536 26048\n",
            "9536 26304\n",
            "9536 26560\n",
            "9536 26816\n",
            "9792 24000\n",
            "9792 24256\n",
            "9792 24512\n",
            "9792 24768\n",
            "9792 25024\n",
            "9792 25280\n",
            "9792 25536\n",
            "9792 25792\n",
            "9792 26048\n",
            "9792 26304\n",
            "9792 26560\n",
            "9792 26816\n",
            "10048 24000\n",
            "10048 24256\n",
            "10048 24512\n",
            "10048 24768\n",
            "10048 25024\n",
            "10048 25280\n",
            "10048 25536\n",
            "10048 25792\n",
            "10048 26048\n",
            "10048 26304\n",
            "10048 26560\n",
            "10048 26816\n",
            "10304 24000\n",
            "10304 24256\n",
            "10304 24512\n",
            "10304 24768\n",
            "10304 25024\n",
            "10304 25280\n",
            "10304 25536\n",
            "10304 25792\n",
            "10304 26048\n",
            "10304 26304\n",
            "10304 26560\n",
            "10304 26816\n",
            "10560 24000\n",
            "10560 24256\n",
            "10560 24512\n",
            "10560 24768\n",
            "10560 25024\n",
            "10560 25280\n",
            "10560 25536\n",
            "10560 25792\n",
            "10560 26048\n",
            "10560 26304\n",
            "10560 26560\n",
            "10560 26816\n",
            "10816 24000\n",
            "10816 24256\n",
            "10816 24512\n",
            "10816 24768\n",
            "10816 25024\n",
            "10816 25280\n",
            "10816 25536\n",
            "10816 25792\n",
            "10816 26048\n",
            "10816 26304\n",
            "10816 26560\n",
            "10816 26816\n",
            "10816 27072\n",
            "11072 24000\n",
            "11072 24256\n",
            "11072 24512\n",
            "11072 24768\n",
            "11072 25024\n",
            "11072 25280\n",
            "11072 25536\n",
            "11072 25792\n",
            "11072 26048\n",
            "11072 26304\n",
            "11072 26560\n",
            "11072 26816\n",
            "11072 27072\n",
            "11328 24256\n",
            "11328 24512\n",
            "11328 24768\n",
            "11328 25024\n",
            "11328 25280\n",
            "11328 25536\n",
            "11328 25792\n",
            "11328 26048\n",
            "11328 26304\n",
            "11328 26560\n",
            "11328 26816\n",
            "11328 27072\n",
            "11584 24000\n",
            "11584 24256\n",
            "11584 24512\n",
            "11584 24768\n",
            "11584 25024\n",
            "11584 25280\n",
            "11584 25536\n",
            "11584 25792\n",
            "11584 26048\n",
            "11584 26304\n",
            "11584 26560\n",
            "11584 26816\n",
            "11584 27072\n",
            "11584 27328\n",
            "11584 27584\n",
            "11840 24000\n",
            "11840 24256\n",
            "11840 24512\n",
            "11840 24768\n",
            "11840 25024\n",
            "11840 25280\n",
            "11840 25536\n",
            "11840 25792\n",
            "11840 26048\n",
            "11840 26304\n",
            "11840 26560\n",
            "11840 26816\n",
            "11840 27072\n",
            "11840 27328\n",
            "11840 27584\n",
            "8000 24000\n",
            "8000 24256\n",
            "8000 24512\n",
            "8000 24768\n",
            "8000 25024\n",
            "8000 25280\n",
            "8000 25536\n",
            "8256 24256\n",
            "8256 24512\n",
            "8256 24768\n",
            "8256 25024\n",
            "8512 24256\n",
            "8512 24512\n",
            "8512 24768\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-lxDqUyCFUq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}