{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "wsi_preprocessing.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "GT4i4PcQau5X",
        "ExlHIuvGbfJF",
        "0l913EqPsIrH",
        "lyfBWQVWoIgz"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vimuth97/FYP-Brain-Tumor-Classification/blob/main/Basic%20pathology%20model/wsi_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjnCDx3uFJhB"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import time\n",
        "import argparse\n",
        "import pdb\n",
        "import pandas as pd\n",
        "import math\n",
        "import xml.etree.ElementTree as ET\n",
        "from xml.dom import minidom\n",
        "import multiprocessing as mp\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import h5py\n",
        "import itertools\n",
        "import pickle\n",
        "!apt update && apt install -y openslide-tools\n",
        "!pip install openslide-python \n",
        "import openslide"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pplQfl5FMgi"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GT4i4PcQau5X"
      },
      "source": [
        "# WSI ProProcessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFmY2prSF2l3"
      },
      "source": [
        "**File Utils**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wY2xd0MEGCsA"
      },
      "source": [
        "**Util Classes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Equ_uuNGAnZ"
      },
      "source": [
        "class Contour_Checking_fn(object):\n",
        "\t# Defining __call__ method \n",
        "\tdef __call__(self, pt): \n",
        "\t\traise NotImplementedError\n",
        "\n",
        "class isInContourV1(Contour_Checking_fn):\n",
        "\tdef __init__(self, contour):\n",
        "\t\tself.cont = contour\n",
        "\n",
        "\tdef __call__(self, pt): \n",
        "\t\treturn 1 if cv2.pointPolygonTest(self.cont, pt, False) >= 0 else 0\n",
        "\n",
        "class isInContourV2(Contour_Checking_fn):\n",
        "\tdef __init__(self, contour, patch_size):\n",
        "\t\tself.cont = contour\n",
        "\t\tself.patch_size = patch_size\n",
        "\n",
        "\tdef __call__(self, pt): \n",
        "\t\treturn 1 if cv2.pointPolygonTest(self.cont, (pt[0]+self.patch_size//2, pt[1]+self.patch_size//2), False) >= 0 else 0\n",
        "\n",
        "class isInContourV3_Easy(Contour_Checking_fn):\n",
        "\tdef __init__(self, contour, patch_size, center_shift=0.5):\n",
        "\t\tself.cont = contour\n",
        "\t\tself.patch_size = patch_size\n",
        "\t\tself.shift = int(patch_size//2*center_shift)\n",
        "\tdef __call__(self, pt): \n",
        "\t\tcenter = (pt[0]+self.patch_size//2, pt[1]+self.patch_size//2)\n",
        "\t\tif self.shift > 0:\n",
        "\t\t\tall_points = [(center[0]-self.shift, center[1]-self.shift),\n",
        "\t\t\t\t\t\t  (center[0]+self.shift, center[1]+self.shift),\n",
        "\t\t\t\t\t\t  (center[0]+self.shift, center[1]-self.shift),\n",
        "\t\t\t\t\t\t  (center[0]-self.shift, center[1]+self.shift)\n",
        "\t\t\t\t\t\t  ]\n",
        "\t\telse:\n",
        "\t\t\tall_points = [center]\n",
        "\t\t\n",
        "\t\tfor points in all_points:\n",
        "\t\t\tif cv2.pointPolygonTest(self.cont, points, False) >= 0:\n",
        "\t\t\t\treturn 1\n",
        "\t\treturn 0\n",
        "\n",
        "# Hard version of 4pt contour checking function - all 4 points need to be in the contour for test to pass\n",
        "class isInContourV3_Hard(Contour_Checking_fn):\n",
        "\tdef __init__(self, contour, patch_size, center_shift=0.5):\n",
        "\t\tself.cont = contour\n",
        "\t\tself.patch_size = patch_size\n",
        "\t\tself.shift = int(patch_size//2*center_shift)\n",
        "\tdef __call__(self, pt): \n",
        "\t\tcenter = (pt[0]+self.patch_size//2, pt[1]+self.patch_size//2)\n",
        "\t\tif self.shift > 0:\n",
        "\t\t\tall_points = [(center[0]-self.shift, center[1]-self.shift),\n",
        "\t\t\t\t\t\t  (center[0]+self.shift, center[1]+self.shift),\n",
        "\t\t\t\t\t\t  (center[0]+self.shift, center[1]-self.shift),\n",
        "\t\t\t\t\t\t  (center[0]-self.shift, center[1]+self.shift)\n",
        "\t\t\t\t\t\t  ]\n",
        "\t\telse:\n",
        "\t\t\tall_points = [center]\n",
        "\t\t\n",
        "\t\tfor points in all_points:\n",
        "\t\t\tif cv2.pointPolygonTest(self.cont, points, False) < 0:\n",
        "\t\t\t\treturn 0\n",
        "\t\treturn 1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rTJX4CfHBmf"
      },
      "source": [
        "**WSI Utils**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uou8Yl6jGI3Y"
      },
      "source": [
        "def save_pkl(filename, save_object):\n",
        "\twriter = open(filename,'wb')\n",
        "\tpickle.dump(save_object, writer)\n",
        "\twriter.close()\n",
        "\n",
        "def load_pkl(filename):\n",
        "\tloader = open(filename,'rb')\n",
        "\tfile = pickle.load(loader)\n",
        "\tloader.close()\n",
        "\treturn file\n",
        "\n",
        "def savePatchIter_bag_hdf5(patch):\n",
        "    x, y, cont_idx, patch_level, downsample, downsampled_level_dim, level_dim, img_patch, name, save_path= tuple(patch.values())\n",
        "    img_patch = np.array(img_patch)[np.newaxis,...]\n",
        "    img_shape = img_patch.shape\n",
        "\n",
        "    file_path = os.path.join(save_path, name)+'.h5'\n",
        "    file = h5py.File(file_path, \"a\")\n",
        "\n",
        "    dset = file['imgs']\n",
        "    dset.resize(len(dset) + img_shape[0], axis=0)\n",
        "    dset[-img_shape[0]:] = img_patch\n",
        "\n",
        "    if 'coords' in file:\n",
        "        coord_dset = file['coords']\n",
        "        coord_dset.resize(len(coord_dset) + img_shape[0], axis=0)\n",
        "        coord_dset[-img_shape[0]:] = (x,y)\n",
        "\n",
        "    file.close()\n",
        "\n",
        "def initialize_hdf5_bag(first_patch, save_coord=False):\n",
        "    x, y, cont_idx, patch_level, downsample, downsampled_level_dim, level_dim, img_patch, name, save_path = tuple(first_patch.values())\n",
        "    file_path = os.path.join(save_path, name)+'.h5'\n",
        "    file = h5py.File(file_path, \"w\")\n",
        "    img_patch = np.array(img_patch)[np.newaxis,...]\n",
        "    dtype = img_patch.dtype\n",
        "\n",
        "    # Initialize a resizable dataset to hold the output\n",
        "    img_shape = img_patch.shape\n",
        "    maxshape = (None,) + img_shape[1:] #maximum dimensions up to which dataset maybe resized (None means unlimited)\n",
        "    dset = file.create_dataset('imgs', \n",
        "                                shape=img_shape, maxshape=maxshape,  chunks=img_shape, dtype=dtype)\n",
        "\n",
        "    dset[:] = img_patch\n",
        "    dset.attrs['patch_level'] = patch_level\n",
        "    dset.attrs['wsi_name'] = name\n",
        "    dset.attrs['downsample'] = downsample\n",
        "    dset.attrs['level_dim'] = level_dim\n",
        "    dset.attrs['downsampled_level_dim'] = downsampled_level_dim\n",
        "\n",
        "    if save_coord:\n",
        "        coord_dset = file.create_dataset('coords', shape=(1, 2), maxshape=(None, 2), chunks=(1, 2), dtype=np.int32)\n",
        "        coord_dset[:] = (x,y)\n",
        "\n",
        "    file.close()\n",
        "    return file_path\n",
        "\n",
        "def coord_generator(x_start, x_end, x_step, y_start, y_end, y_step, args_dict=None):\n",
        "    for x in range(x_start, x_end, x_step):\n",
        "        for y in range(y_start, y_end, y_step):\n",
        "            if args_dict is not None:\n",
        "                process_dict = args_dict.copy()\n",
        "                process_dict.update({'pt':(x,y)})\n",
        "                yield process_dict\n",
        "            else:\n",
        "                yield (x,y)\n",
        "\n",
        "def save_hdf5(output_path, asset_dict, attr_dict= None, mode='a'):\n",
        "    file = h5py.File(output_path, mode)\n",
        "    for key, val in asset_dict.items():\n",
        "        data_shape = val.shape\n",
        "        if key not in file:\n",
        "            data_type = val.dtype\n",
        "            chunk_shape = (1, ) + data_shape[1:]\n",
        "            maxshape = (None, ) + data_shape[1:]\n",
        "            dset = file.create_dataset(key, shape=data_shape, maxshape=maxshape, chunks=chunk_shape, dtype=data_type)\n",
        "            dset[:] = val\n",
        "            if attr_dict is not None:\n",
        "                if key in attr_dict.keys():\n",
        "                    for attr_key, attr_val in attr_dict[key].items():\n",
        "                        dset.attrs[attr_key] = attr_val\n",
        "        else:\n",
        "            dset = file[key]\n",
        "            dset.resize(len(dset) + data_shape[0], axis=0)\n",
        "            dset[-data_shape[0]:] = val\n",
        "    file.close()\n",
        "    return output_path\n",
        "\n",
        "def sample_indices(scores, k, start=0.48, end=0.52, convert_to_percentile=False, seed=1):\n",
        "    np.random.seed(seed)\n",
        "    if convert_to_percentile:\n",
        "        end_value = np.quantile(scores, end)\n",
        "        start_value = np.quantile(scores, start)\n",
        "    else:\n",
        "        end_value = end\n",
        "        start_value = start\n",
        "    score_window = np.logical_and(scores >= start_value, scores <= end_value)\n",
        "    indices = np.where(score_window)[0]\n",
        "    if len(indices) < 1:\n",
        "        return -1 \n",
        "    else:\n",
        "        return np.random.choice(indices, min(k, len(indices)), replace=False)\n",
        "\n",
        "\n",
        "def screen_coords(scores, coords, top_left, bot_right):\n",
        "    bot_right = np.array(bot_right)\n",
        "    top_left = np.array(top_left)\n",
        "    mask = np.logical_and(np.all(coords >= top_left, axis=1), np.all(coords <= bot_right, axis=1))\n",
        "    scores = scores[mask]\n",
        "    coords = coords[mask]\n",
        "    return scores, coords\n",
        "\n",
        "def isBlackPatch(patch, rgbThresh=40):\n",
        "    return True if np.all(np.mean(patch, axis = (0,1)) < rgbThresh) else False\n",
        "\n",
        "def isWhitePatch(patch, satThresh=5):\n",
        "    patch_hsv = cv2.cvtColor(patch, cv2.COLOR_RGB2HSV)\n",
        "    return True if np.mean(patch_hsv[:,:,1]) < satThresh else False\n",
        "\n",
        "def to_percentiles(scores):\n",
        "    from scipy.stats import rankdata\n",
        "    scores = rankdata(scores, 'average')/len(scores) * 100   \n",
        "    return scores\n",
        "\n",
        "def DrawMapFromCoords(canvas, wsi_object, coords, patch_size, vis_level, indices=None, verbose=1, draw_grid=True):\n",
        "    downsamples = wsi_object.wsi.level_downsamples[vis_level]\n",
        "    if indices is None:\n",
        "        indices = np.arange(len(coords))\n",
        "    total = len(indices)\n",
        "    if verbose > 0:\n",
        "        ten_percent_chunk = math.ceil(total * 0.1)\n",
        "        \n",
        "    patch_size = tuple(np.ceil((np.array(patch_size)/np.array(downsamples))).astype(np.int32))\n",
        "    print('downscaled patch size: {}x{}'.format(patch_size[0], patch_size[1]))\n",
        "    \n",
        "    for idx in range(total):\n",
        "        if verbose > 0:\n",
        "            if idx % ten_percent_chunk == 0:\n",
        "                print('progress: {}/{} stitched'.format(idx, total))\n",
        "        \n",
        "        patch_id = indices[idx]\n",
        "        coord = coords[patch_id]\n",
        "        patch = np.array(wsi_object.wsi.read_region(tuple(coord), vis_level, patch_size).convert(\"RGB\"))\n",
        "        coord = np.ceil(coord / downsamples).astype(np.int32)\n",
        "        canvas_crop_shape = canvas[coord[1]:coord[1]+patch_size[1], coord[0]:coord[0]+patch_size[0], :3].shape[:2]\n",
        "        canvas[coord[1]:coord[1]+patch_size[1], coord[0]:coord[0]+patch_size[0], :3] = patch[:canvas_crop_shape[0], :canvas_crop_shape[1], :]\n",
        "        if draw_grid:\n",
        "            DrawGrid(canvas, coord, patch_size)\n",
        "\n",
        "    return Image.fromarray(canvas)\n",
        "\n",
        "def StitchCoords(hdf5_file_path, wsi_object, downscale=16, draw_grid=False, bg_color=(0,0,0), alpha=-1):\n",
        "    wsi = wsi_object.getOpenSlide()\n",
        "    vis_level = wsi.get_best_level_for_downsample(downscale)\n",
        "    file = h5py.File(hdf5_file_path, 'r')\n",
        "    dset = file['coords']\n",
        "    coords = dset[:]\n",
        "    w, h = wsi.level_dimensions[0]\n",
        "\n",
        "    print('start stitching {}'.format(dset.attrs['name']))\n",
        "    print('original size: {} x {}'.format(w, h))\n",
        "\n",
        "    w, h = wsi.level_dimensions[vis_level]\n",
        "\n",
        "    print('downscaled size for stiching: {} x {}'.format(w, h))\n",
        "    print('number of patches: {}'.format(len(coords)))\n",
        "    \n",
        "    patch_size = dset.attrs['patch_size']\n",
        "    patch_level = dset.attrs['patch_level']\n",
        "    print('patch size: {}x{} patch level: {}'.format(patch_size, patch_size, patch_level))\n",
        "    patch_size = tuple((np.array((patch_size, patch_size)) * wsi.level_downsamples[patch_level]).astype(np.int32))\n",
        "    print('ref patch size: {}x{}'.format(patch_size, patch_size))\n",
        "\n",
        "    if w*h > Image.MAX_IMAGE_PIXELS: \n",
        "        raise Image.DecompressionBombError(\"Visualization Downscale %d is too large\" % downscale)\n",
        "    \n",
        "    if alpha < 0 or alpha == -1:\n",
        "        heatmap = Image.new(size=(w,h), mode=\"RGB\", color=bg_color)\n",
        "    else:\n",
        "        heatmap = Image.new(size=(w,h), mode=\"RGBA\", color=bg_color + (int(255 * alpha),))\n",
        "    \n",
        "    heatmap = np.array(heatmap)\n",
        "    heatmap = DrawMapFromCoords(heatmap, wsi_object, coords, patch_size, vis_level, indices=None, draw_grid=draw_grid)\n",
        "    \n",
        "    file.close()\n",
        "    return heatmap\n",
        "\n",
        "def initialize_df(slides, seg_params, filter_params, vis_params, patch_params, \n",
        "\tuse_heatmap_args=False, save_patches=False):\n",
        "\n",
        "\ttotal = len(slides)\n",
        "\tif isinstance(slides, pd.DataFrame):\n",
        "\t\tslide_ids = slides.slide_id.values\n",
        "\telse:\n",
        "\t\tslide_ids = slides\n",
        "\tdefault_df_dict = {'slide_id': slide_ids, 'process': np.full((total), 1, dtype=np.uint8)}\n",
        "\n",
        "\t# initiate empty labels in case not provided\n",
        "\tif use_heatmap_args:\n",
        "\t\tdefault_df_dict.update({'label': np.full((total), -1)})\n",
        "\t\n",
        "\tdefault_df_dict.update({\n",
        "\t\t'status': np.full((total), 'tbp'),\n",
        "\t\t# seg params\n",
        "\t\t'seg_level': np.full((total), int(seg_params['seg_level']), dtype=np.int8),\n",
        "\t\t'sthresh': np.full((total), int(seg_params['sthresh']), dtype=np.uint8),\n",
        "\t\t'mthresh': np.full((total), int(seg_params['mthresh']), dtype=np.uint8),\n",
        "\t\t'close': np.full((total), int(seg_params['close']), dtype=np.uint32),\n",
        "\t\t'use_otsu': np.full((total), bool(seg_params['use_otsu']), dtype=bool),\n",
        "\t\t'keep_ids': np.full((total), seg_params['keep_ids']),\n",
        "\t\t'exclude_ids': np.full((total), seg_params['exclude_ids']),\n",
        "\t\t\n",
        "\t\t# filter params\n",
        "\t\t'a_t': np.full((total), int(filter_params['a_t']), dtype=np.float32),\n",
        "\t\t'a_h': np.full((total), int(filter_params['a_h']), dtype=np.float32),\n",
        "\t\t'max_n_holes': np.full((total), int(filter_params['max_n_holes']), dtype=np.uint32),\n",
        "\n",
        "\t\t# vis params\n",
        "\t\t'vis_level': np.full((total), int(vis_params['vis_level']), dtype=np.int8),\n",
        "\t\t'line_thickness': np.full((total), int(vis_params['line_thickness']), dtype=np.uint32),\n",
        "\n",
        "\t\t# patching params\n",
        "\t\t'use_padding': np.full((total), bool(patch_params['use_padding']), dtype=bool),\n",
        "\t\t'contour_fn': np.full((total), patch_params['contour_fn'])\n",
        "\t\t})\n",
        "\n",
        "\tif save_patches:\n",
        "\t\tdefault_df_dict.update({\n",
        "\t\t\t'white_thresh': np.full((total), int(patch_params['white_thresh']), dtype=np.uint8),\n",
        "\t\t\t'black_thresh': np.full((total), int(patch_params['black_thresh']), dtype=np.uint8)})\n",
        "\n",
        "\tif use_heatmap_args:\n",
        "\t\t# initiate empty x,y coordinates in case not provided\n",
        "\t\tdefault_df_dict.update({'x1': np.empty((total)).fill(np.NaN), \n",
        "\t\t\t'x2': np.empty((total)).fill(np.NaN), \n",
        "\t\t\t'y1': np.empty((total)).fill(np.NaN), \n",
        "\t\t\t'y2': np.empty((total)).fill(np.NaN)})\n",
        "\n",
        "\n",
        "\tif isinstance(slides, pd.DataFrame):\n",
        "\t\ttemp_copy = pd.DataFrame(default_df_dict) # temporary dataframe w/ default params\n",
        "\t\t# find key in provided df\n",
        "\t\t# if exist, fill empty fields w/ default values, else, insert the default values as a new column\n",
        "\t\tfor key in default_df_dict.keys(): \n",
        "\t\t\tif key in slides.columns:\n",
        "\t\t\t\tmask = slides[key].isna()\n",
        "\t\t\t\tslides.loc[mask, key] = temp_copy.loc[mask, key]\n",
        "\t\t\telse:\n",
        "\t\t\t\tslides.insert(len(slides.columns), key, default_df_dict[key])\n",
        "\telse:\n",
        "\t\tslides = pd.DataFrame(default_df_dict)\n",
        "\t\n",
        "\treturn slides"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQ1oPkX-HMho"
      },
      "source": [
        "**WSI Image class**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NI7EyjejHJRx"
      },
      "source": [
        "Image.MAX_IMAGE_PIXELS = 9331200000\n",
        "\n",
        "class WholeSlideImage(object):\n",
        "    def __init__(self, path):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            path (str): fullpath to WSI file\n",
        "        \"\"\"\n",
        "\n",
        "        self.name = \".\".join(path.split(\"/\")[-1].split('.')[:-1])\n",
        "\n",
        "        print(\"Name:\"+self.name)\n",
        "\n",
        "        self.file_path = path \n",
        "        \n",
        "        self.wsi = openslide.open_slide(self.file_path)\n",
        "        \n",
        "\n",
        "        \n",
        "        #self.level_downsamples = level_downsamples\n",
        "        self.level_downsamples = self._assertLevelDownsamples()#\n",
        "        self.level_dim = self.wsi.level_dimensions #(4000,4000)\n",
        "    \n",
        "        self.contours_tissue = None\n",
        "        self.contours_tumor = None\n",
        "        self.hdf5_file = None\n",
        "\n",
        "    def getOpenSlide(self):\n",
        "        return self.wsi\n",
        "\n",
        "    def initXML(self, xml_path):\n",
        "        def _createContour(coord_list):\n",
        "            return np.array([[[int(float(coord.attributes['X'].value)), \n",
        "                               int(float(coord.attributes['Y'].value))]] for coord in coord_list], dtype = 'int32')\n",
        "\n",
        "        xmldoc = minidom.parse(xml_path)\n",
        "        annotations = [anno.getElementsByTagName('Coordinate') for anno in xmldoc.getElementsByTagName('Annotation')]\n",
        "        self.contours_tumor  = [_createContour(coord_list) for coord_list in annotations]\n",
        "        self.contours_tumor = sorted(self.contours_tumor, key=cv2.contourArea, reverse=True)\n",
        "\n",
        "    def initTxt(self,annot_path):\n",
        "        def _create_contours_from_dict(annot):\n",
        "            all_cnts = []\n",
        "            for idx, annot_group in enumerate(annot):\n",
        "                contour_group = annot_group['coordinates']\n",
        "                if annot_group['type'] == 'Polygon':\n",
        "                    for idx, contour in enumerate(contour_group):\n",
        "                        contour = np.array(contour).astype(np.int32).reshape(-1,1,2)\n",
        "                        all_cnts.append(contour) \n",
        "\n",
        "                else:\n",
        "                    for idx, sgmt_group in enumerate(contour_group):\n",
        "                        contour = []\n",
        "                        for sgmt in sgmt_group:\n",
        "                            contour.extend(sgmt)\n",
        "                        contour = np.array(contour).astype(np.int32).reshape(-1,1,2)    \n",
        "                        all_cnts.append(contour) \n",
        "\n",
        "            return all_cnts\n",
        "        \n",
        "        with open(annot_path, \"r\") as f:\n",
        "            annot = f.read()\n",
        "            annot = eval(annot)\n",
        "        self.contours_tumor  = _create_contours_from_dict(annot)\n",
        "        self.contours_tumor = sorted(self.contours_tumor, key=cv2.contourArea, reverse=True)\n",
        "\n",
        "    def initSegmentation(self, mask_file):\n",
        "        # load segmentation results from pickle file\n",
        "        import pickle\n",
        "        asset_dict = load_pkl(mask_file)\n",
        "        self.holes_tissue = asset_dict['holes']\n",
        "        self.contours_tissue = asset_dict['tissue']\n",
        "\n",
        "    def saveSegmentation(self, mask_file):\n",
        "        # save segmentation results using pickle\n",
        "        asset_dict = {'holes': self.holes_tissue, 'tissue': self.contours_tissue}\n",
        "        save_pkl(mask_file, asset_dict)\n",
        "\n",
        "    def segmentTissue(self, seg_level=0, sthresh=20, sthresh_up = 255, mthresh=7, close = 0, use_otsu=False, \n",
        "                            filter_params={'a_t':100}, ref_patch_size=512, exclude_ids=[], keep_ids=[]):\n",
        "        \"\"\"\n",
        "            Segment the tissue via HSV -> Median thresholding -> Binary threshold\n",
        "        \"\"\"\n",
        "        \n",
        "        def _filter_contours(contours, hierarchy, filter_params):\n",
        "            \"\"\"\n",
        "                Filter contours by: area.\n",
        "            \"\"\"\n",
        "            filtered = []\n",
        "\n",
        "            # find indices of foreground contours (parent == -1)\n",
        "            hierarchy_1 = np.flatnonzero(hierarchy[:,1] == -1)\n",
        "            all_holes = []\n",
        "            \n",
        "            # loop through foreground contour indices\n",
        "            for cont_idx in hierarchy_1:\n",
        "                # actual contour\n",
        "                cont = contours[cont_idx]\n",
        "                # indices of holes contained in this contour (children of parent contour)\n",
        "                holes = np.flatnonzero(hierarchy[:, 1] == cont_idx)\n",
        "                # take contour area (includes holes)\n",
        "                a = cv2.contourArea(cont)\n",
        "                # calculate the contour area of each hole\n",
        "                hole_areas = [cv2.contourArea(contours[hole_idx]) for hole_idx in holes]\n",
        "                # actual area of foreground contour region\n",
        "                a = a - np.array(hole_areas).sum()\n",
        "                if a == 0: continue\n",
        "                if tuple((filter_params['a_t'],)) < tuple((a,)): \n",
        "                    filtered.append(cont_idx)\n",
        "                    all_holes.append(holes)\n",
        "\n",
        "\n",
        "            foreground_contours = [contours[cont_idx] for cont_idx in filtered]\n",
        "            \n",
        "            hole_contours = []\n",
        "\n",
        "            for hole_ids in all_holes:\n",
        "                unfiltered_holes = [contours[idx] for idx in hole_ids ]\n",
        "                unfilered_holes = sorted(unfiltered_holes, key=cv2.contourArea, reverse=True)\n",
        "                # take max_n_holes largest holes by area\n",
        "                unfilered_holes = unfilered_holes[:filter_params['max_n_holes']]\n",
        "                filtered_holes = []\n",
        "                \n",
        "                # filter these holes\n",
        "                for hole in unfilered_holes:\n",
        "                    if cv2.contourArea(hole) > filter_params['a_h']:\n",
        "                        filtered_holes.append(hole)\n",
        "\n",
        "                hole_contours.append(filtered_holes)\n",
        "\n",
        "            return foreground_contours, hole_contours\n",
        "        \n",
        "        img = np.array(self.wsi.read_region((0,0), seg_level, self.level_dim[seg_level]))\n",
        "        img_hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)  # Convert to HSV space\n",
        "        img_med = cv2.medianBlur(img_hsv[:,:,1], mthresh)  # Apply median blurring\n",
        "        \n",
        "       \n",
        "        # Thresholding\n",
        "        if use_otsu:\n",
        "            _, img_otsu = cv2.threshold(img_med, 0, sthresh_up, cv2.THRESH_OTSU+cv2.THRESH_BINARY)\n",
        "        else:\n",
        "            _, img_otsu = cv2.threshold(img_med, sthresh, sthresh_up, cv2.THRESH_BINARY)\n",
        "\n",
        "        # Morphological closing\n",
        "        if close > 0:\n",
        "            kernel = np.ones((close, close), np.uint8)\n",
        "            img_otsu = cv2.morphologyEx(img_otsu, cv2.MORPH_CLOSE, kernel)                 \n",
        "\n",
        "        scale = self.level_downsamples[seg_level]\n",
        "        scaled_ref_patch_area = int(ref_patch_size**2 / (scale[0] * scale[1]))\n",
        "        filter_params = filter_params.copy()\n",
        "        filter_params['a_t'] = filter_params['a_t'] * scaled_ref_patch_area\n",
        "        filter_params['a_h'] = filter_params['a_h'] * scaled_ref_patch_area\n",
        "        \n",
        "        #print(img_otsu,np.shape(img_otsu), cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)\n",
        "        # Find and filter contours\n",
        "        contours, hierarchy = cv2.findContours(img_otsu, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE) # Find contours \n",
        "\n",
        "        #print(contours)\n",
        "        hierarchy = np.squeeze(hierarchy, axis=(0,))[:, 2:]\n",
        "        \n",
        "        if filter_params: foreground_contours, hole_contours = _filter_contours(contours, hierarchy, filter_params)  # Necessary for filtering out artifacts\n",
        "\n",
        "        self.contours_tissue = self.scaleContourDim(foreground_contours, scale)\n",
        "        self.holes_tissue = self.scaleHolesDim(hole_contours, scale)\n",
        "\n",
        "        #exclude_ids = [0,7,9]\n",
        "        if len(keep_ids) > 0:\n",
        "            contour_ids = set(keep_ids) - set(exclude_ids)\n",
        "        else:\n",
        "            contour_ids = set(np.arange(len(self.contours_tissue))) - set(exclude_ids)\n",
        "\n",
        "        self.contours_tissue = [self.contours_tissue[i] for i in contour_ids]\n",
        "        self.holes_tissue = [self.holes_tissue[i] for i in contour_ids]\n",
        "\n",
        "    def visWSI(self, vis_level=0, color = (0,255,0), hole_color = (0,0,255), annot_color=(255,0,0), \n",
        "                    line_thickness=250, max_size=None, top_left=None, bot_right=None, custom_downsample=1, view_slide_only=False,\n",
        "                    number_contours=False, seg_display=True, annot_display=True):\n",
        "        \n",
        "        downsample = self.level_downsamples[vis_level]\n",
        "        scale = [1/downsample[0], 1/downsample[1]]\n",
        "        \n",
        "        if top_left is not None and bot_right is not None:\n",
        "            top_left = tuple(top_left)\n",
        "            bot_right = tuple(bot_right)\n",
        "            w, h = tuple((np.array(bot_right) * scale).astype(int) - (np.array(top_left) * scale).astype(int))\n",
        "            region_size = (w, h)\n",
        "        else:\n",
        "            top_left = (0,0)\n",
        "            region_size = self.level_dim[vis_level]\n",
        "\n",
        "        img = np.array(self.wsi.read_region(top_left, vis_level, region_size).convert(\"RGB\"))\n",
        "        \n",
        "        if not view_slide_only:\n",
        "            offset = tuple(-(np.array(top_left) * scale).astype(int))\n",
        "            line_thickness = int(line_thickness * math.sqrt(scale[0] * scale[1]))\n",
        "            if self.contours_tissue is not None and seg_display:\n",
        "                if not number_contours:\n",
        "                    cv2.drawContours(img, self.scaleContourDim(self.contours_tissue, scale), \n",
        "                                     -1, color, line_thickness, lineType=cv2.LINE_8, offset=offset)\n",
        "\n",
        "                else: # add numbering to each contour\n",
        "                    for idx, cont in enumerate(self.contours_tissue):\n",
        "                        contour = np.array(self.scaleContourDim(cont, scale))\n",
        "                        M = cv2.moments(contour)\n",
        "                        cX = int(M[\"m10\"] / (M[\"m00\"] + 1e-9))\n",
        "                        cY = int(M[\"m01\"] / (M[\"m00\"] + 1e-9))\n",
        "                        # draw the contour and put text next to center\n",
        "                        cv2.drawContours(img,  [contour], -1, color, line_thickness, lineType=cv2.LINE_8, offset=offset)\n",
        "                        cv2.putText(img, \"{}\".format(idx), (cX, cY),\n",
        "                                cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 0, 0), 10)\n",
        "\n",
        "                for holes in self.holes_tissue:\n",
        "                    cv2.drawContours(img, self.scaleContourDim(holes, scale), \n",
        "                                     -1, hole_color, line_thickness, lineType=cv2.LINE_8)\n",
        "            \n",
        "            if self.contours_tumor is not None and annot_display:\n",
        "                cv2.drawContours(img, self.scaleContourDim(self.contours_tumor, scale), \n",
        "                                 -1, annot_color, line_thickness, lineType=cv2.LINE_8, offset=offset)\n",
        "        \n",
        "        img = Image.fromarray(img)\n",
        "    \n",
        "        w, h = img.size\n",
        "        if custom_downsample > 1:\n",
        "            img = img.resize((int(w/custom_downsample), int(h/custom_downsample)))\n",
        "\n",
        "        if max_size is not None and (w > max_size or h > max_size):\n",
        "            resizeFactor = max_size/w if w > h else max_size/h\n",
        "            img = img.resize((int(w*resizeFactor), int(h*resizeFactor)))\n",
        "       \n",
        "        return img\n",
        "\n",
        "\n",
        "    def createPatches_bag_hdf5(self, save_path, patch_level=0, patch_size=256, step_size=256, save_coord=True, **kwargs):\n",
        "        contours = self.contours_tissue\n",
        "        contour_holes = self.holes_tissue\n",
        "\n",
        "        print(\"Creating patches for: \", self.name, \"...\",)\n",
        "        elapsed = time.time()\n",
        "        for idx, cont in enumerate(contours):\n",
        "            patch_gen = self._getPatchGenerator(cont, idx, patch_level, save_path, patch_size, step_size, **kwargs)\n",
        "            \n",
        "            if self.hdf5_file is None:\n",
        "                try:\n",
        "                    first_patch = next(patch_gen)\n",
        "\n",
        "                # empty contour, continue\n",
        "                except StopIteration:\n",
        "                    continue\n",
        "\n",
        "                file_path = initialize_hdf5_bag(first_patch, save_coord=save_coord)\n",
        "                self.hdf5_file = file_path\n",
        "\n",
        "            for patch in patch_gen:\n",
        "                savePatchIter_bag_hdf5(patch)\n",
        "\n",
        "        return self.hdf5_file\n",
        "\n",
        "\n",
        "    def _getPatchGenerator(self, cont, cont_idx, patch_level, save_path, patch_size=256, step_size=256, custom_downsample=1,\n",
        "        white_black=True, white_thresh=5, black_thresh=50, contour_fn='four_pt', use_padding=True):\n",
        "        start_x, start_y, w, h = cv2.boundingRect(cont) if cont is not None else (0, 0, self.level_dim[patch_level][0], self.level_dim[patch_level][1])\n",
        "        print(\"Bounding Box:\", start_x, start_y, w, h)\n",
        "        print(\"Contour Area:\", cv2.contourArea(cont))\n",
        "        \n",
        "        if custom_downsample > 1:\n",
        "            assert custom_downsample == 2 \n",
        "            target_patch_size = patch_size\n",
        "            patch_size = target_patch_size * 2\n",
        "            step_size = step_size * 2\n",
        "            print(\"Custom Downsample: {}, Patching at {} x {}, But Final Patch Size is {} x {}\".format(custom_downsample, patch_size, patch_size, \n",
        "                target_patch_size, target_patch_size))\n",
        "\n",
        "        patch_downsample = (int(self.level_downsamples[patch_level][0]), int(self.level_downsamples[patch_level][1]))\n",
        "        ref_patch_size = (patch_size*patch_downsample[0], patch_size*patch_downsample[1])\n",
        "        \n",
        "        step_size_x = step_size * patch_downsample[0]\n",
        "        step_size_y = step_size * patch_downsample[1]\n",
        "        \n",
        "        if isinstance(contour_fn, str):\n",
        "            if contour_fn == 'four_pt':\n",
        "                cont_check_fn = isInContourV3_Easy(contour=cont, patch_size=ref_patch_size[0], center_shift=0.5)\n",
        "            elif contour_fn == 'four_pt_hard':\n",
        "                cont_check_fn = isInContourV3_Hard(contour=cont, patch_size=ref_patch_size[0], center_shift=0.5)\n",
        "            elif contour_fn == 'center':\n",
        "                cont_check_fn = isInContourV2(contour=cont, patch_size=ref_patch_size[0])\n",
        "            elif contour_fn == 'basic':\n",
        "                cont_check_fn = isInContourV1(contour=cont)\n",
        "            else:\n",
        "                raise NotImplementedError\n",
        "        else:\n",
        "            assert isinstance(contour_fn, Contour_Checking_fn)\n",
        "            cont_check_fn = contour_fn\n",
        "\n",
        "        img_w, img_h = self.level_dim[0]\n",
        "        if use_padding:\n",
        "            stop_y = start_y+h\n",
        "            stop_x = start_x+w\n",
        "        else:\n",
        "            stop_y = min(start_y+h, img_h-ref_patch_size[1])\n",
        "            stop_x = min(start_x+w, img_w-ref_patch_size[0])\n",
        "\n",
        "        count = 0\n",
        "        for y in range(start_y, stop_y, step_size_y):\n",
        "            for x in range(start_x, stop_x, step_size_x):\n",
        "\n",
        "                if not self.isInContours(cont_check_fn, (x,y), self.holes_tissue[cont_idx], ref_patch_size[0]): #point not inside contour and its associated holes\n",
        "                    continue    \n",
        "                \n",
        "                count+=1\n",
        "                patch_PIL = self.wsi.read_region((x,y), patch_level, (patch_size, patch_size)).convert('RGB')\n",
        "                if custom_downsample > 1:\n",
        "                    patch_PIL = patch_PIL.resize((target_patch_size, target_patch_size))\n",
        "                \n",
        "                if white_black:\n",
        "                    if isBlackPatch(np.array(patch_PIL), rgbThresh=black_thresh) or isWhitePatch(np.array(patch_PIL), satThresh=white_thresh): \n",
        "                        continue\n",
        "\n",
        "                patch_info = {'x':x // (patch_downsample[0] * custom_downsample), 'y':y // (patch_downsample[1] * custom_downsample), 'cont_idx':cont_idx, 'patch_level':patch_level, \n",
        "                'downsample': self.level_downsamples[patch_level], 'downsampled_level_dim': tuple(np.array(self.level_dim[patch_level])//custom_downsample), 'level_dim': self.level_dim[patch_level],\n",
        "                'patch_PIL':patch_PIL, 'name':self.name, 'save_path':save_path}\n",
        "\n",
        "                yield patch_info\n",
        "\n",
        "        \n",
        "        print(\"patches extracted: {}\".format(count))\n",
        "\n",
        "    @staticmethod\n",
        "    def isInHoles(holes, pt, patch_size):\n",
        "        for hole in holes:\n",
        "            if cv2.pointPolygonTest(hole, (pt[0]+patch_size/2, pt[1]+patch_size/2), False) > 0:\n",
        "                return 1\n",
        "        \n",
        "        return 0\n",
        "\n",
        "    @staticmethod\n",
        "    def isInContours(cont_check_fn, pt, holes=None, patch_size=256):\n",
        "        if cont_check_fn(pt):\n",
        "            if holes is not None:\n",
        "                return not WholeSlideImage.isInHoles(holes, pt, patch_size)\n",
        "            else:\n",
        "                return 1\n",
        "        return 0\n",
        "    \n",
        "    @staticmethod\n",
        "    def scaleContourDim(contours, scale):\n",
        "        return [np.array(cont * scale, dtype='int32') for cont in contours]\n",
        "\n",
        "    @staticmethod\n",
        "    def scaleHolesDim(contours, scale):\n",
        "        return [[np.array(hole * scale, dtype = 'int32') for hole in holes] for holes in contours]\n",
        "\n",
        "    def _assertLevelDownsamples(self):\n",
        "        level_downsamples = []\n",
        "        dim_0 = self.wsi.level_dimensions[0]   #(4000,4000)\n",
        "        \n",
        "        for downsample, dim in zip(self.wsi.level_downsamples, self.wsi.level_dimensions):\n",
        "            estimated_downsample = (dim_0[0]/float(dim[0]), dim_0[1]/float(dim[1]))\n",
        "            level_downsamples.append(estimated_downsample) if estimated_downsample != (downsample, downsample) else level_downsamples.append((downsample, downsample))\n",
        "        \n",
        "        return level_downsamples\n",
        "\n",
        "    def process_contours(self, save_path, patch_level=0, patch_size=256, step_size=256, **kwargs):\n",
        "        save_path_hdf5 = os.path.join(save_path, str(self.name) + '.h5')\n",
        "        print(\"Creating patches for: \", self.name, \"...\",)\n",
        "        elapsed = time.time()\n",
        "        n_contours = len(self.contours_tissue)\n",
        "        print(\"Total number of contours to process: \", n_contours)\n",
        "        fp_chunk_size = math.ceil(n_contours * 0.05)\n",
        "        init = True\n",
        "        for idx, cont in enumerate(self.contours_tissue):\n",
        "            if (idx + 1) % fp_chunk_size == fp_chunk_size:\n",
        "                print('Processing contour {}/{}'.format(idx, n_contours))\n",
        "            \n",
        "            asset_dict, attr_dict = self.process_contour(cont, self.holes_tissue[idx], patch_level, save_path, patch_size, step_size, **kwargs)\n",
        "            if len(asset_dict) > 0:\n",
        "                if init:\n",
        "                    save_hdf5(save_path_hdf5, asset_dict, attr_dict, mode='w')\n",
        "                    init = False\n",
        "                else:\n",
        "                    save_hdf5(save_path_hdf5, asset_dict, mode='a')\n",
        "\n",
        "        return self.hdf5_file\n",
        "\n",
        "\n",
        "    def process_contour(self, cont, contour_holes, patch_level, save_path, patch_size = 256, step_size = 256,\n",
        "        contour_fn='four_pt', use_padding=True, top_left=None, bot_right=None):\n",
        "        start_x, start_y, w, h = cv2.boundingRect(cont) if cont is not None else (0, 0, self.level_dim[patch_level][0], self.level_dim[patch_level][1])\n",
        "\n",
        "        patch_downsample = (int(self.level_downsamples[patch_level][0]), int(self.level_downsamples[patch_level][1]))\n",
        "        ref_patch_size = (patch_size*patch_downsample[0], patch_size*patch_downsample[1])\n",
        "        \n",
        "        img_w, img_h = self.level_dim[0]\n",
        "        if use_padding:\n",
        "            stop_y = start_y+h\n",
        "            stop_x = start_x+w\n",
        "        else:\n",
        "            stop_y = min(start_y+h, img_h-ref_patch_size[1]+1)\n",
        "            stop_x = min(start_x+w, img_w-ref_patch_size[0]+1)\n",
        "        \n",
        "        print(\"Bounding Box:\", start_x, start_y, w, h)\n",
        "        print(\"Contour Area:\", cv2.contourArea(cont))\n",
        "\n",
        "        if bot_right is not None:\n",
        "            stop_y = min(bot_right[1], stop_y)\n",
        "            stop_x = min(bot_right[0], stop_x)\n",
        "        if top_left is not None:\n",
        "            start_y = max(top_left[1], start_y)\n",
        "            start_x = max(top_left[0], start_x)\n",
        "\n",
        "        if bot_right is not None or top_left is not None:\n",
        "            w, h = stop_x - start_x, stop_y - start_y\n",
        "            if w <= 0 or h <= 0:\n",
        "                print(\"Contour is not in specified ROI, skip\")\n",
        "                return {}, {}\n",
        "            else:\n",
        "                print(\"Adjusted Bounding Box:\", start_x, start_y, w, h)\n",
        "    \n",
        "        if isinstance(contour_fn, str):\n",
        "            if contour_fn == 'four_pt':\n",
        "                cont_check_fn = isInContourV3_Easy(contour=cont, patch_size=ref_patch_size[0], center_shift=0.5)\n",
        "            elif contour_fn == 'four_pt_hard':\n",
        "                cont_check_fn = isInContourV3_Hard(contour=cont, patch_size=ref_patch_size[0], center_shift=0.5)\n",
        "            elif contour_fn == 'center':\n",
        "                cont_check_fn = isInContourV2(contour=cont, patch_size=ref_patch_size[0])\n",
        "            elif contour_fn == 'basic':\n",
        "                cont_check_fn = isInContourV1(contour=cont)\n",
        "            else:\n",
        "                raise NotImplementedError\n",
        "        else:\n",
        "            assert isinstance(contour_fn, Contour_Checking_fn)\n",
        "            cont_check_fn = contour_fn\n",
        "\n",
        "        \n",
        "        step_size_x = step_size * patch_downsample[0]\n",
        "        step_size_y = step_size * patch_downsample[1]\n",
        "\n",
        "        x_range = np.arange(start_x, stop_x, step=step_size_x)\n",
        "        y_range = np.arange(start_y, stop_y, step=step_size_y)\n",
        "        x_coords, y_coords = np.meshgrid(x_range, y_range, indexing='ij')\n",
        "        coord_candidates = np.array([x_coords.flatten(), y_coords.flatten()]).transpose()\n",
        "\n",
        "        num_workers = mp.cpu_count()\n",
        "        if num_workers > 4:\n",
        "            num_workers = 4\n",
        "        pool = mp.Pool(num_workers)\n",
        "\n",
        "        iterable = [(coord, contour_holes, ref_patch_size[0], cont_check_fn) for coord in coord_candidates]\n",
        "        results = pool.starmap(WholeSlideImage.process_coord_candidate, iterable)\n",
        "        pool.close()\n",
        "        results = np.array([result for result in results if result is not None])\n",
        "        \n",
        "        print('Extracted {} coordinates'.format(len(results)))\n",
        "\n",
        "        if len(results)>1:\n",
        "            asset_dict = {'coords' :          results}\n",
        "            \n",
        "            attr = {'patch_size' :            patch_size, # To be considered...\n",
        "                    'patch_level' :           patch_level,\n",
        "                    'downsample':             self.level_downsamples[patch_level],\n",
        "                    'downsampled_level_dim' : tuple(np.array(self.level_dim[patch_level])),\n",
        "                    'level_dim':              self.level_dim[patch_level],\n",
        "                    'name':                   self.name,\n",
        "                    'save_path':              save_path}\n",
        "\n",
        "            attr_dict = { 'coords' : attr}\n",
        "            return asset_dict, attr_dict\n",
        "\n",
        "        else:\n",
        "            return {}, {}\n",
        "\n",
        "    @staticmethod\n",
        "    def process_coord_candidate(coord, contour_holes, ref_patch_size, cont_check_fn):\n",
        "        if WholeSlideImage.isInContours(cont_check_fn, coord, contour_holes, ref_patch_size):\n",
        "            return coord\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    def visHeatmap(self, scores, coords, vis_level=-1, \n",
        "                   top_left=None, bot_right=None,\n",
        "                   patch_size=(256, 256), \n",
        "                   blank_canvas=False, canvas_color=(220, 20, 50), alpha=0.4, \n",
        "                   blur=False, overlap=0.0, \n",
        "                   segment=True, use_holes=True,\n",
        "                   convert_to_percentiles=False, \n",
        "                   binarize=False, thresh=0.5,\n",
        "                   max_size=None,\n",
        "                   custom_downsample = 1,\n",
        "                   cmap='coolwarm'):\n",
        "\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            scores (numpy array of float): Attention scores \n",
        "            coords (numpy array of int, n_patches x 2): Corresponding coordinates (relative to lvl 0)\n",
        "            vis_level (int): WSI pyramid level to visualize\n",
        "            patch_size (tuple of int): Patch dimensions (relative to lvl 0)\n",
        "            blank_canvas (bool): Whether to use a blank canvas to draw the heatmap (vs. using the original slide)\n",
        "            canvas_color (tuple of uint8): Canvas color\n",
        "            alpha (float [0, 1]): blending coefficient for overlaying heatmap onto original slide\n",
        "            blur (bool): apply gaussian blurring\n",
        "            overlap (float [0 1]): percentage of overlap between neighboring patches (only affect radius of blurring)\n",
        "            segment (bool): whether to use tissue segmentation contour (must have already called self.segmentTissue such that \n",
        "                            self.contours_tissue and self.holes_tissue are not None\n",
        "            use_holes (bool): whether to also clip out detected tissue cavities (only in effect when segment == True)\n",
        "            convert_to_percentiles (bool): whether to convert attention scores to percentiles\n",
        "            binarize (bool): only display patches > threshold\n",
        "            threshold (float): binarization threshold\n",
        "            max_size (int): Maximum canvas size (clip if goes over)\n",
        "            custom_downsample (int): additionally downscale the heatmap by specified factor\n",
        "            cmap (str): name of matplotlib colormap to use\n",
        "        \"\"\"\n",
        "\n",
        "        if vis_level < 0:\n",
        "            vis_level = self.wsi.get_best_level_for_downsample(32)\n",
        "\n",
        "        downsample = self.level_downsamples[vis_level]\n",
        "        scale = [1/downsample[0], 1/downsample[1]] # Scaling from 0 to desired level\n",
        "                \n",
        "        if len(scores.shape) == 2:\n",
        "            scores = scores.flatten()\n",
        "\n",
        "        if binarize:\n",
        "            if thresh < 0:\n",
        "                threshold = 1.0/len(scores)\n",
        "                \n",
        "            else:\n",
        "                threshold =  thresh\n",
        "        \n",
        "        else:\n",
        "            threshold = 0.0\n",
        "\n",
        "        ##### calculate size of heatmap and filter coordinates/scores outside specified bbox region #####\n",
        "        if top_left is not None and bot_right is not None:\n",
        "            scores, coords = screen_coords(scores, coords, top_left, bot_right)\n",
        "            coords = coords - top_left\n",
        "            top_left = tuple(top_left)\n",
        "            bot_right = tuple(bot_right)\n",
        "            w, h = tuple((np.array(bot_right) * scale).astype(int) - (np.array(top_left) * scale).astype(int))\n",
        "            region_size = (w, h)\n",
        "\n",
        "        else:\n",
        "            region_size = self.level_dim[vis_level]\n",
        "            top_left = (0,0)\n",
        "            bot_right = self.level_dim[0]\n",
        "            w, h = region_size\n",
        "\n",
        "        patch_size  = np.ceil(np.array(patch_size) * np.array(scale)).astype(int)\n",
        "        coords = np.ceil(coords * np.array(scale)).astype(int)\n",
        "        \n",
        "        print('\\ncreating heatmap for: ')\n",
        "        print('top_left: ', top_left, 'bot_right: ', bot_right)\n",
        "        print('w: {}, h: {}'.format(w, h))\n",
        "        print('scaled patch size: ', patch_size)\n",
        "\n",
        "        ###### normalize filtered scores ######\n",
        "        if convert_to_percentiles:\n",
        "            scores = to_percentiles(scores) \n",
        "\n",
        "        scores /= 100\n",
        "        \n",
        "        ######## calculate the heatmap of raw attention scores (before colormap) \n",
        "        # by accumulating scores over overlapped regions ######\n",
        "        \n",
        "        # heatmap overlay: tracks attention score over each pixel of heatmap\n",
        "        # overlay counter: tracks how many times attention score is accumulated over each pixel of heatmap\n",
        "        overlay = np.full(np.flip(region_size), 0).astype(float)\n",
        "        counter = np.full(np.flip(region_size), 0).astype(np.uint16)      \n",
        "        count = 0\n",
        "        for idx in range(len(coords)):\n",
        "            score = scores[idx]\n",
        "            coord = coords[idx]\n",
        "            if score >= threshold:\n",
        "                if binarize:\n",
        "                    score=1.0\n",
        "                    count+=1\n",
        "            else:\n",
        "                score=0.0\n",
        "            # accumulate attention\n",
        "            overlay[coord[1]:coord[1]+patch_size[1], coord[0]:coord[0]+patch_size[0]] += score\n",
        "            # accumulate counter\n",
        "            counter[coord[1]:coord[1]+patch_size[1], coord[0]:coord[0]+patch_size[0]] += 1\n",
        "\n",
        "        if binarize:\n",
        "            print('\\nbinarized tiles based on cutoff of {}'.format(threshold))\n",
        "            print('identified {}/{} patches as positive'.format(count, len(coords)))\n",
        "        \n",
        "        # fetch attended region and average accumulated attention\n",
        "        zero_mask = counter == 0\n",
        "\n",
        "        if binarize:\n",
        "            overlay[~zero_mask] = np.around(overlay[~zero_mask] / counter[~zero_mask])\n",
        "        else:\n",
        "            overlay[~zero_mask] = overlay[~zero_mask] / counter[~zero_mask]\n",
        "        del counter \n",
        "        if blur:\n",
        "            overlay = cv2.GaussianBlur(overlay,tuple((patch_size * (1-overlap)).astype(int) * 2 +1),0)  \n",
        "\n",
        "        if segment:\n",
        "            tissue_mask = self.get_seg_mask(region_size, scale, use_holes=use_holes, offset=tuple(top_left))\n",
        "            # return Image.fromarray(tissue_mask) # tissue mask\n",
        "        \n",
        "        if not blank_canvas:\n",
        "            # downsample original image and use as canvas\n",
        "            img = np.array(self.wsi.read_region(top_left, vis_level, region_size).convert(\"RGB\"))\n",
        "        else:\n",
        "            # use blank canvas\n",
        "            img = np.array(Image.new(size=region_size, mode=\"RGB\", color=(255,255,255))) \n",
        "\n",
        "        #return Image.fromarray(img) #raw image\n",
        "\n",
        "        print('\\ncomputing heatmap image')\n",
        "        print('total of {} patches'.format(len(coords)))\n",
        "        twenty_percent_chunk = max(1, int(len(coords) * 0.2))\n",
        "\n",
        "        if isinstance(cmap, str):\n",
        "            cmap = plt.get_cmap(cmap)\n",
        "        \n",
        "        for idx in range(len(coords)):\n",
        "            if (idx + 1) % twenty_percent_chunk == 0:\n",
        "                print('progress: {}/{}'.format(idx, len(coords)))\n",
        "            \n",
        "            score = scores[idx]\n",
        "            coord = coords[idx]\n",
        "            if score >= threshold:\n",
        "\n",
        "                # attention block\n",
        "                raw_block = overlay[coord[1]:coord[1]+patch_size[1], coord[0]:coord[0]+patch_size[0]]\n",
        "                \n",
        "                # image block (either blank canvas or orig image)\n",
        "                img_block = img[coord[1]:coord[1]+patch_size[1], coord[0]:coord[0]+patch_size[0]].copy()\n",
        "\n",
        "                # color block (cmap applied to attention block)\n",
        "                color_block = (cmap(raw_block) * 255)[:,:,:3].astype(np.uint8)\n",
        "\n",
        "                if segment:\n",
        "                    # tissue mask block\n",
        "                    mask_block = tissue_mask[coord[1]:coord[1]+patch_size[1], coord[0]:coord[0]+patch_size[0]] \n",
        "                    # copy over only tissue masked portion of color block\n",
        "                    img_block[mask_block] = color_block[mask_block]\n",
        "                else:\n",
        "                    # copy over entire color block\n",
        "                    img_block = color_block\n",
        "\n",
        "                # rewrite image block\n",
        "                img[coord[1]:coord[1]+patch_size[1], coord[0]:coord[0]+patch_size[0]] = img_block.copy()\n",
        "        \n",
        "        #return Image.fromarray(img) #overlay\n",
        "        print('Done')\n",
        "        del overlay\n",
        "\n",
        "        if blur:\n",
        "            img = cv2.GaussianBlur(img,tuple((patch_size * (1-overlap)).astype(int) * 2 +1),0)  \n",
        "\n",
        "        if alpha < 1.0:\n",
        "            img = self.block_blending(img, vis_level, top_left, bot_right, alpha=alpha, blank_canvas=blank_canvas, block_size=1024)\n",
        "        \n",
        "        img = Image.fromarray(img)\n",
        "        w, h = img.size\n",
        "\n",
        "        if custom_downsample > 1:\n",
        "            img = img.resize((int(w/custom_downsample), int(h/custom_downsample)))\n",
        "\n",
        "        if max_size is not None and (w > max_size or h > max_size):\n",
        "            resizeFactor = max_size/w if w > h else max_size/h\n",
        "            img = img.resize((int(w*resizeFactor), int(h*resizeFactor)))\n",
        "       \n",
        "        return img\n",
        "\n",
        "    \n",
        "    def block_blending(self, img, vis_level, top_left, bot_right, alpha=0.5, blank_canvas=False, block_size=1024):\n",
        "        print('\\ncomputing blend')\n",
        "        downsample = self.level_downsamples[vis_level]\n",
        "        w = img.shape[1]\n",
        "        h = img.shape[0]\n",
        "        block_size_x = min(block_size, w)\n",
        "        block_size_y = min(block_size, h)\n",
        "        print('using block size: {} x {}'.format(block_size_x, block_size_y))\n",
        "\n",
        "        shift = top_left # amount shifted w.r.t. (0,0)\n",
        "        for x_start in range(top_left[0], bot_right[0], block_size_x * int(downsample[0])):\n",
        "            for y_start in range(top_left[1], bot_right[1], block_size_y * int(downsample[1])):\n",
        "                #print(x_start, y_start)\n",
        "\n",
        "                # 1. convert wsi coordinates to image coordinates via shift and scale\n",
        "                x_start_img = int((x_start - shift[0]) / int(downsample[0]))\n",
        "                y_start_img = int((y_start - shift[1]) / int(downsample[1]))\n",
        "                \n",
        "                # 2. compute end points of blend tile, careful not to go over the edge of the image\n",
        "                y_end_img = min(h, y_start_img+block_size_y)\n",
        "                x_end_img = min(w, x_start_img+block_size_x)\n",
        "\n",
        "                if y_end_img == y_start_img or x_end_img == x_start_img:\n",
        "                    continue\n",
        "                #print('start_coord: {} end_coord: {}'.format((x_start_img, y_start_img), (x_end_img, y_end_img)))\n",
        "                \n",
        "                # 3. fetch blend block and size\n",
        "                blend_block = img[y_start_img:y_end_img, x_start_img:x_end_img] \n",
        "                blend_block_size = (x_end_img-x_start_img, y_end_img-y_start_img)\n",
        "                \n",
        "                if not blank_canvas:\n",
        "                    # 4. read actual wsi block as canvas block\n",
        "                    pt = (x_start, y_start)\n",
        "                    canvas = np.array(self.wsi.read_region(pt, vis_level, blend_block_size).convert(\"RGB\"))     \n",
        "                else:\n",
        "                    # 4. OR create blank canvas block\n",
        "                    canvas = np.array(Image.new(size=blend_block_size, mode=\"RGB\", color=(255,255,255)))\n",
        "\n",
        "                # 5. blend color block and canvas block\n",
        "                img[y_start_img:y_end_img, x_start_img:x_end_img] = cv2.addWeighted(blend_block, alpha, canvas, 1 - alpha, 0, canvas)\n",
        "        return img\n",
        "\n",
        "    def get_seg_mask(self, region_size, scale, use_holes=False, offset=(0,0)):\n",
        "        print('\\ncomputing foreground tissue mask')\n",
        "        tissue_mask = np.full(np.flip(region_size), 0).astype(np.uint8)\n",
        "        contours_tissue = self.scaleContourDim(self.contours_tissue, scale)\n",
        "        offset = tuple((np.array(offset) * np.array(scale) * -1).astype(np.int32))\n",
        "\n",
        "        contours_holes = self.scaleHolesDim(self.holes_tissue, scale)\n",
        "        contours_tissue, contours_holes = zip(*sorted(zip(contours_tissue, contours_holes), key=lambda x: cv2.contourArea(x[0]), reverse=True))\n",
        "        for idx in range(len(contours_tissue)):\n",
        "            cv2.drawContours(image=tissue_mask, contours=contours_tissue, contourIdx=idx, color=(1), offset=offset, thickness=-1)\n",
        "\n",
        "            if use_holes:\n",
        "                cv2.drawContours(image=tissue_mask, contours=contours_holes[idx], contourIdx=-1, color=(0), offset=offset, thickness=-1)\n",
        "            # contours_holes = self._scaleContourDim(self.holes_tissue, scale, holes=True, area_thresh=area_thresh)\n",
        "                \n",
        "        tissue_mask = tissue_mask.astype(bool)\n",
        "        print('detected {}/{} of region as tissue'.format(tissue_mask.sum(), tissue_mask.size))\n",
        "        return tissue_mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldkOr4bQHXo3"
      },
      "source": [
        "def stitching(file_path, wsi_object, downscale=64):\n",
        "  start = time.time()\n",
        "  heatmap = StitchCoords(\n",
        "      file_path,\n",
        "      wsi_object,\n",
        "      downscale=downscale,\n",
        "      bg_color=(0, 0, 0),\n",
        "      alpha=-1,\n",
        "      draw_grid=False,\n",
        "  )\n",
        "  total_time = time.time() - start\n",
        "\n",
        "  return heatmap, total_time\n",
        "\n",
        "\n",
        "def segment(WSI_object, seg_params, filter_params):\n",
        "  ### Start Seg Timer\n",
        "  start_time = time.time()\n",
        "\n",
        "  # Segment\n",
        "  WSI_object.segmentTissue(**seg_params, filter_params=filter_params)\n",
        "\n",
        "  ### Stop Seg Timers\n",
        "  seg_time_elapsed = time.time() - start_time\n",
        "  return WSI_object, seg_time_elapsed\n",
        "\n",
        "\n",
        "def patching(WSI_object, **kwargs):\n",
        "  ### Start Patch Timer\n",
        "  start_time = time.time()\n",
        "\n",
        "  # Patch\n",
        "  file_path = WSI_object.process_contours(**kwargs)\n",
        "\n",
        "  ### Stop Patch Timer\n",
        "  patch_time_elapsed = time.time() - start_time\n",
        "  return file_path, patch_time_elapsed\n",
        "\n",
        "\n",
        "def seg_and_patch(source, save_dir, patch_save_dir, mask_save_dir, stitch_save_dir, \n",
        "\t\t\t\t  patch_size = 256, step_size = 256, \n",
        "\t\t\t\t  seg_params = {'seg_level': -1, 'sthresh': 8, 'mthresh': 7, 'close': 4, 'use_otsu': False,\n",
        "\t\t\t\t  'keep_ids': 'none', 'exclude_ids': 'none'},\n",
        "\t\t\t\t  filter_params = {'a_t':100, 'a_h': 16, 'max_n_holes':8}, \n",
        "\t\t\t\t  vis_params = {'vis_level': -1, 'line_thickness': 500},\n",
        "\t\t\t\t  patch_params = {'use_padding': True, 'contour_fn': 'four_pt'},\n",
        "\t\t\t\t  patch_level = 0,\n",
        "\t\t\t\t  use_default_params = False, \n",
        "\t\t\t\t  seg = True, save_mask = True, \n",
        "\t\t\t\t  stitch= True, \n",
        "\t\t\t\t  patch = True, auto_skip=True, process_list = None):\n",
        "\t\n",
        "\n",
        "\n",
        "\tslides = sorted(os.listdir(source))\n",
        "\tslides = [slide for slide in slides if os.path.isfile(os.path.join(source, slide))]\n",
        "\tif process_list is None:\n",
        "\t\tdf = initialize_df(slides, seg_params, filter_params, vis_params, patch_params)\n",
        "\t\n",
        "\telse:\n",
        "\t\tdf = pd.read_csv(process_list)\n",
        "\t\tdf = initialize_df(df, seg_params, filter_params, vis_params, patch_params)\n",
        "\n",
        "\tmask = df['process'] == 1\n",
        "\tprocess_stack = df[mask]\n",
        "\n",
        "\ttotal = len(process_stack)\n",
        "\n",
        "\tlegacy_support = 'a' in df.keys()\n",
        "\tif legacy_support:\n",
        "\t\tprint('detected legacy segmentation csv file, legacy support enabled')\n",
        "\t\tdf = df.assign(**{'a_t': np.full((len(df)), int(filter_params['a_t']), dtype=np.uint32),\n",
        "\t\t'a_h': np.full((len(df)), int(filter_params['a_h']), dtype=np.uint32),\n",
        "\t\t'max_n_holes': np.full((len(df)), int(filter_params['max_n_holes']), dtype=np.uint32),\n",
        "\t\t'line_thickness': np.full((len(df)), int(vis_params['line_thickness']), dtype=np.uint32),\n",
        "\t\t'contour_fn': np.full((len(df)), patch_params['contour_fn'])})\n",
        "\n",
        "\tseg_times = 0.\n",
        "\tpatch_times = 0.\n",
        "\tstitch_times = 0.\n",
        "\n",
        "\tfor i in range(total):\n",
        "\t\tdf.to_csv(os.path.join(save_dir, 'process_list_autogen.csv'), index=False)\n",
        "\t\tidx = process_stack.index[i]\n",
        "\t\tslide = process_stack.loc[idx, 'slide_id']\n",
        "\t\tprint(\"\\n\\nprogress: {:.2f}, {}/{}\".format(i/total, i, total))\n",
        "\t\tprint('processing {}'.format(slide))\n",
        "\t\t\n",
        "\t\tdf.loc[idx, 'process'] = 0\n",
        "\t\tslide_id, _ = os.path.splitext(slide)\n",
        "\n",
        "\t\tif auto_skip and os.path.isfile(os.path.join(patch_save_dir, slide_id + '.h5')):\n",
        "\t\t\tprint('{} already exist in destination location, skipped'.format(slide_id))\n",
        "\t\t\tdf.loc[idx, 'status'] = 'already_exist'\n",
        "\t\t\tcontinue\n",
        "\t\tif auto_skip and os.path.isfile(os.path.join(mask_save_dir, slide_id + '.jpg')):\n",
        "\t\t\tprint('{} already exist in destination location(mask), skipped'.format(slide_id))\n",
        "\t\t\tdf.loc[idx, 'status'] = 'already_exist'\n",
        "\t\t\tcontinue\n",
        "\n",
        "\t\t# Inialize WSI\n",
        "\t\tfull_path = os.path.join(source, slide)\n",
        "\t\tWSI_object = WholeSlideImage(full_path)\n",
        "\t\ttry:\n",
        "\t\t\tif use_default_params:\n",
        "\t\t\t\tcurrent_vis_params = vis_params.copy()\n",
        "\t\t\t\tcurrent_filter_params = filter_params.copy()\n",
        "\t\t\t\tcurrent_seg_params = seg_params.copy()\n",
        "\t\t\t\tcurrent_patch_params = patch_params.copy()\n",
        "\t\t\t\t\n",
        "\t\t\telse:\n",
        "\t\t\t\tcurrent_vis_params = {}\n",
        "\t\t\t\tcurrent_filter_params = {}\n",
        "\t\t\t\tcurrent_seg_params = {}\n",
        "\t\t\t\tcurrent_patch_params = {}\n",
        "\n",
        "\n",
        "\t\t\t\tfor key in vis_params.keys():\n",
        "\t\t\t\t\tif legacy_support and key == 'vis_level':\n",
        "\t\t\t\t\t\tdf.loc[idx, key] = -1\n",
        "\t\t\t\t\tcurrent_vis_params.update({key: df.loc[idx, key]})\n",
        "\n",
        "\t\t\t\tfor key in filter_params.keys():\n",
        "\t\t\t\t\tif legacy_support and key == 'a_t':\n",
        "\t\t\t\t\t\told_area = df.loc[idx, 'a']\n",
        "\t\t\t\t\t\tseg_level = df.loc[idx, 'seg_level']\n",
        "\t\t\t\t\t\tscale = WSI_object.level_downsamples[seg_level]\n",
        "\t\t\t\t\t\tadjusted_area = int(old_area * (scale[0] * scale[1]) / (512 * 512))\n",
        "\t\t\t\t\t\tcurrent_filter_params.update({key: adjusted_area})\n",
        "\t\t\t\t\t\tdf.loc[idx, key] = adjusted_area\n",
        "\t\t\t\t\tcurrent_filter_params.update({key: df.loc[idx, key]})\n",
        "\n",
        "\t\t\t\tfor key in seg_params.keys():\n",
        "\t\t\t\t\tif legacy_support and key == 'seg_level':\n",
        "\t\t\t\t\t\tdf.loc[idx, key] = -1\n",
        "\t\t\t\t\tcurrent_seg_params.update({key: df.loc[idx, key]})\n",
        "\n",
        "\t\t\t\tfor key in patch_params.keys():\n",
        "\t\t\t\t\tcurrent_patch_params.update({key: df.loc[idx, key]})\n",
        "\n",
        "\t\t\tif current_vis_params['vis_level'] < 0:\n",
        "\t\t\t\tif len(WSI_object.level_dim) == 1:\n",
        "\t\t\t\t\tcurrent_vis_params['vis_level'] = 0\n",
        "\t\t\t\t\n",
        "\t\t\t\telse:\t\n",
        "\t\t\t\t\twsi = WSI_object.getOpenSlide()\n",
        "\t\t\t\t\tbest_level = wsi.get_best_level_for_downsample(64)\n",
        "\t\t\t\t\tcurrent_vis_params['vis_level'] = best_level\n",
        "\n",
        "\t\t\tif current_seg_params['seg_level'] < 0:\n",
        "\t\t\t\tif len(WSI_object.level_dim) == 1:\n",
        "\t\t\t\t\tcurrent_seg_params['seg_level'] = 0\n",
        "\t\t\t\t\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\twsi = WSI_object.getOpenSlide()\n",
        "\t\t\t\t\tbest_level = wsi.get_best_level_for_downsample(64)\n",
        "\t\t\t\t\tcurrent_seg_params['seg_level'] = best_level\n",
        "\n",
        "\t\t\tkeep_ids = str(current_seg_params['keep_ids'])\n",
        "\t\t\tif keep_ids != 'none' and len(keep_ids) > 0:\n",
        "\t\t\t\tstr_ids = current_seg_params['keep_ids']\n",
        "\t\t\t\tcurrent_seg_params['keep_ids'] = np.array(str_ids.split(',')).astype(int)\n",
        "\t\t\telse:\n",
        "\t\t\t\tcurrent_seg_params['keep_ids'] = []\n",
        "\n",
        "\t\t\texclude_ids = str(current_seg_params['exclude_ids'])\n",
        "\t\t\tif exclude_ids != 'none' and len(exclude_ids) > 0:\n",
        "\t\t\t\tstr_ids = current_seg_params['exclude_ids']\n",
        "\t\t\t\tcurrent_seg_params['exclude_ids'] = np.array(str_ids.split(',')).astype(int)\n",
        "\t\t\telse:\n",
        "\t\t\t\tcurrent_seg_params['exclude_ids'] = []\n",
        "\n",
        "\t\t\tw, h = WSI_object.level_dim[current_seg_params['seg_level']] \n",
        "\t\t\tif w * h > 1e15:\n",
        "\t\t\t\tprint('level_dim {} x {} is likely too large for successful segmentation, aborting'.format(w, h))\n",
        "\t\t\t\tdf.loc[idx, 'status'] = 'failed_seg'\n",
        "\t\t\t\tcontinue\n",
        "\n",
        "\t\t\tdf.loc[idx, 'vis_level'] = current_vis_params['vis_level']\n",
        "\t\t\tdf.loc[idx, 'seg_level'] = current_seg_params['seg_level']\n",
        "\n",
        "\n",
        "\t\t\tseg_time_elapsed = -1\n",
        "\t\t\n",
        "\t\t\tif seg:\n",
        "\t\t\t\tWSI_object, seg_time_elapsed = segment(WSI_object, current_seg_params, current_filter_params) \n",
        "\t\texcept (AttributeError,IndexError) as e:\n",
        "\t\t\tseg_times += -1\n",
        "\t\t\tpatch_times += -1\n",
        "\t\t\tstitch_times += -1\n",
        "\t\t\tprint(\" Exception Occured in \"+slide)\n",
        "\t\t\tcontinue\n",
        "\t\tif save_mask:\n",
        "\t\t\tmask = WSI_object.visWSI(**current_vis_params)\n",
        "\t\t\tmask_path = os.path.join(mask_save_dir, slide_id+'.jpg')\n",
        "\t\t\tmask.save(mask_path)\n",
        "\n",
        "\t\tpatch_time_elapsed = -1 # Default time\n",
        "\t\tif patch:\n",
        "\t\t\tcurrent_patch_params.update({'patch_level': patch_level, 'patch_size': patch_size, 'step_size': step_size, \n",
        "\t\t\t\t\t\t\t\t\t\t 'save_path': patch_save_dir})\n",
        "\t\t\tfile_path, patch_time_elapsed = patching(WSI_object = WSI_object,  **current_patch_params,)\n",
        "\t\t\n",
        "\t\tstitch_time_elapsed = -1\n",
        "\t\tif stitch:\n",
        "\t\t\tfile_path = os.path.join(patch_save_dir, slide_id+'.h5')\n",
        "\t\t\tif os.path.isfile(file_path):\n",
        "\t\t\t\theatmap, stitch_time_elapsed = stitching(file_path, WSI_object, downscale=64)\n",
        "\t\t\t\tstitch_path = os.path.join(stitch_save_dir, slide_id+'.jpg')\n",
        "\t\t\t\theatmap.save(stitch_path)\n",
        "\n",
        "\t\tprint(\"segmentation took {} seconds\".format(seg_time_elapsed))\n",
        "\t\tprint(\"patching took {} seconds\".format(patch_time_elapsed))\n",
        "\t\tprint(\"stitching took {} seconds\".format(stitch_time_elapsed))\n",
        "\t\tdf.loc[idx, 'status'] = 'processed'\n",
        "\n",
        "\t\tseg_times += seg_time_elapsed\n",
        "\t\tpatch_times += patch_time_elapsed\n",
        "\t\tstitch_times += stitch_time_elapsed\n",
        "\n",
        "\tseg_times /= total\n",
        "\tpatch_times /= total\n",
        "\tstitch_times /= total\n",
        "\n",
        "\tdf.to_csv(os.path.join(save_dir, 'process_list_autogen.csv'), index=False)\n",
        "\tprint(\"average segmentation time in s per slide: {}\".format(seg_times))\n",
        "\tprint(\"average patching time in s per slide: {}\".format(patch_times))\n",
        "\tprint(\"average stiching time in s per slide: {}\".format(stitch_times))\n",
        "\t\t\n",
        "\treturn seg_times, patch_times"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VS_HkJ6HcYL"
      },
      "source": [
        "def wsi_preprocess(f_name):\n",
        "\tprint(\"Preprocessing : \",f_name)\n",
        "\t# 'gdrive/My Drive/Data_Directory'\n",
        "\tsource = 'gdrive/My Drive/Regions' #\n",
        "\tsave_dir = 'gdrive/My Drive/RESULTS_DIRECTORY'\n",
        "\t#process_list = 'gdrive/My Drive/RESULTS_DIRECTORY/bwh_biopsy.csv'\n",
        "\tpatch_save_dir = os.path.join(save_dir, 'patches') #  \n",
        "\tmask_save_dir = os.path.join(save_dir, 'masks')\n",
        "\tstitch_save_dir = os.path.join(save_dir, 'stiches')\n",
        "\n",
        "\tdirectories = {'source': source, \n",
        "\t\t\t\t\t'save_dir': save_dir,\n",
        "\t\t\t\t\t'patch_save_dir': patch_save_dir, \n",
        "\t\t\t\t\t'mask_save_dir' : mask_save_dir, \n",
        "\t\t\t\t\t'stitch_save_dir': stitch_save_dir} \n",
        "\n",
        "\tfor key, val in directories.items():\n",
        "\t\t\t#print(\"{} : {}\".format(key, val))\n",
        "\t\t\tif key not in ['source']:\n",
        "\t\t\t\tos.makedirs(val, exist_ok=True)\n",
        "\t\n",
        "\tseg_params = {'seg_level': -1, 'sthresh': 5, 'mthresh': 15, 'close': 2, 'use_otsu': False,'keep_ids': 'none', 'exclude_ids': 'none'}\n",
        "\tfilter_params = {'a_t':1, 'a_h': 1, 'max_n_holes':2}\n",
        "\tvis_params = {'vis_level': -1, 'line_thickness': 50}\n",
        "\tpatch_params = {'use_padding': True, 'contour_fn': 'four_pt',} # four_pt_hard\n",
        "\tparameters = {'seg_params': seg_params,\n",
        "\t\t\t\t\t\t'filter_params': filter_params,\n",
        "\t\t\t\t\t\t'patch_params': patch_params,\n",
        "\t\t\t\t\t\t'vis_params': vis_params}\n",
        "\n",
        "\tpatch_size = 256\n",
        "\tstep_size = 256\n",
        "\tseg = True\n",
        "\tstitch = True\n",
        "\tpatch  = True\n",
        "\tpatch_level = 0\n",
        "\tno_auto_skip = True\n",
        "\tprocess_list = None\n",
        "\tseg_times, patch_times = seg_and_patch(**directories, **parameters,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\tpatch_size = patch_size, step_size=step_size, \n",
        "\t\t\t\t\t\t\t\t\t\t\t\tseg = seg,  use_default_params=False, save_mask = True, \n",
        "\t\t\t\t\t\t\t\t\t\t\t\tstitch= stitch,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\tpatch_level=patch_level, patch = patch,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\tprocess_list = process_list, auto_skip=no_auto_skip)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExlHIuvGbfJF"
      },
      "source": [
        "# Split one WSI image to regions to apply preprocess "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9SHf5MaFXjU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OogGRKwCPAdi"
      },
      "source": [
        "# Gives image names which are already broken into regions\n",
        "def getProcessedImages(category):\n",
        "    lines = []\n",
        "    if category == 0:\n",
        "        path = 'gdrive/My Drive/RESULTS_DIRECTORY/Splitted_Images.txt'\n",
        "    elif category == 1:\n",
        "        path = 'gdrive/My Drive/RESULTS_DIRECTORY/Processed_Images.txt'\n",
        "    with open(path, 'r') as file:\n",
        "        line = file.readline().strip()\n",
        "        while line != \"\":\n",
        "            lines.append(line)\n",
        "            line = file.readline().strip()\n",
        "    return lines\n",
        "\n",
        "# Update the text file with new image name which is broken into regions\n",
        "def writeProcessedImages(data,category):\n",
        "    str_data=\"\"\n",
        "    if category == 0:\n",
        "        path = 'gdrive/My Drive/RESULTS_DIRECTORY/Splitted_Images.txt'\n",
        "    elif category == 1:\n",
        "        path = 'gdrive/My Drive/RESULTS_DIRECTORY/Processed_Images.txt'\n",
        "\n",
        "    for i in data:\n",
        "        str_data += i+\"\\n\"\n",
        "    with open(path,'w') as file:\n",
        "        file.write(str_data)\n",
        "\n",
        "\n",
        "# Split given image to regions\n",
        "def splitRegions(file):\n",
        "    source = 'gdrive/My Drive/Data_Directory' \n",
        "    regions_dir = 'gdrive/My Drive/Regions'\n",
        "\n",
        "    file_name = file.split(\".\")\n",
        "\n",
        "    full_path = os.path.join(source, file)\n",
        "    #print(full_path)\n",
        "    wsi = openslide.OpenSlide(full_path)\n",
        "\n",
        "    # Read the image by 4000 x 4000 slides. To identify all the regions following method used.\n",
        "    wsi_w, wsi_h = wsi.level_dimensions[0]\n",
        "\n",
        "    width_coor=[i for i in range(0,wsi_w,4000)]\n",
        "    height_coor=[i for i in range(0,wsi_h,4000)]\n",
        "    \n",
        "    # Adding last pixel coordinate to calclute acurate region sizes\n",
        "    width_coor.append(wsi_w)\n",
        "    height_coor.append(wsi_h)\n",
        "\n",
        "    for ht in range (len(height_coor)-1):\n",
        "        for wd in range (len(width_coor)-1):\n",
        "            w0,h0 = width_coor[wd], height_coor[ht]\n",
        "            newFileName = file_name[0]+\"-\"+str(w0)+\"_\"+str(h0)+\".tiff\"  # Save Image with coordinate (width,height) \n",
        "            savePath = os.path.join(regions_dir, newFileName)\n",
        "            if not (os.path.isfile(savePath)):\n",
        "                h_size,w_size = (height_coor[ht+1] - height_coor[ht]) , (width_coor[wd+1] - width_coor[wd])\n",
        "                wsi_region = wsi.read_region((w0,h0),0,(w_size,h_size))\n",
        "                wsi_region.convert('RGB').save(savePath)\n",
        "                print(newFileName+\" file written.\")\n",
        "            else:\n",
        "                print(newFileName+\" already written.\")\n",
        "    \n",
        "    print(file_name[0]+\" completely broken into regions\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0l913EqPsIrH"
      },
      "source": [
        "# Remove splitted region files in Regions Directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecW8Ck4XsH8Q"
      },
      "source": [
        "def removeProcessedRegions():\n",
        "    source = 'gdrive/My Drive/Regions'\n",
        "    files = os.listdir(source)\n",
        "\n",
        "    for file in files:\n",
        "        full_path = os.path.join(source, file)\n",
        "        os.remove(full_path)\n",
        "    print(\"Region Directory Cleared\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLPhTmb2BfTi"
      },
      "source": [
        "# Main Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKwElg_rBHBU"
      },
      "source": [
        "def main():\n",
        "    source = 'gdrive/My Drive/Data_Directory' \n",
        "    slides = sorted(os.listdir(source))\n",
        "    slides = [slide for slide in slides if os.path.isfile(os.path.join(source, slide))]\n",
        "    for slide in slides:\n",
        "        file_name = slide.split(\".\")\n",
        "\n",
        "        #For Split regions\n",
        "        splittedImages = getProcessedImages(0)\n",
        "        \n",
        "        if file_name[0] in splittedImages:\n",
        "            print(file_name[0]+\" is already Splitted...\")            \n",
        "        else:\n",
        "            splitRegions(slide)\n",
        "            splittedImages.append(file_name[0])\n",
        "            writeProcessedImages(splittedImages,0)\n",
        "            \n",
        "\n",
        "        # For Preprocess Images\n",
        "        preprocessedImages = getProcessedImages(1)\n",
        "\n",
        "        if file_name[0] in preprocessedImages:\n",
        "            print(file_name[0]+\" is already Processed...\")\n",
        "            continue\n",
        "            \n",
        "        else:\n",
        "            # Always Preprocess region images on the regions folder.\n",
        "            wsi_preprocess(file_name[0])\n",
        "            preprocessedImages.append(file_name[0])\n",
        "            writeProcessedImages(preprocessedImages,1)\n",
        "\n",
        "        # Clear Region forlder after preprocessing one image\n",
        "        if file_name[0] in preprocessedImages and file_name[0] in splittedImages:\n",
        "            removeProcessedRegions()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bk5CdiMMDFOa"
      },
      "source": [
        "main()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyfBWQVWoIgz"
      },
      "source": [
        "#comments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1bTPYaheDc2"
      },
      "source": [
        "'''files = os.listdir('gdrive/My Drive/Regions')\n",
        "\n",
        "for f in files:\n",
        "\tprint(f)'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Aqr5NQeS--W"
      },
      "source": [
        "'''print(seg_times, patch_times)'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzNcPOFY2WVJ"
      },
      "source": [
        "'''process_list = 'gdrive/My Drive/RESULTS_DIRECTORY/bwh_biopsy.csv''''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uy-B48FPdGYN"
      },
      "source": [
        "'''df = pd.read_csv(process_list,index_col=False)'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AM5gxu02Yji"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYygrzTCThBn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOPil_1S4CSM"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5zhVcbjU8F1"
      },
      "source": [
        "'''import os\n",
        "files = os.listdir('gdrive/My Drive/RESULTS_DIRECTORY/patches') \n",
        "allCoordinates = np.empty((0,2), int)\n",
        "for f in files:\n",
        "    file_path = os.path.join('gdrive/My Drive/RESULTS_DIRECTORY/patches', f)   \n",
        "    fileName = f.split(\".\")\n",
        "    fileName = fileName[0].split(\"-\")\n",
        "    coordinates = [int(x) for x in fileName[1].split(\"_\")]\n",
        "    \n",
        "    with h5py.File(file_path,'r') as hdf5_file:\n",
        "        ls = list(hdf5_file.keys())\n",
        "        dset = hdf5_file['coords']\n",
        "        print(type(dset))\n",
        "        for i in dset:\n",
        "            allCoordinates = np.append(allCoordinates,[[i[0]+coordinates[0] , i[1]+coordinates[1]]], axis = 0)\n",
        "            print(i[0]+coordinates[0] , i[1]+coordinates[1])\n",
        "        #for name, value in dset.attrs.items():\n",
        "        #    print(name, value)\n",
        "        #print(np.array(dset))\n",
        "        #print(dset[:],np.array(dset))\n",
        "    print(\"\\n\\n\") \n",
        "#print(allCoordinates) '''\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iH-fN7Bnuxzt"
      },
      "source": [
        "  "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}