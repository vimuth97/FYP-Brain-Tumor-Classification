{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "create_splits.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "cGpa8K910IPR",
        "ciKjpX6g1la5",
        "cg-WQryayiW6"
      ],
      "authorship_tag": "ABX9TyPuuLZzs0oBy+I3JrgkESKq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vimuth97/FYP-Brain-Tumor-Classification/blob/main/Basic%20pathology%20model/create_splits.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lS2ZNIGyyBcG"
      },
      "source": [
        "import os\n",
        "import argparse\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from scipy import stats"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYYp54lDzYNf",
        "outputId": "83d3751d-e5d9-4e7e-a4af-ff8a4bc97212"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlwGrGamz2-m",
        "outputId": "ac8d0ad0-712f-4684-bb8f-a63fd9913a3b"
      },
      "source": [
        "%cd /content/gdrive/MyDrive/WSI_classification"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/WSI_classification\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGpa8K910IPR"
      },
      "source": [
        "#Dataset Generic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22ZCWumb0I4K"
      },
      "source": [
        "def save_splits(split_datasets, column_keys, filename, boolean_style=False):\n",
        "\tsplits = [split_datasets[i].slide_data['slide_id'] for i in range(len(split_datasets))]\n",
        "\tif not boolean_style:\n",
        "\t\tdf = pd.concat(splits, ignore_index=True, axis=1)\n",
        "\t\tdf.columns = column_keys\n",
        "\telse:\n",
        "\t\tdf = pd.concat(splits, ignore_index = True, axis=0)\n",
        "\t\tindex = df.values.tolist()\n",
        "\t\tone_hot = np.eye(len(split_datasets)).astype(bool)\n",
        "\t\tbool_array = np.repeat(one_hot, [len(dset) for dset in split_datasets], axis=0)\n",
        "\t\tdf = pd.DataFrame(bool_array, index=index, columns = ['train', 'val', 'test'])\n",
        "\n",
        "\tdf.to_csv(filename)\n",
        "\tprint()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5vmeBL40LsR"
      },
      "source": [
        "class Generic_WSI_Classification_Dataset(Dataset):\n",
        "\n",
        "\tdef __init__(self,\n",
        "\t\tcsv_path = 'dataset_csv/ccrcc_clean.csv',\n",
        "\t\tshuffle = False, \n",
        "\t\tseed = 7, \n",
        "\t\tprint_info = True,\n",
        "\t\tlabel_dict = {},\n",
        "\t\tfilter_dict = {},\n",
        "\t\tignore=[],\n",
        "\t\tpatient_strat=False,\n",
        "\t\tlabel_col = None,\n",
        "\t\tpatient_voting = 'max',\n",
        "\t\t):\n",
        "\t\t\"\"\"\n",
        "\t\tArgs:\n",
        "\t\t\tcsv_file (string): Path to the csv file with annotations.\n",
        "\t\t\tshuffle (boolean): Whether to shuffle\n",
        "\t\t\tseed (int): random seed for shuffling the data\n",
        "\t\t\tprint_info (boolean): Whether to print a summary of the dataset\n",
        "\t\t\tlabel_dict (dict): Dictionary with key, value pairs for converting str labels to int\n",
        "\t\t\tignore (list): List containing class labels to ignore\n",
        "\t\t\"\"\"\n",
        "\t\tself.label_dict = label_dict\n",
        "\t\tself.num_classes = len(set(self.label_dict.values()))\n",
        "\t\tself.seed = seed\n",
        "\t\tself.print_info = print_info\n",
        "\t\tself.patient_strat = patient_strat\n",
        "\t\tself.train_ids, self.val_ids, self.test_ids  = (None, None, None)\n",
        "\t\tself.data_dir = None\n",
        "\t\tif not label_col:\n",
        "\t\t\tlabel_col = 'label'\n",
        "\t\tself.label_col = label_col\n",
        "\n",
        "\t\tslide_data = pd.read_csv(csv_path)\n",
        "\t\tslide_data = self.filter_df(slide_data, filter_dict)\n",
        "\t\tslide_data = self.df_prep(slide_data, self.label_dict, ignore, self.label_col)\n",
        "\n",
        "\t\t###shuffle data\n",
        "\t\tif shuffle:\n",
        "\t\t\tnp.random.seed(seed)\n",
        "\t\t\tnp.random.shuffle(slide_data)\n",
        "\n",
        "\t\tself.slide_data = slide_data\n",
        "\n",
        "\t\tself.patient_data_prep(patient_voting)\n",
        "\t\tself.cls_ids_prep()\n",
        "\n",
        "\t\tif print_info:\n",
        "\t\t\tself.summarize()\n",
        "\n",
        "\tdef cls_ids_prep(self):\n",
        "\t\t# store ids corresponding each class at the patient or case level\n",
        "\t\tself.patient_cls_ids = [[] for i in range(self.num_classes)]\t\t\n",
        "\t\tfor i in range(self.num_classes):\n",
        "\t\t\tself.patient_cls_ids[i] = np.where(self.patient_data['label'] == i)[0]\n",
        "\n",
        "\t\t# store ids corresponding each class at the slide level\n",
        "\t\tself.slide_cls_ids = [[] for i in range(self.num_classes)]\n",
        "\t\tfor i in range(self.num_classes):\n",
        "\t\t\tself.slide_cls_ids[i] = np.where(self.slide_data['label'] == i)[0]\n",
        "\n",
        "\tdef patient_data_prep(self, patient_voting='max'):\n",
        "\t\tpatients = np.unique(np.array(self.slide_data['case_id'])) # get unique patients\n",
        "\t\tpatient_labels = []\n",
        "\t\t\n",
        "\t\tfor p in patients:\n",
        "\t\t\tlocations = self.slide_data[self.slide_data['case_id'] == p].index.tolist()\n",
        "\t\t\tassert len(locations) > 0\n",
        "\t\t\tlabel = self.slide_data['label'][locations].values\n",
        "\t\t\tif patient_voting == 'max':\n",
        "\t\t\t\tlabel = label.max() # get patient label (MIL convention)\n",
        "\t\t\telif patient_voting == 'maj':\n",
        "\t\t\t\tlabel = stats.mode(label)[0]\n",
        "\t\t\telse:\n",
        "\t\t\t\traise NotImplementedError\n",
        "\t\t\tpatient_labels.append(label)\n",
        "\t\t\n",
        "\t\tself.patient_data = {'case_id':patients, 'label':np.array(patient_labels)}\n",
        "\n",
        "\t@staticmethod\n",
        "\tdef df_prep(data, label_dict, ignore, label_col): # map label to sub-class type {'subtype_1':0, 'subtype_2':1, 'subtype_3':2}\n",
        "\t\tif label_col != 'label':\n",
        "\t\t\tdata['label'] = data[label_col].copy()\n",
        "\n",
        "\t\tmask = data['label'].isin(ignore)\n",
        "\t\tdata = data[~mask]\n",
        "\t\tdata.reset_index(drop=True, inplace=True)\n",
        "\t\tfor i in data.index:\n",
        "\t\t\tkey = data.loc[i, 'label']\n",
        "\t\t\tdata.at[i, 'label'] = label_dict[key]\n",
        "\n",
        "\t\treturn data\n",
        "\n",
        "\tdef filter_df(self, df, filter_dict={}):\n",
        "\t\tif len(filter_dict) > 0:\n",
        "\t\t\tfilter_mask = np.full(len(df), True, bool)\n",
        "\t\t\t# assert 'label' not in filter_dict.keys()\n",
        "\t\t\tfor key, val in filter_dict.items():\n",
        "\t\t\t\tmask = df[key].isin(val)\n",
        "\t\t\t\tfilter_mask = np.logical_and(filter_mask, mask)\n",
        "\t\t\tdf = df[filter_mask]\n",
        "\t\treturn df\n",
        "\n",
        "\tdef __len__(self):\n",
        "\t\tif self.patient_strat:\n",
        "\t\t\treturn len(self.patient_data['case_id'])\n",
        "\n",
        "\t\telse:\n",
        "\t\t\treturn len(self.slide_data)\n",
        "\n",
        "\tdef summarize(self):\n",
        "\t\tprint(\"label column: {}\".format(self.label_col))\n",
        "\t\tprint(\"label dictionary: {}\".format(self.label_dict))\n",
        "\t\tprint(\"number of classes: {}\".format(self.num_classes))\n",
        "\t\tprint(\"slide-level counts: \", '\\n', self.slide_data['label'].value_counts(sort = False))\n",
        "\t\tfor i in range(self.num_classes):\n",
        "\t\t\tprint('Patient-LVL; Number of samples registered in class %d: %d' % (i, self.patient_cls_ids[i].shape[0]))\n",
        "\t\t\tprint('Slide-LVL; Number of samples registered in class %d: %d' % (i, self.slide_cls_ids[i].shape[0]))\n",
        "\n",
        "\tdef create_splits(self, k = 3, val_num = (25, 25), test_num = (40, 40), label_frac = 1.0, custom_test_ids = None):\n",
        "\t\tsettings = {\n",
        "\t\t\t\t\t'n_splits' : k, \n",
        "\t\t\t\t\t'val_num' : val_num, \n",
        "\t\t\t\t\t'test_num': test_num,\n",
        "\t\t\t\t\t'label_frac': label_frac,\n",
        "\t\t\t\t\t'seed': self.seed,\n",
        "\t\t\t\t\t'custom_test_ids': custom_test_ids\n",
        "\t\t\t\t\t}\n",
        "\n",
        "\t\tif self.patient_strat:\n",
        "\t\t\tsettings.update({'cls_ids' : self.patient_cls_ids, 'samples': len(self.patient_data['case_id'])})\n",
        "\t\telse:\n",
        "\t\t\tsettings.update({'cls_ids' : self.slide_cls_ids, 'samples': len(self.slide_data)})\n",
        "\n",
        "\t\tself.split_gen = generate_split(**settings)\n",
        "\n",
        "\tdef set_splits(self,start_from=None):\n",
        "\t\tif start_from:\n",
        "\t\t\tids = nth(self.split_gen, start_from)\n",
        "\n",
        "\t\telse:\n",
        "\t\t\tids = next(self.split_gen)\n",
        "\n",
        "\t\tif self.patient_strat:\n",
        "\t\t\tslide_ids = [[] for i in range(len(ids))] \n",
        "\n",
        "\t\t\tfor split in range(len(ids)): \n",
        "\t\t\t\tfor idx in ids[split]:\n",
        "\t\t\t\t\tcase_id = self.patient_data['case_id'][idx]\n",
        "\t\t\t\t\tslide_indices = self.slide_data[self.slide_data['case_id'] == case_id].index.tolist()\n",
        "\t\t\t\t\tslide_ids[split].extend(slide_indices)\n",
        "\n",
        "\t\t\tself.train_ids, self.val_ids, self.test_ids = slide_ids[0], slide_ids[1], slide_ids[2]\n",
        "\n",
        "\t\telse:\n",
        "\t\t\tself.train_ids, self.val_ids, self.test_ids = ids\n",
        "\n",
        "\tdef get_split_from_df(self, all_splits, split_key='train'):\n",
        "\t\tsplit = all_splits[split_key]\n",
        "\t\tsplit = split.dropna().reset_index(drop=True)\n",
        "\n",
        "\t\tif len(split) > 0:\n",
        "\t\t\tmask = self.slide_data['slide_id'].isin(split.tolist())\n",
        "\t\t\tdf_slice = self.slide_data[mask].reset_index(drop=True)\n",
        "\t\t\tsplit = Generic_Split(df_slice, data_dir=self.data_dir, num_classes=self.num_classes)\n",
        "\t\telse:\n",
        "\t\t\tsplit = None\n",
        "\t\t\n",
        "\t\treturn split\n",
        "\n",
        "\tdef get_merged_split_from_df(self, all_splits, split_keys=['train']):\n",
        "\t\tmerged_split = []\n",
        "\t\tfor split_key in split_keys:\n",
        "\t\t\tsplit = all_splits[split_key]\n",
        "\t\t\tsplit = split.dropna().reset_index(drop=True).tolist()\n",
        "\t\t\tmerged_split.extend(split)\n",
        "\n",
        "\t\tif len(split) > 0:\n",
        "\t\t\tmask = self.slide_data['slide_id'].isin(merged_split)\n",
        "\t\t\tdf_slice = self.slide_data[mask].reset_index(drop=True)\n",
        "\t\t\tsplit = Generic_Split(df_slice, data_dir=self.data_dir, num_classes=self.num_classes)\n",
        "\t\telse:\n",
        "\t\t\tsplit = None\n",
        "\t\t\n",
        "\t\treturn split\n",
        "\n",
        "\n",
        "\tdef return_splits(self, from_id=True, csv_path=None):\n",
        "\t\tif from_id:\n",
        "\t\t\tif len(self.train_ids) > 0:\n",
        "\t\t\t\ttrain_data = self.slide_data.loc[self.train_ids].reset_index(drop=True)\n",
        "\t\t\t\ttrain_split = Generic_Split(train_data, data_dir=self.data_dir, num_classes=self.num_classes)\n",
        "\n",
        "\t\t\telse:\n",
        "\t\t\t\ttrain_split = None\n",
        "\t\t\t\n",
        "\t\t\tif len(self.val_ids) > 0:\n",
        "\t\t\t\tval_data = self.slide_data.loc[self.val_ids].reset_index(drop=True)\n",
        "\t\t\t\tval_split = Generic_Split(val_data, data_dir=self.data_dir, num_classes=self.num_classes)\n",
        "\n",
        "\t\t\telse:\n",
        "\t\t\t\tval_split = None\n",
        "\t\t\t\n",
        "\t\t\tif len(self.test_ids) > 0:\n",
        "\t\t\t\ttest_data = self.slide_data.loc[self.test_ids].reset_index(drop=True)\n",
        "\t\t\t\ttest_split = Generic_Split(test_data, data_dir=self.data_dir, num_classes=self.num_classes)\n",
        "\t\t\t\n",
        "\t\t\telse:\n",
        "\t\t\t\ttest_split = None\n",
        "\t\t\t\n",
        "\t\t\n",
        "\t\telse:\n",
        "\t\t\tassert csv_path \n",
        "\t\t\tall_splits = pd.read_csv(csv_path)\n",
        "\t\t\ttrain_split = self.get_split_from_df(all_splits, 'train')\n",
        "\t\t\tval_split = self.get_split_from_df(all_splits, 'val')\n",
        "\t\t\ttest_split = self.get_split_from_df(all_splits, 'test')\n",
        "\t\t\t\n",
        "\t\treturn train_split, val_split, test_split\n",
        "\n",
        "\tdef get_list(self, ids):\n",
        "\t\treturn self.slide_data['slide_id'][ids]\n",
        "\n",
        "\tdef getlabel(self, ids):\n",
        "\t\treturn self.slide_data['label'][ids]\n",
        "\n",
        "\tdef __getitem__(self, idx):\n",
        "\t\treturn None\n",
        "\n",
        "\tdef test_split_gen(self, return_descriptor=False):\n",
        "\n",
        "\t\tif return_descriptor:\n",
        "\t\t\tindex = [list(self.label_dict.keys())[list(self.label_dict.values()).index(i)] for i in range(self.num_classes)]\n",
        "\t\t\tcolumns = ['train', 'val', 'test']\n",
        "\t\t\tdf = pd.DataFrame(np.full((len(index), len(columns)), 0, dtype=np.int32), index= index,\n",
        "\t\t\t\t\t\t\tcolumns= columns)\n",
        "\n",
        "\t\tcount = len(self.train_ids)\n",
        "\t\tprint('\\nnumber of training samples: {}'.format(count))\n",
        "\t\tlabels = self.getlabel(self.train_ids)\n",
        "\t\tunique, counts = np.unique(labels, return_counts=True)\n",
        "\t\tfor u in range(len(unique)):\n",
        "\t\t\tprint('number of samples in cls {}: {}'.format(unique[u], counts[u]))\n",
        "\t\t\tif return_descriptor:\n",
        "\t\t\t\tdf.loc[index[u], 'train'] = counts[u]\n",
        "\t\t\n",
        "\t\tcount = len(self.val_ids)\n",
        "\t\tprint('\\nnumber of val samples: {}'.format(count))\n",
        "\t\tlabels = self.getlabel(self.val_ids)\n",
        "\t\tunique, counts = np.unique(labels, return_counts=True)\n",
        "\t\tfor u in range(len(unique)):\n",
        "\t\t\tprint('number of samples in cls {}: {}'.format(unique[u], counts[u]))\n",
        "\t\t\tif return_descriptor:\n",
        "\t\t\t\tdf.loc[index[u], 'val'] = counts[u]\n",
        "\n",
        "\t\tcount = len(self.test_ids)\n",
        "\t\tprint('\\nnumber of test samples: {}'.format(count))\n",
        "\t\tlabels = self.getlabel(self.test_ids)\n",
        "\t\tunique, counts = np.unique(labels, return_counts=True)\n",
        "\t\tfor u in range(len(unique)):\n",
        "\t\t\tprint('number of samples in cls {}: {}'.format(unique[u], counts[u]))\n",
        "\t\t\tif return_descriptor:\n",
        "\t\t\t\tdf.loc[index[u], 'test'] = counts[u]\n",
        "\n",
        "\t\tassert len(np.intersect1d(self.train_ids, self.test_ids)) == 0\n",
        "\t\tassert len(np.intersect1d(self.train_ids, self.val_ids)) == 0\n",
        "\t\tassert len(np.intersect1d(self.val_ids, self.test_ids)) == 0\n",
        "\n",
        "\t\tif return_descriptor:\n",
        "\t\t\treturn df\n",
        "\n",
        "\tdef save_split(self, filename):\n",
        "\t\ttrain_split = self.get_list(self.train_ids)\n",
        "\t\tval_split = self.get_list(self.val_ids)\n",
        "\t\ttest_split = self.get_list(self.test_ids)\n",
        "\t\tdf_tr = pd.DataFrame({'train': train_split})\n",
        "\t\tdf_v = pd.DataFrame({'val': val_split})\n",
        "\t\tdf_t = pd.DataFrame({'test': test_split})\n",
        "\t\tdf = pd.concat([df_tr, df_v, df_t], axis=1) \n",
        "\t\tdf.to_csv(filename, index = False)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neuZmctC2GV_"
      },
      "source": [
        "class Generic_MIL_Dataset(Generic_WSI_Classification_Dataset):\n",
        "\tdef __init__(self,\n",
        "\t\tdata_dir, \n",
        "\t\t**kwargs):\n",
        "\t\n",
        "\t\tsuper(Generic_MIL_Dataset, self).__init__(**kwargs)\n",
        "\t\tself.data_dir = data_dir\n",
        "\t\tself.use_h5 = False\n",
        "\n",
        "\tdef load_from_h5(self, toggle):\n",
        "\t\tself.use_h5 = toggle\n",
        "\n",
        "\tdef __getitem__(self, idx):\n",
        "\t\tslide_id = self.slide_data['slide_id'][idx]\n",
        "\t\tlabel = self.slide_data['label'][idx]\n",
        "\t\tif type(self.data_dir) == dict:\n",
        "\t\t\tsource = self.slide_data['source'][idx]\n",
        "\t\t\tdata_dir = self.data_dir[source]\n",
        "\t\telse:\n",
        "\t\t\tdata_dir = self.data_dir\n",
        "\n",
        "\t\tif not self.use_h5:\n",
        "\t\t\tif self.data_dir:\n",
        "\t\t\t\tfull_path = os.path.join(data_dir, 'pt_files', '{}.pt'.format(slide_id))\n",
        "\t\t\t\tfeatures = torch.load(full_path)\n",
        "\t\t\t\treturn features, label\n",
        "\t\t\t\n",
        "\t\t\telse:\n",
        "\t\t\t\treturn slide_id, label\n",
        "\n",
        "\t\telse:\n",
        "\t\t\tfull_path = os.path.join(data_dir,'h5_files','{}.h5'.format(slide_id))\n",
        "\t\t\twith h5py.File(full_path,'r') as hdf5_file:\n",
        "\t\t\t\tfeatures = hdf5_file['features'][:]\n",
        "\t\t\t\tcoords = hdf5_file['coords'][:]\n",
        "\n",
        "\t\t\tfeatures = torch.from_numpy(features)\n",
        "\t\t\treturn features, label, coords"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Py0dh1P_2B55"
      },
      "source": [
        "class Generic_Split(Generic_MIL_Dataset):\n",
        "\tdef __init__(self, slide_data, data_dir=None, num_classes=2):\n",
        "\t\tself.use_h5 = False\n",
        "\t\tself.slide_data = slide_data\n",
        "\t\tself.data_dir = data_dir\n",
        "\t\tself.num_classes = num_classes\n",
        "\t\tself.slide_cls_ids = [[] for i in range(self.num_classes)]\n",
        "\t\tfor i in range(self.num_classes):\n",
        "\t\t\tself.slide_cls_ids[i] = np.where(self.slide_data['label'] == i)[0]\n",
        "\n",
        "\tdef __len__(self):\n",
        "\t\treturn len(self.slide_data)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciKjpX6g1la5"
      },
      "source": [
        "#Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYXRjMnJ1nT3"
      },
      "source": [
        "def generate_split(cls_ids, val_num, test_num, samples, n_splits = 5,\n",
        "\tseed = 7, label_frac = 1.0, custom_test_ids = None):\n",
        "\tindices = np.arange(samples).astype(int)\n",
        "\t\n",
        "\tif custom_test_ids is not None:\n",
        "\t\tindices = np.setdiff1d(indices, custom_test_ids)\n",
        "\n",
        "\tnp.random.seed(seed)\n",
        "\tfor i in range(n_splits):\n",
        "\t\tall_val_ids = []\n",
        "\t\tall_test_ids = []\n",
        "\t\tsampled_train_ids = []\n",
        "\t\t\n",
        "\t\tif custom_test_ids is not None: # pre-built test split, do not need to sample\n",
        "\t\t\tall_test_ids.extend(custom_test_ids)\n",
        "\n",
        "\t\tfor c in range(len(val_num)):\n",
        "\t\t\tpossible_indices = np.intersect1d(cls_ids[c], indices) #all indices of this class\n",
        "\t\t\tval_ids = np.random.choice(possible_indices, val_num[c], replace = False) # validation ids\n",
        "\n",
        "\t\t\tremaining_ids = np.setdiff1d(possible_indices, val_ids) #indices of this class left after validation\n",
        "\t\t\tall_val_ids.extend(val_ids)\n",
        "\n",
        "\t\t\tif custom_test_ids is None: # sample test split\n",
        "\n",
        "\t\t\t\ttest_ids = np.random.choice(remaining_ids, test_num[c], replace = False)\n",
        "\t\t\t\tremaining_ids = np.setdiff1d(remaining_ids, test_ids)\n",
        "\t\t\t\tall_test_ids.extend(test_ids)\n",
        "\n",
        "\t\t\tif label_frac == 1:\n",
        "\t\t\t\tsampled_train_ids.extend(remaining_ids)\n",
        "\t\t\t\n",
        "\t\t\telse:\n",
        "\t\t\t\tsample_num  = math.ceil(len(remaining_ids) * label_frac)\n",
        "\t\t\t\tslice_ids = np.arange(sample_num)\n",
        "\t\t\t\tsampled_train_ids.extend(remaining_ids[slice_ids])\n",
        "\n",
        "\t\tyield sampled_train_ids, all_val_ids, all_test_ids"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cg-WQryayiW6"
      },
      "source": [
        "#Args"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgzYFPm1ySvx"
      },
      "source": [
        "label_frac = 1.0\n",
        "seed = 1\n",
        "k = 10\n",
        "task = 'task_2_tumor_subtyping'\n",
        "val_frac = 0.1\n",
        "test_frac = 0.1\n",
        "n_classes = 3"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbjAs_nWzOiu"
      },
      "source": [
        "#Main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgZ-DFViy82v",
        "outputId": "c7919124-d89b-45d2-a4dc-4429cd5eb87a"
      },
      "source": [
        "dataset = Generic_WSI_Classification_Dataset(csv_path = 'dataset_csv/tumor_subtyping_dummy_clean.csv',\n",
        "                            shuffle = False, \n",
        "                            seed = seed, \n",
        "                            print_info = True,\n",
        "                            label_dict = {'G':0, 'A':1, 'O':2},\n",
        "                            patient_strat= True,\n",
        "                            patient_voting='maj',\n",
        "                            ignore=[])\n",
        "\n",
        "num_slides_cls = np.array([len(cls_ids) for cls_ids in dataset.patient_cls_ids])\n",
        "val_num = np.round(num_slides_cls * val_frac).astype(int)\n",
        "test_num = np.round(num_slides_cls * test_frac).astype(int)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label column: label\n",
            "label dictionary: {'G': 0, 'A': 1, 'O': 2}\n",
            "number of classes: 3\n",
            "slide-level counts:  \n",
            " 0    133\n",
            "1     54\n",
            "2     34\n",
            "Name: label, dtype: int64\n",
            "Patient-LVL; Number of samples registered in class 0: 133\n",
            "Slide-LVL; Number of samples registered in class 0: 133\n",
            "Patient-LVL; Number of samples registered in class 1: 54\n",
            "Slide-LVL; Number of samples registered in class 1: 54\n",
            "Patient-LVL; Number of samples registered in class 2: 34\n",
            "Slide-LVL; Number of samples registered in class 2: 34\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hmui25QEzIrX",
        "outputId": "0181fcd5-56af-46db-b4bf-0a8dc0a300ea"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    if label_frac > 0:\n",
        "        label_fracs = [label_frac]\n",
        "    else:\n",
        "        label_fracs = [0.1, 0.25, 0.5, 0.75, 1.0]\n",
        "    \n",
        "    for lf in label_fracs:\n",
        "        split_dir = 'splits/'+ str(task) + '_{}'.format(int(lf * 100))\n",
        "        os.makedirs(split_dir, exist_ok=True)\n",
        "        dataset.create_splits(k = k, val_num = val_num, test_num = test_num, label_frac=lf)\n",
        "        for i in range(k):\n",
        "            dataset.set_splits()\n",
        "            descriptor_df = dataset.test_split_gen(return_descriptor=True)\n",
        "            splits = dataset.return_splits(from_id=True)\n",
        "            save_splits(splits, ['train', 'val', 'test'], os.path.join(split_dir, 'splits_{}.csv'.format(i)))\n",
        "            save_splits(splits, ['train', 'val', 'test'], os.path.join(split_dir, 'splits_{}_bool.csv'.format(i)), boolean_style=True)\n",
        "            descriptor_df.to_csv(os.path.join(split_dir, 'splits_{}_descriptor.csv'.format(i)))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "number of training samples: 179\n",
            "number of samples in cls 0: 107\n",
            "number of samples in cls 1: 44\n",
            "number of samples in cls 2: 28\n",
            "\n",
            "number of val samples: 21\n",
            "number of samples in cls 0: 13\n",
            "number of samples in cls 1: 5\n",
            "number of samples in cls 2: 3\n",
            "\n",
            "number of test samples: 21\n",
            "number of samples in cls 0: 13\n",
            "number of samples in cls 1: 5\n",
            "number of samples in cls 2: 3\n",
            "\n",
            "\n",
            "\n",
            "number of training samples: 179\n",
            "number of samples in cls 0: 107\n",
            "number of samples in cls 1: 44\n",
            "number of samples in cls 2: 28\n",
            "\n",
            "number of val samples: 21\n",
            "number of samples in cls 0: 13\n",
            "number of samples in cls 1: 5\n",
            "number of samples in cls 2: 3\n",
            "\n",
            "number of test samples: 21\n",
            "number of samples in cls 0: 13\n",
            "number of samples in cls 1: 5\n",
            "number of samples in cls 2: 3\n",
            "\n",
            "\n",
            "\n",
            "number of training samples: 179\n",
            "number of samples in cls 0: 107\n",
            "number of samples in cls 1: 44\n",
            "number of samples in cls 2: 28\n",
            "\n",
            "number of val samples: 21\n",
            "number of samples in cls 0: 13\n",
            "number of samples in cls 1: 5\n",
            "number of samples in cls 2: 3\n",
            "\n",
            "number of test samples: 21\n",
            "number of samples in cls 0: 13\n",
            "number of samples in cls 1: 5\n",
            "number of samples in cls 2: 3\n",
            "\n",
            "\n",
            "\n",
            "number of training samples: 179\n",
            "number of samples in cls 0: 107\n",
            "number of samples in cls 1: 44\n",
            "number of samples in cls 2: 28\n",
            "\n",
            "number of val samples: 21\n",
            "number of samples in cls 0: 13\n",
            "number of samples in cls 1: 5\n",
            "number of samples in cls 2: 3\n",
            "\n",
            "number of test samples: 21\n",
            "number of samples in cls 0: 13\n",
            "number of samples in cls 1: 5\n",
            "number of samples in cls 2: 3\n",
            "\n",
            "\n",
            "\n",
            "number of training samples: 179\n",
            "number of samples in cls 0: 107\n",
            "number of samples in cls 1: 44\n",
            "number of samples in cls 2: 28\n",
            "\n",
            "number of val samples: 21\n",
            "number of samples in cls 0: 13\n",
            "number of samples in cls 1: 5\n",
            "number of samples in cls 2: 3\n",
            "\n",
            "number of test samples: 21\n",
            "number of samples in cls 0: 13\n",
            "number of samples in cls 1: 5\n",
            "number of samples in cls 2: 3\n",
            "\n",
            "\n",
            "\n",
            "number of training samples: 179\n",
            "number of samples in cls 0: 107\n",
            "number of samples in cls 1: 44\n",
            "number of samples in cls 2: 28\n",
            "\n",
            "number of val samples: 21\n",
            "number of samples in cls 0: 13\n",
            "number of samples in cls 1: 5\n",
            "number of samples in cls 2: 3\n",
            "\n",
            "number of test samples: 21\n",
            "number of samples in cls 0: 13\n",
            "number of samples in cls 1: 5\n",
            "number of samples in cls 2: 3\n",
            "\n",
            "\n",
            "\n",
            "number of training samples: 179\n",
            "number of samples in cls 0: 107\n",
            "number of samples in cls 1: 44\n",
            "number of samples in cls 2: 28\n",
            "\n",
            "number of val samples: 21\n",
            "number of samples in cls 0: 13\n",
            "number of samples in cls 1: 5\n",
            "number of samples in cls 2: 3\n",
            "\n",
            "number of test samples: 21\n",
            "number of samples in cls 0: 13\n",
            "number of samples in cls 1: 5\n",
            "number of samples in cls 2: 3\n",
            "\n",
            "\n",
            "\n",
            "number of training samples: 179\n",
            "number of samples in cls 0: 107\n",
            "number of samples in cls 1: 44\n",
            "number of samples in cls 2: 28\n",
            "\n",
            "number of val samples: 21\n",
            "number of samples in cls 0: 13\n",
            "number of samples in cls 1: 5\n",
            "number of samples in cls 2: 3\n",
            "\n",
            "number of test samples: 21\n",
            "number of samples in cls 0: 13\n",
            "number of samples in cls 1: 5\n",
            "number of samples in cls 2: 3\n",
            "\n",
            "\n",
            "\n",
            "number of training samples: 179\n",
            "number of samples in cls 0: 107\n",
            "number of samples in cls 1: 44\n",
            "number of samples in cls 2: 28\n",
            "\n",
            "number of val samples: 21\n",
            "number of samples in cls 0: 13\n",
            "number of samples in cls 1: 5\n",
            "number of samples in cls 2: 3\n",
            "\n",
            "number of test samples: 21\n",
            "number of samples in cls 0: 13\n",
            "number of samples in cls 1: 5\n",
            "number of samples in cls 2: 3\n",
            "\n",
            "\n",
            "\n",
            "number of training samples: 179\n",
            "number of samples in cls 0: 107\n",
            "number of samples in cls 1: 44\n",
            "number of samples in cls 2: 28\n",
            "\n",
            "number of val samples: 21\n",
            "number of samples in cls 0: 13\n",
            "number of samples in cls 1: 5\n",
            "number of samples in cls 2: 3\n",
            "\n",
            "number of test samples: 21\n",
            "number of samples in cls 0: 13\n",
            "number of samples in cls 1: 5\n",
            "number of samples in cls 2: 3\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}